TY  - JOUR
AU  - Garvey, JB
TI  - LET'S GET REAL: WEAK ARTIFICIAL INTELLIGENCE HAS FREE SPEECH RIGHTS
T2  - FORDHAM LAW REVIEW
LA  - English
AB  - The right to free speech is a strongly protected constitutional right under the First Amendment to the U.S. Constitution. In 2010, the U.S. Supreme Court significantly expanded free speech protections for corporations in Citizens United v. FEC. This case prompted the question: could other nonhuman actors also be eligible for free speech protection under the First Amendment? This inquiry is no longer a mere intellectual exercise: sophisticated artificial intelligence (AI) may soon be capable of producing speech. As such, there are novel and complex questions surrounding the application of the First Amendment to AI. Some commentators argue that AI should be granted free speech rights because AI speech may soon be sufficiently comparable to human speech. Others disagree and argue that First Amendment rights should not be extended to AI because there are traits in human speech that AI speech could not replicate. This Note explores the application of First Amendment jurisprudence to AI. Introducing relevant philosophical literature, this Note examines theories of human intelligence and decision-making in order to better understand the process that humans use to produce speech, and whether AI produces speech in a similar manner. In light of the legal and philosophical literature, as well as the Supreme Court's current First Amendment jurisprudence, this Note proposes that some types of AI are eligible for free speech protection under the First Amendment.
AD  - Fordham Univ, Sch Law, Bronx, NY 10458 USAC3  - Fordham UniversityPU  - FORDHAM UNIV, SCHOOL LAW
PI  - NEW YORK
PA  - 140 W 62ND STREET, NEW YORK, NY 10023 USA
SN  - 0015-704X
J9  - FORDHAM LAW REV
JI  - Fordham Law Rev.
DA  - DEC
PY  - 2022
VL  - 91
IS  - 3
SP  - 953
EP  - 991
WE  - Social Science Citation Index (SSCI)AN  - WOS:000892560400005
N1  - Times Cited in Web of Science Core Collection:  2
Total Times Cited:  2
Cited Reference Count:  92
ER  -

TY  - JOUR
AU  - Khan, A
AU  - Jiliani, MAHS
TI  - EXPANDING THE BOUNDARIES OF JURISPRUDENCE IN THE ERA OF TECHNOLOGICAL ADVANCEMENTS
T2  - IIUM LAW JOURNAL
LA  - English
KW  - New Technology Era
KW  - Artificial Intelligence
KW  - Big Data Basic
KW  - Scope of Jurisprudence
KW  - Jurisprudence Response
KW  - ARTIFICIAL-INTELLIGENCE
KW  - LAW
KW  - INFORMATION
KW  - TRANSFORMATION
KW  - PARTICIPATION
KW  - SOCIOLOGY
KW  - PROPERTY
KW  - JUDGES
KW  - ETHICS
KW  - NORMS
AB  - In the current era of advanced technology, the convergence of artificial intelligence (AI) and big data presents intricate challenges in the technical and doctrinal aspects of law and the fundamental principles of jurisprudence. Addressing this challenge entails three potential approaches: reevaluating the independent status of specific foundational categories, reconfiguring the interpretation of such categories, or steadfastly defending and enhancing our understanding of specific classifications. The reconstruction of the essential concept of "law" remains uncertain and necessitates further deliberation. Although the new technological era has not introduced entirely novel jurisprudential dilemmas, it has reconsidered existing perspectives. Swiftly and effectively responding to these challenges becomes paramount in seizing fresh opportunities for the independent advancement of Chinese jurisprudence. The purpose of the study is to push the boundaries of jurisprudence by exploring and addressing legal issues arising in the era of technological advancements. The qualitative research methodology has been applied in this article.
AD  - Univ Sialkot, Dept Law, Sialkot, PakistanAD  - Zhengzhou Univ, Sch Law, Zhengzhou, Peoples R ChinaC3  - Zhengzhou UniversityPU  - INT ISLAMIC UNIV MALAYSIA, PRESS RESEARCH MANAGEMENT CENTER
PI  - KUALA LUMPUR
PA  - PO BOX 10, KUALA LUMPUR, 50728, MALAYSIA
SN  - 0128-2530
SN  - 2289-7852
J9  - IIUM LAW J
JI  - IIUM Law J.
PY  - 2023
VL  - 31
IS  - 2
SP  - 393
EP  - 426
WE  - Emerging Sources Citation Index (ESCI)AN  - WOS:001125185300014
N1  - Times Cited in Web of Science Core Collection:  1
Total Times Cited:  1
Cited Reference Count:  177
ER  -

TY  - JOUR
AU  - Chatterjee, S
AU  - Sreenivasulu, NS
TI  - Artificial intelligence and human rights: a comprehensive study from Indian legal and policy perspective
T2  - INTERNATIONAL JOURNAL OF LAW AND MANAGEMENT
LA  - English
KW  - Law and regulation
KW  - Governance and ethics
KW  - Policy and law
KW  - Data privacy law
KW  - Technology law
KW  - AI
KW  - Regulation
KW  - Law
KW  - Policy
KW  - India
KW  - Technology
KW  - Jurisprudence
KW  - TECHNOLOGY
KW  - GOVERNANCE
KW  - INTERNET
AB  - Purpose - The purpose of this study is to investigate the impact of artificial intelligence (AI) on the human rights issue. This study has also examined issues with AI for business and its civil and criminal liability. This study has provided inputs to the policymakers and government authorities to overcome different challenges.
   Design/methodology/approach - This study has analysed different international and Indian laws on human rights issues and the impacts of these laws to protect the human rights of the individual, which could be under threat due to the advancement of AI technology. This study has used descriptive doctrinal legal research methods to examine and understand the insights of existing laws and regulations in India to protect human rights and how these laws could be further developed to protect human rights under the Indian jurisprudence, which is under threat due to rapid advancement of AI-related technology.
   Findings - The study provides a comprehensive insight on the influence of AI on human rights issues and the existing laws in India. The study also shows different policy initiatives by the Government of India to regulate AI.
   Research limitations/implications - The study highlights some of the key policy recommendations helpful to regulate AI. Moreover, this study provides inputs to the regulatory authorities and legal fraternity to draft a much-needed comprehensive policy to regulate AI in the context of the protection of human rights of the citizens.
   Originality/value - AI is constantly posing entangled challenges to human rights. There is no comprehensive study, which investigated the emergence of AI and its influence on human rights issues, especially from the Indian legal perspective. So there is a research gap. This study provides a unique insight of the emergence of AI applications and its influence on human rights issues and provides inputs to the policymaker to help them to draft an effective regulation on AI to protect the human rights of Indian citizens. Thus, this study is considered a unique study that adds value towards the overall literature.
AD  - WB Natl Univ Jurid Sci, Kolkata, IndiaPU  - EMERALD GROUP PUBLISHING LTD
PI  - BINGLEY
PA  - HOWARD HOUSE, WAGON LANE, BINGLEY BD16 1WA, W YORKSHIRE, ENGLAND
SN  - 1754-243X
SN  - 1754-2448
J9  - INT J LAW MANAG
JI  - Int. J. Law Manag.
DA  - JAN 7
PY  - 2022
VL  - 64
IS  - 1
SP  - 110
EP  - 134
DO  - 10.1108/IJLMA-02-2021-0049
C6  - JUN 2021
WE  - Emerging Sources Citation Index (ESCI)AN  - WOS:000663042700001
N1  - Times Cited in Web of Science Core Collection:  8
Total Times Cited:  8
Cited Reference Count:  54
ER  -

TY  - JOUR
AU  - Hacker, P
AU  - Cordes, J
AU  - Rochon, J
TI  - Regulating Gatekeeper Artificial Intelligence and Data: Transparency, Access and Fairness under the Digital Markets Act, the General Data Protection Regulation and Beyond
T2  - EUROPEAN JOURNAL OF RISK REGULATION
LA  - English
KW  - AI
KW  - data
KW  - DMA
KW  - AUTOMATED DECISION-MAKING
KW  - TRADE SECRETS
KW  - INNOVATION EVIDENCE
KW  - DISCRIMINATION
AB  - Artificial intelligence (AI) is not only increasingly being used in business and administration contexts, but a race for its regulation is also underway, with the European Union (EU) spearheading the efforts. Contrary to existing literature, this article suggests that the most far-reaching and effective EU rules for AI applications in the digital economy will not be contained in the proposed AI Act, but in the Digital Markets Act (DMA). We analyse the impact of the DMA and related EU acts on AI models and underlying data across four key areas: disclosure requirements; the regulation of AI training data; access rules; and the regime for fair rankings. We demonstrate that fairness, under the DMA, goes beyond traditionally protected categories of non-discrimination law on which scholarship at the intersection of AI and law has focused on. Rather, we draw on competition law and the FRAND criteria known from intellectual property law to interpret and refine the DMA provisions on fair rankings. Moreover, we show how, based on Court of Justice of the European Union jurisprudence, a coherent interpretation of the concept of non-discrimination in both traditional non-discrimination and competition law may be found. The final section sketches out proposals for a comprehensive framework of transparency, access and fairness under the DMA and beyond.
AD  - European Univ Viadrina, Chair Law & Eth Digital Soc, European New Sch Digital Studies, Frankfurt, GermanyC3  - European University Viadrina Frankfurt OderPU  - CAMBRIDGE UNIV PRESS
PI  - CAMBRIDGE
PA  - EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND
SN  - 1867-299X
SN  - 2190-8249
J9  - EUR J RISK REGUL
JI  - Eur. J. Risk Regul.
DA  - MAR
PY  - 2024
VL  - 15
IS  - 1
SP  - 49
EP  - 86
DO  - 10.1017/err.2023.81
C6  - DEC 2023
WE  - Emerging Sources Citation Index (ESCI)AN  - WOS:001125220300001
N1  - Times Cited in Web of Science Core Collection:  2
Total Times Cited:  2
Cited Reference Count:  221
ER  -

TY  - JOUR
AU  - Devany, BE
TI  - Clearview AI's First Amendment: A Dangerous Reality?
T2  - TEXAS LAW REVIEW
LA  - English
KW  - PRIVACY
AB  - On May 9, 2022, Clearview AI and the ACLU settled a two-year long dispute over the Illinois Biometric Information Privacy Act (BIPA), which prohibits companies like Clearview from scraping mass amounts of data from the internet. The ACLU sued Clearview for collecting billions of our personal- but publicly available-photos, a violation not only of BIPA but also of the user agreements of websites like Facebook, LinkedIn, and Twitter. Clearview uses these photos to create the largest known facial recognition database. Clearview's technology, which it licenses to law enforcement agencies across the country, can identify a face in a matter of seconds. As privacy and technology continue to clash, ACLU v. Clearview, Inc. provided an opportunity to address the underlying constitutional tension between the First Amendment and privacy. But since the suit settled, these questions remain unanswered.Clearview claims it has a First Amendment right to scrape data and sell its facial recognition service. Legal scholars have disposed of this argument as "simplistic, " "at odds with long-established First Amendment doctrine, " "far from convincing, " and even "dangerous. " But whether we like it or not, Clearview's claims might not be so far off from current First Amendment jurisprudence, which has recently taken an aggressive and deregulatory turn. This Note explores current First Amendment jurisprudence and Clearview AI's interpretation of the First Amendment, which might be a reality. This Note also addresses the advantages and risks associated with facial recognition technology (FRT). Finally, this Note proposes a template for legislation that can regulate FRT in a way that is consistent with modern notions of privacy and current First Amendment doctrine.
AD  - Univ Texas Austin, Sch Law, Austin, TX 78705 USAC3  - University of Texas SystemC3  - University of Texas AustinPU  - TEXAS LAW REVIEW PUBL INC
PI  - AUSTIN
PA  - 727 E 26TH ST, AUSTIN, TX 78705 USA
SN  - 0040-4411
SN  - 1942-857X
J9  - TEX LAW REV
JI  - Tex. Law Rev.
DA  - DEC
PY  - 2022
VL  - 101
IS  - 2
SP  - 473
EP  - 507
WE  - Social Science Citation Index (SSCI)AN  - WOS:000920401800004
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  118
ER  -

TY  - JOUR
AU  - Devany, BE
TI  - Clearview AI's First Amendment: A Dangerous Reality?
T2  - TEXAS LAW REVIEW
LA  - English
KW  - PRIVACY
AB  - On May 9, 2022, Clearview AI and the ACLU settled a two-year long dispute over the Illinois Biometric Information Privacy Act (BIPA), which prohibits companies like Clearview from scraping mass amounts of data from the internet. The ACLU sued Clearview for collecting billions of our personal- but publicly available-photos, a violation not only of BIPA but also of the user agreements of websites like Facebook, LinkedIn, and Twitter. Clearview uses these photos to create the largest known facial recognition database. Clearview's technology, which it licenses to law enforcement agencies across the country, can identify a face in a matter of seconds. As privacy and technology continue to clash, ACLU v. Clearview, Inc. provided an opportunity to address the underlying constitutional tension between the First Amendment and privacy. But since the suit settled, these questions remain unanswered.Clearview claims it has a First Amendment right to scrape data and sell its facial recognition service. Legal scholars have disposed of this argument as "simplistic," "at odds with long-established First Amendment doctrine," "far from convincing," and even "dangerous." But whether we like it or not, Clearview's claims might not be so far off from current First Amendment jurisprudence, which has recently taken an aggressive and deregulatory turn. This Note explores current First Amendment jurisprudence and Clearview AI's interpretation of the First Amendment, which might be a reality. This Note also addresses the advantages and risks associated with facial recognition technology (FRT). Finally, this Note proposes a template for legislation that can regulate FRT in a way that is consistent with modern notions of privacy and current First Amendment doctrine.
AD  - Univ Texas Austin, Sch Law, Austin, TX 78705 USAC3  - University of Texas SystemC3  - University of Texas AustinPU  - TEXAS LAW REVIEW PUBL INC
PI  - AUSTIN
PA  - 727 E 26TH ST, AUSTIN, TX 78705 USA
SN  - 0040-4411
SN  - 1942-857X
J9  - TEX LAW REV
JI  - Tex. Law Rev.
DA  - DEC
PY  - 2022
VL  - 101
IS  - 2
SP  - 473
EP  - 507
WE  - Social Science Citation Index (SSCI)AN  - WOS:000967921300001
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  114
ER  -

TY  - JOUR
AU  - Ferreira, DB
AU  - Gromova, EA
TI  - Hyperrealistic Jurisprudence: The Digital Age and the (Un)Certainty of Judge Analytics
T2  - INTERNATIONAL JOURNAL FOR THE SEMIOTICS OF LAW-REVUE INTERNATIONALE DE SEMIOTIQUE JURIDIQUE
LA  - English
KW  - Hyperrealism
KW  - Legal realism
KW  - Data analytics
KW  - Judge analytics
KW  - Legal decision making
KW  - LEGAL REALISM
KW  - JURIMETRICS
KW  - CONCEPTIONS
KW  - LAW
KW  - AI
AB  - This article is the first attempt to justify the "next" milestone in the development of legal realism: hyperrealism. The implications of digitalization have become the new fuel for the legal realist's jurisprudence prediction theory, that is, empirical research to predict the judge's or the court's decision. Indeed, that was impossible for American realists in the early twentieth century, and all the attempts failed. Therefore, tools such as Judicial Analytics allow us to prove that personal motives and prejudices affect a dispute's resolution. Based on a systemic, comparative, and interdisciplinary analysis that intermingles legal theory, data analytics and digital technologies, the article substantiates the concept of hyperrealism itself. It evaluates the advantages and disadvantages of its primary tool-judicial analytics. The authors state the necessity of creating regulatory mechanisms of "curbing" to use them to improve justice and minimize the risk of rights violations. They propose using tools of expert evaluation, standardization, and ethical regulation of forensic analysis.
AD  - Brazilian Ctr Mediat & Arbitrat CBMA, Rio De Janeiro, BrazilAD  - South Ural State Univ, Natl Res Univ, Dept Business Law, Int Cooperat, Chelyabinsk, RussiaC3  - South Ural State UniversityPU  - SPRINGER
PI  - DORDRECHT
PA  - VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN  - 0952-8059
SN  - 1572-8722
J9  - INT J SEMIOTIC LAW
JI  - Int. J. Semiotics Law
DA  - DEC
PY  - 2023
VL  - 36
IS  - 6
SP  - 2261
EP  - 2281
DO  - 10.1007/s11196-023-10015-0
C6  - MAY 2023
WE  - Emerging Sources Citation Index (ESCI)AN  - WOS:000992332200001
N1  - Times Cited in Web of Science Core Collection:  2
Total Times Cited:  2
Cited Reference Count:  94
ER  -

TY  - JOUR
AU  - Januário, TFX
TI  - Corporate Internal Investigations 4.0: on the criminal procedural aspects of applying artificial intelligence in the reactive corporate compliance
T2  - REVISTA BRASILEIRA DE DIREITO PROCESSUAL PENAL
LA  - English
KW  - Corporate criminal law
KW  - compliance
KW  - internal investigations
KW  - artificial intelligence
KW  - criminal procedure
AB  - The aim of the present paper is to analyze the criminal procedural implications of applying artificial intelligence systems in the context of internal investigations. More specifically, we will seek to answer the following questions: how can AI be used in these procedures and which are its legal boundaries? In case of effective use of this technology, how can it, in a future criminal proceeding, affect the admissibility and valuation of elements of information derived from internal investigations? In order to address these questions, we will apply the deductive methodology with a review of European and Brazilian legislation, doctrine and jurisprudence. At the end of the paper, we will demonstrate the limits to be observed for the processing of data and the use of AI in the scope of internal investigations, as well as the requirements and limits of sharing the information obtained from them with criminal proceedings.
AD  - Univ Coimbra, Law, Coimbra, PortugalC3  - Universidade de CoimbraPU  - INST BRASILEIRO DIREITO PROCESSUAL PENAL-IBRASPP
PI  - PORTO ALEGRE
PA  - AV PALMEIRA, 27-PETROPOLIS, PORTO ALEGRE, RS CEP90470-300, BRAZIL
SN  - 2359-3881
SN  - 2525-510X
J9  - REV BRAS DIREITO PRO
JI  - Rev. Bras. Direito Processual Penal
DA  - MAY-AUG
PY  - 2023
VL  - 9
IS  - 2
SP  - 723
EP  - 785
DO  - 10.22197/rbdpp.v9i2.837
WE  - Emerging Sources Citation Index (ESCI)AN  - WOS:001025630100007
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  113
ER  -

TY  - JOUR
AU  - Olimid, AP
AU  - Georgescu, CM
AU  - Olimid, DA
TI  - LEGAL ANALYSIS OF EU ARTIFICIAL INTELLIGENCE ACT (2024): INSIGHTS FROM PERSONAL DATA GOVERNANCE AND HEALTH POLICY
T2  - ACCESS TO JUSTICE IN EASTERN EUROPE
LA  - English
KW  - artificial intelligence
KW  - AI
KW  - ethical AI
KW  - EU legislation
KW  - generative AI
KW  - medical data
KW  - AI
AB  - Background: This study correlates the up-to-date ethical, functional and legal evaluations related to the management and governance of artificial intelligence (AI) under European Union (EU) law, particularly impacting the health data sector and medical standards as provided by the Artificial Intelligence Act within the Regulation adopted by the European Council in May 2024. The initial proposal for the management and governance of the AI sector was submitted in April 2021. Three years later, on 13 March 2024, the European Union Artificial Intelligence Act (EU AIA) was adopted by the European Parliament. Subsequently, on 21 May 2024, the Council adopted an innovative legislative framework that harmonises the standards and rules for AI regulation. This framework is set to take effect in May 2026, with the central objective of stimulating and motivating a fair, safe, legal single market that respects the principles of ethics and the fundamental rights of the human person. Methods: The current legal analysis focuses on the European Unions' new institutional governance involving a multistage approach to managing health data, ethical artificial intelligence, generative artificial intelligence and classification of types of AI by considering the degree of risk (e.g. artificial intelligence systems with limited risk and systems with high risk) and medical devices. It outlines the legal framework for AI regulation and governance in the EU by focusing on compliance with the previously adopted legislation in the Medical Devices Regulation (2017) and the In-Vitro Diagnostic Regulation (2017). The paper also examines the application of the newly adopted EU Artificial Intelligence Act in relation to national justice systems, previous EU regulations on medical devices and personal data protection regulation, and its correlation with the European Court of Human Rights jurisprudence. This opens up complex discussions related to judicial reform and access to justice. For this purpose, as a research objective, the legal analysis includes an innovative perspective following an integrative discussion on the latest legal reforms and regulations of the AI sector in Eastern Europe launched in 2024 with a special focus on the latest developments in the EU Candidate Countries namely Ukraine and the Republic of Moldova. Results and conclusions: The present research facilitates the exploration of the real benefits of managing innovative AI systems for medical data, research, and development, as well as within the medical technology industry.
AD  - Univ Craiova, Fac Social Sci, Dept Hist Polit Sci & Int Relat, Craiova, RomaniaAD  - Univ Craiova, Dept Biol & Environm Engn, Craiova, RomaniaC3  - University of CraiovaC3  - University of CraiovaPU  - EAST EUROPEAN LAW RESEARCH CENTER
PI  - KYIV
PA  - BANDERY STEPANA STR., 20A, KYIV, 04655, UKRAINE
SN  - 2663-0575
SN  - 2663-0583
J9  - ACCESS JUSTICE E EUR
JI  - Access Justice East Eur.
DA  - 2024 SEP 2
PY  - 2024
DO  - 10.33327/AJEE-18-7.4-a000103
C6  - SEP 2024
WE  - Emerging Sources Citation Index (ESCI)AN  - WOS:001304269100001
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  27
ER  -

TY  - JOUR
AU  - Mrcela, M
AU  - Vuletic, I
TI  - RETHINKING THE PRIVILEGE AGAINST SELF-INCRIMINATION IN TERMS OF EMERGING NEURO-TECHNOLOGY: COMPARING THE EUROPEAN AND UNITED STATES PERSPECTIVE
T2  - CROATIAN YEARBOOK OF EUROPEAN LAW & POLICY
LA  - English
KW  - lie detector
KW  - fair trial
KW  - self-incrimination
KW  - truth
KW  - evidence
KW  - testimonial
KW  - artificial intelligence
KW  - neuroscience
KW  - LIE-DETECTOR
KW  - TRIALS
AB  - This paper analyses new fact-finding methods in criminal proceedings, using state-of-the-art innovations in neuroscience and artificial intelligence (AI). It will outline the existing methods and explain their effects. Then it will address the criminal-law aspects of the use of such methods as evidence in criminal proceedings, with an emphasis on the assessment of their admissibility from the perspective of the right to a fair trial and the privilege against self-incrimination. This topic will be observed from the perspective of US and European law, highlighting the existing jurisprudence of the European Court of Human Rights (ECtHR) and the legal standards established by the court in relation to the privilege against self-incrimination. Based on this analysis, the authors will formulate a conclusion suggesting that the use of current AI technologies should be juxtaposed to the relevant benchmark of the privilege against self-incrimination as the requisite standard of the right to a fair trial.
AD  - Justice Supreme Court Republ Croatia, Zagreb, CroatiaAD  - JJ Strossmayer Univ Osijek, Criminal Law, Osijek, CroatiaC3  - University of JJ Strossmayer OsijekPU  - UNIV ZAGREB, FAC LAW
PI  - ZAGREB
PA  - TRG MARSALA TITA 14, ZAGREB, 10000, CROATIA
SN  - 1845-5662
J9  - CROAT YEARB EUR LAW
JI  - Croat. Yearb. EUr. Law Policy
PY  - 2023
VL  - 19
SP  - 206
EP  - 223
DO  - 10.3935/cyelp.19.2023.504
WE  - Emerging Sources Citation Index (ESCI)AN  - WOS:001144675100001
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  60
ER  -

TY  - JOUR
AU  - Paget, A
TI  - (SYNTHETIC) STUMP SPEECH: CRAFTING GENERATIVE AI DISCLOSURE REGULATIONS FOR POLITICAL ADVERTISEMENTS
T2  - FORDHAM LAW REVIEW
LA  - English
KW  - DEMOCRACY
AB  - Synthetic media, or content generated using artificial intelligence, has begun to infect political advertising. Federal legislation has spent most of its time stalled in committees, but states and online platforms have rapidly implemented regulations. Although synthetic media may pose harms through voter manipulation and democratic distortion, it also can lower campaign costs and more vividly illustrate conceptions of a political choice's consequences. Some governments and commentators have sought to prohibit the most harmful forms, while others have focused more on transparent approaches to regulation. In the face of yet another contentious election cycle, the question of how to ensure choices are made based on belief and not manipulation looms large. This Note assesses the current regulatory landscape for synthetic media in political advertising to analyze the benefits and drawbacks of greater regulation. Based on current and emerging regulatory approaches, this Note examines how governments and private actors have limited synthetic media usage within existing First Amendment jurisprudence. Although initial prohibitions served a necessary role, this Note proposes that transparency enforcement is the best approach and should be built upon by creating a repository that contains information on an advertisement's synthetic content.
AD  - Fordham Univ, Sch Law, New York, NY 10023 USAC3  - Fordham UniversityPU  - FORDHAM UNIV, SCHOOL LAW
PI  - NEW YORK
PA  - 140 W 62ND STREET, NEW YORK, NY 10023 USA
SN  - 0015-704X
J9  - FORDHAM LAW REV
JI  - Fordham Law Rev.
DA  - OCT
PY  - 2024
VL  - 93
IS  - 1
SP  - 321
EP  - 358
WE  - Social Science Citation Index (SSCI)AN  - WOS:001328710900008
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  126
ER  -

TY  - JOUR
AU  - Chucha, SY
TI  - ARTIFICIAL INTELLIGENCE IN JUSTICE: LEGAL AND PSYCHOLOGICAL ASPECTS OF LAW ENFORCEMENT
T2  - PRAVOPRIMENENIE-LAW ENFORCEMENT REVIEW
LA  - English
KW  - Artificial intelligence (AI)
KW  - concept
KW  - justice
KW  - law enforcement
KW  - efficiency
KW  - legal psychology
KW  - labor activity
KW  - remote work
KW  - corporate governance
KW  - SYSTEM
AB  - The subject. Artificial intelligence is considered as an interdisciplinary legal and psychologi-cal phenomenon. The special need to strengthen the psychological component in legal re-search of artificial intelligence and its introduction into the practice of law enforcement and justice, in particular, is substantiated.The main goal of the study is to confirm or refute hypothesis that AI may be implemented in justice and to substantiate the legal limits of such implementation.The methodology. Based on the comparison of the current legislation, the practice of its application, and other empirical data, internal and external legal and psychological factors of legal regulation and the use of artificial intelligence in jurisprudence and judicial proceed-ings are identified.The main results, scope of application. The analysis of legal and doctrinal definitions of ar-tificial intelligence in jurisprudence has shown that their defining and integral part is rela-tionships that are the result of psychological practices and the subject of psychological sci-ence (internal factors). Legal studies of artificial intelligence are based on a psychological conceptual apparatus, all of them legally describe artificial intelligence, first of all, as a psy-chological phenomenon and build an analogy between the psychology of a living intelligent subject and an inanimate object, humanizing the latter. The federal legislator is also follow-ing the path of using the psychological conceptual apparatus. Such categories like human cognitive functions and intellectual activity are applied in Russian Federal Law "On conduct-ing an experiment to establish special regulation in order to create the necessary conditions for the development and implementation of artificial intelligence technologies in the sub-ject of the Russian Federation -the federal city of Moscow and amending Articles 6 and 10 of the Federal Law "On Personal Data". The legal and psychological analysis of the practice of using elements of artificial intelligence in corporate governance, justice, labor relations, social insurance, electoral procedures has been subjected.The conclusion is substantiated that an indispensable condition for the introduction of arti-ficial intelligence and its elements into justice is trust on the part of the disputing parties and the court. Such trust is provided with a real possibility of verifying the actions and de-cisions made with artificial intelligence by psychologically acceptable and legally formalized methods (external factors). The use of artificial intelligence in law enforcement in general and justice in particular is possible in two directions: (1) solving problems related to the approximation of specialized artificial intelligence systems in legal proceedings to human capabilities and their integration to enhance intelligence; (2) creating artificial intelligence, which is the integration of already created elements of artificial intelligence into a single system capable of participating in justice, but does not have the properties of free will and does not acquire legal personality. Law enforcement using artificial intelligence should com-ply with the principles enshrined in the European Ethical Charter on the Use of Artificial Intelligence in Judicial Systems and their environment, the provisions of which should be implemented in domestic legislation, having previously been revised in accordance with the national legal tradition.
AD  - Russian Acad Sci, Inst State & Law, Moscow, RussiaC3  - Russian Academy of SciencesC3  - Institute of State & Law of the Russian Academy of SciencesPU  - DOSTOEVSKY OMSK STATE UNIV
PI  - OMSK
PA  - PROSPEKT MIRA 55-A, OMSK, 644077, RUSSIA
SN  - 2542-1514
SN  - 2658-4050
J9  - PRAVOPRIMENENIE-LAW
JI  - Pravoprimenenie-Law Enforc. Rev.
PY  - 2023
VL  - 7
IS  - 2
SP  - 116
EP  - 124
DO  - 10.52468/2542-1514.2023.7(2).116-124
WE  - Emerging Sources Citation Index (ESCI)AN  - WOS:001027805400012
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  28
ER  -

TY  - JOUR
AU  - Vuletic, I
TI  - Corporate Criminal Liability: An Overview of the Croatian Model after 20 Years of Practice
T2  - LAWS
LA  - English
KW  - sanction
KW  - guilt
KW  - artificial intelligence
KW  - corporation
KW  - culpability
AB  - The Croatian legislators introduced the concept of criminal liability for legal entities already in 2003 with the adoption of the Law on Criminal Liability of Legal Entities. Influenced by the writing of esteemed domestic scholars, and inspired by French law, the legislators opted for a system linking the liability of corporations to the liability of the responsible person. There were very few cases in practice during the first years of its application, and the situation changed after the first prominent indictment of this type against the ruling political party for economic crimes. Since then, the legislation has been amended several times and a significant body of jurisprudence has developed. In the first part of this paper, I will describe the chronology of the development and formation of the Croatian legislative model of corporate criminal liability. The second part will analyze 31 available final court judgments, which will be the basis for the conclusion about the issues in the practical application of the legislative model and, more generally, the phenomenon of criminal offenses committed by legal entities in Croatia. Based on this analysis, I will indicate the potential deficiencies of such a concept. In the context of future development, special attention will be given to the problem of economic crimes committed by AI corporate systems.
AD  - Josip Juraj Strossmayer Univ Osijek, Fac Law, Osijek 31000, CroatiaC3  - University of JJ Strossmayer OsijekPU  - MDPI
PI  - BASEL
PA  - ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND
SN  - 2075-471X
J9  - LAWS-BASEL
JI  - Laws
DA  - APR
PY  - 2023
VL  - 12
IS  - 2
C7  - 27
DO  - 10.3390/laws12020027
WE  - Emerging Sources Citation Index (ESCI)AN  - WOS:000977697000001
N1  - Times Cited in Web of Science Core Collection:  0
Total Times Cited:  0
Cited Reference Count:  25
ER  -

TY  - JOUR
AU  - Wachter, S
AU  - Mittelstadt, B
AU  - Russell, C
TI  - Why fairness cannot be automated: Bridging the gap between EU non-discrimination law and AI
T2  - COMPUTER LAW & SECURITY REVIEW
LA  - English
KW  - European union
KW  - Non-discrimination
KW  - Fairness
KW  - Discrimination
KW  - Bias
KW  - Algorithm
KW  - Law
KW  - Demographic&nbsp
KW  - parity
KW  - Machine learning
KW  - Artificial intelligence
KW  - BIG DATA
KW  - DISCRIMINATION
KW  - BIAS
KW  - ETHICS
KW  - IMPACT
AB  - In recent years a substantial literature has emerged concerning bias, discrimination, and fairness in artificial intelligence (AI) and machine learning. Connecting this work to existing legal non-discrimination frameworks is essential to create tools and methods that are practically useful across divergent legal regimes. While much work has been undertaken from an American legal perspective, comparatively little has mapped the effects and requirements of EU law. This Article addresses this critical gap between legal, technical, and organisational notions of algorithmic fairness. Through analysis of EU non-discrimination law and jurisprudence of the European Court of Justice (ECJ) and national courts, we identify a critical incompatibility between European notions of discrimination and existing work on algorithmic and automated fairness. A clear gap exists between statistical measures of fairness as embedded in myriad fairness toolkits and governance mechanisms and the context-sensitive, often intuitive and ambiguous discrimination metrics and evidential requirements used by the ECJ; we refer to this approach as "contextual equality." This Article makes three contributions. First, we review the evidential requirements to bring a claim under EU non-discrimination law. Due to the disparate nature of algorithmic and human discrimination, the EU's current requirements are too contextual, reliant on intuition, and open to judicial interpretation to be automated. Many of the concepts fundamental to bringing a claim, such as the composition of the disadvantaged and advantaged group, the severity and type of harm suffered, and requirements for the relevance and admissibility of evidence, require normative or political choices to be made by the judiciary on a caseby-case basis. We show that automating fairness or non-discrimination in Europe may be impossible because the law, by design, does not provide a static or homogenous framework suited to testing for discrimination in AI systems. Second, we show how the legal protection offered by non-discrimination law is challenged when AI, not humans, discriminate. Humans discriminate due to negative attitudes (e.g. stereotypes, prejudice) and unintentional biases (e.g. organisational practices or internalised stereotypes) which can act as a signal to victims that discrimination has occurred. Equivalent signalling mechanisms and agency do not exist in algorithmic systems. Compared to traditional forms of discrimination, automated discrimination is more abstract and unintuitive, subtle, intangible, and difficult to detect. The increasing use of algorithms disrupts traditional legal remedies and procedures for detection, investigation, prevention, and correction of discrimination which have predominantly relied upon intuition. Consistent assessment procedures that define a common standard for statistical evidence to detect and assess prima facie automated discrimination are urgently needed to support judges, regulators, system controllers and developers, and claimants. Finally, we examine how existing work on fairness in machine learning lines up with procedures for assessing cases under EU non-discrimination law. A 'gold standard' for assessment of prima facie discrimination has been advanced by the European Court of Justice but not yet translated into standard assessment procedures for automated discrimination. We propose 'conditional demographic disparity' (CDD) as a standard baseline statistical measurement that aligns with the Court's 'gold standard'.
   Establishing a standard set of statistical evidence for automated discrimination cases can help ensure consistent procedures for assessment, but not judicial interpretation, of cases involving AI and automated systems. Through this proposal for procedural regularity in the identification and assessment of automated discrimination, we clarify how to build considerations of fairness into automated systems as far as possible while still respecting and enabling the contextual approach to judicial interpretation practiced under EU non-discrimination law.
AD  - Univ Oxford, Oxford Internet Inst, 1St Giles, Oxford OX1 3JS, EnglandAD  - Harvard Univ, Harvard Law Sch, Cambridge, MA 02138 USAAD  - British Lib, Alan Turing Inst, 96 Euston Rd, London NW1 2DB, EnglandAD  - Univ Surrey, Dept Elect & Elect Engn, Guildford GU2 7HX, Surrey, EnglandAD  - Amazon, Paul Ehrlich Str, Tubingen, GermanyC3  - University of OxfordC3  - Harvard UniversityC3  - University of SurreyC3  - Amazon.comFU  - EPSRC [EP/N510129/1] Funding Source: UKRI
PU  - ELSEVIER ADVANCED TECHNOLOGY
PI  - OXFORD
PA  - OXFORD FULFILLMENT CENTRE THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN  - 0267-3649
J9  - COMPUT LAW SECUR REV
JI  - Comput. Law Secur. Rev.
DA  - JUL
PY  - 2021
VL  - 41
C7  - 105567
DO  - 10.1016/j.clsr.2021.105567
C6  - JUN 2021
WE  - Social Science Citation Index (SSCI)AN  - WOS:000685463100019
N1  - Times Cited in Web of Science Core Collection:  124
Total Times Cited:  126
Cited Reference Count:  126
ER  -

