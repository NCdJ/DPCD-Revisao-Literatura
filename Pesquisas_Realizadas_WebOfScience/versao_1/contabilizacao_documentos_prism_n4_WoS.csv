"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"7RTK7DAH","journalArticle","2023","Chen, SS","THE DAWN OF AI GENERATED CONTENTS: REVISITING COMPULSORY MEDIATION AND IP DISPUTES RESOLUTION","CONTEMPORARY ASIA ARBITRATION JOURNAL","","1999-9747","","","With the popularity of generative artificial intelligence (hereinafter ""AI""), current intellectual property laws are being greatly challenged and the established doctrines redefined. As different jurisdictions are in the process of ""catching up"" to the technology, this paper argues that compulsory mediation, as an alternate dispute resolution, has the potential to address legal uncertainties. The flexible and informal nature of the compulsory mediation process makes a suitable environment for all stakeholders involved, the right owners, the creators, and the users of the AI, to come to an agreement, thus lessening the impact such new invention brings to domestic legal framework. Moreover, by looking into compulsory mediations in Taiwan, the Philippines, and Turkey, this paper hopes to outline key factors for compulsory mediation to properly tackle the subject of intellectual property disputes of AI nature.","2023","2024-10-27 16:07:35","2024-10-27 16:30:54","","301-331","","2","16","","","","","","","","","","English","","","","WOS:001111303600004","","","","","","","AI; AIgenerated content; Alternate dispute resolution; artificial intelligence; compulsory mediation; deficiency in law; intellectual property; IP infringement through AI; IP protection; machine learning; machine learning data; natural language processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TEGK8I5F","journalArticle","2024","Hacker, P; Cordes, J; Rochon, J","Regulating Gatekeeper Artificial Intelligence and Data: Transparency, Access and Fairness under the Digital Markets Act, the General Data Protection Regulation and Beyond","EUROPEAN JOURNAL OF RISK REGULATION","","1867-299X","10.1017/err.2023.81","","Artificial intelligence (AI) is not only increasingly being used in business and administration contexts, but a race for its regulation is also underway, with the European Union (EU) spearheading the efforts. Contrary to existing literature, this article suggests that the most far-reaching and effective EU rules for AI applications in the digital economy will not be contained in the proposed AI Act, but in the Digital Markets Act (DMA). We analyse the impact of the DMA and related EU acts on AI models and underlying data across four key areas: disclosure requirements; the regulation of AI training data; access rules; and the regime for fair rankings. We demonstrate that fairness, under the DMA, goes beyond traditionally protected categories of non-discrimination law on which scholarship at the intersection of AI and law has focused on. Rather, we draw on competition law and the FRAND criteria known from intellectual property law to interpret and refine the DMA provisions on fair rankings. Moreover, we show how, based on Court of Justice of the European Union jurisprudence, a coherent interpretation of the concept of non-discrimination in both traditional non-discrimination and competition law may be found. The final section sketches out proposals for a comprehensive framework of transparency, access and fairness under the DMA and beyond.","2024-03","2024-10-27 16:07:55","2024-10-27 16:30:50","","49-86","","1","15","","","","","","","","","","English","","","","WOS:001125220300001","","","","","","","AI; AUTOMATED DECISION-MAKING; data; DISCRIMINATION; DMA; INNOVATION EVIDENCE; TRADE SECRETS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MUUSD3NR","journalArticle","2023","Yao, L","Specifics of Regulatory and Legal Regulation of Generative Artificial Intelligence in the UK, USA, EU and China","PRAVO-ZHURNAL VYSSHEI SHKOLY EKONOMIKI","","2072-8166","10.17323/2072-8166.2023.3.245.267","","On November 30, 2022, OpenAI launched ChatGPT conversational artificial intelligence; with the latest version update, ChatGPT has demonstrated an impressive ability to understand natural language, making it an attractive tool for companies and individuals looking to provide customer service and support. GPT-3 uses textual data, mostly from publicly available information on the Internet, as training data. GPT-4, on the other hand, uses a large number of images in addition to textual data for training, and thus can process both textual and graphical data. The emergence of generative AI has greatly impacted human life, but it can be said that intelligent technology is a double-edged sword:rapid development of generative artificial intelligence (AI) technologies, on the one hand, it can improve efficiency and productivity, reduce costs and open new opportunities for economic growth, but on the other hand, the use of generative AI services to create synthetic content in the form of text, audio, video and images poses possible risks. To date, different regions around the world are at different stages of development of normative acts concerning generative AI.Using the comparative legal method and the method of system analysis, this article analyzes in detail the main models of legal regulation of generative AI in the modern world on the example of the UK, the USA, the European Union and China, noting the different approach in the development and adoption of relevant normative legal acts in the field of regulation of generative AI services.It especially reveals the Chinese government's position on ""development and security"" and ""innovation and governance"" at present. The main trends of improving the regulation of generative AI services by China are proposed, and it is concluded that it is necessary to balance ""rule of law"" and ""innovation"" and promote the healthy development of generative AI.","2023","2024-10-27 16:12:06","2024-10-27 16:30:52","","245-267","","3","","","","","","","","","","","Russian","","","","WOS:001083415400011","","","","","","","Chat Generative Pre-TrainedTransformer, risks; foreign experience; Generative AI; innovations; regulation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y5URTEIU","conferencePaper","2024","Varma, S; Shivam, S; Natarajan, S; Biswas, S; Gupta, J","Taking Natural Language Generation and Information Extraction to Domain Specific Tasks","","2367-3370","","10.1007/978-3-031-47715-7_48","","A lot of domain-specific unstructured data is available at present. To make them available to common users, domain experts often have to extract the key points and convert them to layman's terms manually. For domains like legal, documents are often needed to be manually analyzed in order to check if all the critical information is present in them and to extract the important points if needed. All these manual domain-specific tasks can be automated with the help of different Natural Language Processing (NLP) and Natural Language Generation (NLG) techniques. In this paper, some of the tools in NLP and NLG that can be used to automate the above-mentioned processes for key information extraction are discussed. We also bring forth two such domain-specific use cases where we attempt to provide suggestions to the subject experts to make their tasks easier using the tools discussed.","2024","2024-10-27 16:13:49","2024-10-27 16:13:49","","713-728","","","824","","","","","","","","","","English","","","","WOS:001261693800048","","","","","","","Text summarization; Named entity recognition; Content automation; Custom rule-based parsing; Domain tasks; Information extraction; NAMED ENTITY RECOGNITION; Natural language generation; Text simplification","","Arai, K","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","INTELLIGENT SYSTEMS AND APPLICATIONS, VOL 3, INTELLISYS 2023","","","","","","","","","","","","","","",""
"I48F535F","journalArticle","2024","Herbosch, M","Fraud by generative AI chatbots: On the thin line between deception and negligence","COMPUTER LAW & SECURITY REVIEW","","0267-3649","10.1016/j.clsr.2024.105941","","The use of generative AI systems is on the rise. As a result, we are increasingly often conversing with AI chatbots rather than with fellow humans. This increasing use of AI systems leads to legal challenges as well, particularly when the chatbot provides incorrect information. In this article, we study whether someone who decides to contract on the basis of incorrect information provided by a generative AI chatbot might invoke the fraud regime to annul the resulting contract in various legal systems. During this analysis, it becomes clear that some of the requirements that are currently being put forward from a public law perspective, such as in the European AI Act, may also naturally arise from existing private law figures. In the same vein, this analysis highlights the interesting intradisciplinary feedback between instruments of public law and other legal domains.","2024-04","2024-10-27 16:14:03","2024-10-27 16:30:31","","","","","52","","","","","","","","","","English","","","","WOS:001178316700001","","","","","","","Artificial intelligence; BLACK-BOX; Contract law; Fraud; Law of obligations; Vice of consent","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H6NG6DL3","journalArticle","2024","Mattalo, B","Artificial Intelligence: The Future of Pedagogy","JOURNAL OF LEGAL STUDIES EDUCATION","","0896-5811","10.1111/jlse.12146","","While it is important to research the negative impact of generative artificial intelligence on academic integrity, academics should focus most of their efforts on the opportunities these technologies present for improving pedagogical practices. In this note, I attempt to flip the narrative from one of fear to one of opportunity. I suggest that academics should research the use of generative AI to improve teaching effectiveness and efficiency. I offer various practical suggestions on how these tools can be used to advance pedagogical practices, with specific business law examples.","2024-12","2024-10-27 16:14:03","2024-10-27 16:14:03","","49-71","","1","41","","","","","","","","","","English","","","","WOS:001154667400001","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2TXP33U3","journalArticle","2024","Migliorini, S","""More than Words"": A Legal Approach to the Risks of Commercial Chatbots Powered by Generative Artificial Intelligence","EUROPEAN JOURNAL OF RISK REGULATION","","1867-299X","10.1017/err.2024.4","","The recent commercial release of a new generation of chatbot systems, particularly those leveraging Transformer-based large language models (LLMs) such as ChatGPT, has caught the world by surprise and sparked debate about their potential consequences for society. While concerns about the existential threat posed by these technologies are often discussed, it is crucial to shift our focus towards the more immediate risks associated with their deployment. Such risks are further compounded by the lack of proactive measures addressing users' literacy and the for-profit model via which these chatbots are distributed. Drawing on research in computer science and other fields, this paper looks at the immediate risks triggered by these products and reflects on the role of law within a broader policy directed at steering generative artificial intelligence technology towards the common good. It also reviews the relevant amendments proposed by the European Parliament to the European Commission's proposal for an AI Act.","2024-02-29","2024-10-27 16:14:04","2024-10-27 16:14:04","","","","","","","","","","","","","","","English","","","","WOS:001173990200001","","","","","","","foundation models; Artificial intelligence; EU AI Act; generative AI; regulation of emerging technology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HYJJBABY","journalArticle","2024","Oh, E","Admitting AI Art as Demonstrative Evidence","CALIFORNIA LAW REVIEW","","0008-1221","","","Images and animations created through generative artificial intelligence (GAI) pose new possibilities and questions for the law of demonstrative evidence. AI art tools may allow parties to prepare pedagogical displays-including hyper-realistic virtual imagery- without retaining expensive third-party artists. But these programs raise evidentiary concerns such as reliability and undue prejudice, issues that remain largely unaddressed under the notoriously undeveloped law governing computer-made demonstratives. This Note explains both how artificial intelligence companies could institute initiatives for better quality assurance at the front end, and how courts can encourage such measures through new applications of existing evidentiary and procedural rules. The Note ultimately argues that the emerging use of GAI imagery may necessitate stricter standards in demonstrative evidence law.","2024-08","2024-10-27 16:14:04","2024-10-27 16:14:04","","1501-1533","","","112","","","","","","","","","","English","","","","WOS:001318203100006","","","","","","","COMPUTER-ART; INTELLIGENCE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BSKRI7BK","journalArticle","2023","Magowan, J","""It's Like I've Got This Music in My Mind"":1 Protecting Human Authorship in the Age of Generative Artificial Intelligence","HASTINGS LAW JOURNAL","","0017-8322","","","The music industry stands on the brink of a crisis. With unpredictable judicial standards that are inconsistent across the country, plaintiffs seeking to protect their musical works against copyright infringement face a heavy burden of proof, especially when facing defendants who are more wellknown and more well-funded. Not only that, but plaintiffs may not receive their day in court given that powerhouse artists like Taylor Swift, Sam Smith, and Bruno Mars have chosen to settle rather than defend their musical works in court. Now, Generative Artificial Intelligence (""Generative A.I."") and A.I.-generated music will inevitably send the music industry into a tailspin-and the law is not ready to grapple with the complexities that will arise. To wit, Generative A.I. is poised to threaten the very principles on which copyright law is founded: To encourage (human) creativity by protecting original works of expression. This Note seeks to protect human music copyright holders against the ever-growing threat of A.I.-generated music. Part I addresses A.I. technology and the legal uncertainties associated with A.I.-generated music. Part II discusses the current doctrine of music copyright infringement. Part III offers a series of proposals for how to adapt the current doctrine to ensure music copyright holders can protect their original works of human authorship against A.I.-generated works.","2023-12","2024-10-27 16:14:04","2024-10-27 16:14:04","","","","1","75","","","","","","","","","","English","","","","WOS:001183218800003","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9NNS5VIX","journalArticle","2023","Chan, E; Gore, KN; Jiang, E","HARNESSING ARTIFICIAL INTELLIGENCE IN INTERNATIONAL ARBITRATION PRACTICE","CONTEMPORARY ASIA ARBITRATION JOURNAL","","1999-9747","","","Since the beginning of 2023, generative artificial intelligence (hereinafter ""Generative AI"") in the form of large language models (LLMs) like ChatGPT-4 has taken the world by storm. Legal practice is no exception. Among other stories, worldwide headlines have featured the fact that ChatGPT-4 is capable of passing the New York Bar Exam, that courts are adopting Generative AI in their decision-making, and that a New York lawyer has been sanctioned by a judge for relying upon non-existent case law precedent that he obtained from ChatGPT-4 and did not double-check. Yet, putting aside these newsworthy developments, tools powered by other forms of artificial intelligence (hereinafter ""AI"") have already been relied upon in legal practice for many years. This article introduces how AI supports successful international arbitration practice, including uses and methods that are already available and those that are anticipated to become helpful. This article also addresses the challenges and pitfalls that accompany these opportunities. Overall, this article concludes that the brave new world of AI in international arbitration is an exciting one that, through careful and thoughtful deployment of best practices, can add significant value to international arbitration teams in the decades to come.","2023","2024-10-27 16:14:04","2024-10-27 16:14:04","","263-299","","2","16","","","","","","","","","","English","","","","WOS:001111303600003","","","","","","","artificial intelligence practical applications in arbitration; artificial intelligence regulation in arbitration; artificially intelligent legal technology use cases in arbitration; future applications of artificial intelligence in arbitration practice; generative artificial intelligence in arbitration; large language models' use in arbitration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A9MT2FIU","journalArticle","2024","Head, A; Willis, S","Assessing law students in a GenAI world to create knowledgeable future lawyers","INTERNATIONAL JOURNAL OF THE LEGAL PROFESSION","","0969-5958","10.1080/09695958.2024.2379785","","Assessing law students has always been a challenging task, but the introduction of Generative Artificial Intelligence (GenAI), such as ChatGPT, compounds the problems already caused by increased student numbers, contract cheating and budget cuts in universities. As GenAI rapidly develops, legal educators must find ways to accommodate, and even incorporate, GenAI into their curricula and assessments so that law graduates can understand its capabilities and limitations within legal practice. Simultaneously, many jurisdictions, including Australia, have legislative obligations to deliver law graduates who satisfy legal knowledge-based ""eligibility"" requirements for admission into practice. This article introduces a knowledge framework for managing GenAI in legal education consisting of three pillars: Substantive Legal Knowledge, GenAI Ethics Knowledge, and GenAI System Knowledge. The authors argue this framework can assist legal educators in designing optimal assessments in an AI-disrupted world. The article employs the knowledge framework to examine the experiences and views of Australian law students' engagement with GenAI outputs in completing a compulsory legal ethics assessment in 2023. This empirical case study demonstrates that effective assessment design incorporating GenAI can enhance law student and graduate outcomes despite the ongoing challenges for legal educators and the profession associated with GenAI.","2024-07-18","2024-10-27 16:14:04","2024-10-27 16:14:04","","","","","","","","","","","","","","","English","","","","WOS:001272888800001","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CMSWUTP3","journalArticle","2024","Carlini, G","RETHINKING THE PRESUMPTION OF ENABLEMENT IN NONPATENT PRIOR ART","DUKE LAW JOURNAL","","0012-7086","","","The rising popularity of tools such as preprint servers, open-access data sources, and generative artificial intelligence has resulted in a proliferation of prior art that has never been seen before under the current patent system. In a rapidly changing world, patent law is slow to catch up, and the current system is not equipped to handle the flood of incoming prior art. In the academic research setting in particular, while the use of preprint servers and open-source data has allowed researchers to participate in widespread information exchange, these tools have also generated a new, large class of prior art dedicated to early-stage research. This creates a tension with patent law, which assigns a presumption of enablement to nonpatent prior art, including preprint disclosures. Essentially, the law presumes that any public disclosure of an invention contains enough detail to instruct the public to make and use it. Thus, any public disclosure ""starts the clock"" on an applicant's time to get to the patent office. This Note explores how that presumption artificially incentivizes premature patent filing, decreasing the overall quality of patents entering the patent system.","2024-01","2024-10-27 16:14:04","2024-10-27 16:14:04","","871-904","","4","73","","","","","","","","","","English","","","","WOS:001131880000002","","","","","","","INFORMATION; PATENTS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5Q6EYJ9Z","conferencePaper","2023","Nguyen, HT; Goebel, R; Toni, F; Stathis, K; Satoh, K","LawGiBa - Combining GPT, Knowledge Bases, and Logic Programming in a Legal Assistance System","Research Organization of Information & Systems (ROIS)","0922-6389","","10.3233/FAIA230991","","We present LawGiBa, a proof-of-concept demonstration system for legal assistance that combines GPT, legal knowledge bases, and Prolog's logic programming structure to provide explanations for legal queries. This novel combination effectively and feasibly addresses the hallucination issue of large language models (LLMs) in critical domains, such as law. Through this system, we demonstrate how incorporating a legal knowledge base and logical reasoning can enhance the accuracy and reliability of legal advice provided by AI models like GPT. Though our work is primarily a demonstration, it provides a framework to explore how knowledge bases and logic programming structures can be further integrated with generative AI systems, to achieve improved results across various natural languages and legal systems.","2023","2024-10-27 16:14:04","2024-10-27 16:30:35","","371-374","","","379","","","","","","","","","","English","","","","WOS:001175464100050","","","","","","","ChatGPT; interactive demonstration; knowledge base; legal advice; logic programming; Prolog","","Spanakis, J; VanDijck, G; Sileno, G","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","LEGAL KNOWLEDGE AND INFORMATION SYSTEMS","","","","","","","","","","","","","","",""
"SQH7L3FU","journalArticle","2023","Navarro-Dolmestch, R","Risks and Challenges Posed by Artificial Intelligence Generative Applications for Academic Integrity","DERECHO PUCP","","0251-3420","10.18800/derechopucp.202302.007","","From the perspective of a descriptive analysis, and as a starting point to a new research line, this paper examines the potential impact Generative Artificial Intelligence (GAI) technologies may have on academic integrity, manifested in the learning and evaluation processes of law classes at the university level. The article takes as its premise the definition of academic integrity as a set of values and argues that a series of risks arise from the GAI that threaten those values, such as excessive dependence and trust in the GAI, the unreallizability of the pedagogical project and the loss of competitiveness of educational institutions, among others. To minimize or nullify such risks, and thus prevent them from affecting academic integrity, four mitigation measures are identified to be applied in university environments.","2023-12","2024-10-27 16:14:04","2024-10-27 16:14:04","","231-270","","91","","","","","","","","","","","English","","","","WOS:001146757500011","","","","","","","artificial intelligence; ETHICS; chatbot; ChatGPT; Academic integrity; automatic text generation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G9W9HCCU","journalArticle","2024","Schweitzer, S; Conrads, M","The digital transformation of jurisprudence: an evaluation of ChatGPT-4's applicability to solve cases in business law","ARTIFICIAL INTELLIGENCE AND LAW","","0924-8463","10.1007/s10506-024-09406-w","","In the evolving landscape of legal information systems, ChatGPT-4 and other advanced conversational agents (CAs) offer the potential to disruptively transform the law industry. This study evaluates commercially available CAs within the German legal context, thereby assessing the generalizability of previous U.S.-based findings. Employing a unique corpus of 200 distinct legal tasks, ChatGPT-4 was benchmarked against Google Bard, Google Gemini, and its predecessor, ChatGPT-3.5. Human-expert and automated assessments of 4000 CA-generated responses reveal ChatGPT-4 to be the first CA to surpass the threshold of solving realistic legal tasks and passing a German business law exam. While ChatGPT-4 outperforms ChatGPT-3.5, Google Bard, and Google Gemini in both consistency and quality, the results demonstrate a considerable degree of variability, especially in complex cases with no predefined response options. Based on these findings, legal professionals should manually verify all texts produced by CAs before use. Novices must exercise caution with CA-generated legal advice, given the expertise needed for its assessment.","2024-07-01","2024-10-27 16:14:04","2024-10-27 16:14:04","","","","","","","","","","","","","","","English","","","","WOS:001259372900001","","","","","","","Large language models; Generative artificial intelligence; Chatbots; Conversational agents; Legal information systems; Performance assessment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DLCRLMSH","journalArticle","2024","Migliorini, S","China's ' s Interim Measures on generative AI: Origin, content and significance","COMPUTER LAW & SECURITY REVIEW","","0267-3649","10.1016/j.clsr.2024.105985","","On 15 August 2023, China's new rules on generative artificial intelligence (AI) entered into force. This article explores the underlying reasons and context for this rapid regulatory development. It argues that China's swift adoption of the Interim Measures on generative AI has been enabled by its traditional approach to digital policy, together with its renewed system of governance and the extensive work that Chinese regulators had conducted on AI ethics and relevant principles. The article also analyses some of the substantial rules laid down by the Interim Measures, offering scholars and policymakers working on generative AI regulation in other jurisdictions the possibility to engage with the solutions chosen by the Chinese regulators. To this end, the article brielfy presents key provisions regarding training data and IP rights; labelling of synthetic content; algorithm registration; accountability for content; and the applicability of existing laws to generative AI. It compares these aspects of the Interim Measures with examples from the European Union and the United States.","2024-07","2024-10-27 16:14:04","2024-10-27 16:14:04","","","","","53","","","","","","","","","","English","","","","WOS:001292877200001","","","","","","","Generative AI; China; Comparative AI law & policy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T6GQSAPH","journalArticle","2024","Khawaldeh, AM","Generative AI Hallucinations and Legal Liability in Jordanian Civil Courts: Promoting the Responsible Use of Conversational Chat Bots","INTERNATIONAL JOURNAL FOR THE SEMIOTICS OF LAW-REVUE INTERNATIONALE DE SEMIOTIQUE JURIDIQUE","","0952-8059","10.1007/s11196-024-10199-z","","Generative Artificial Intelligence (AI) tools produce hallucinations exposing developers and users to a myriad of liabilities in courts. Given the absence of strict laws and regulations structuring how Generative AI content interact with potential allegations of defamation, libel, and slander, judges and attorneys are left with the semiotics of the fragmented articles and rules in each system attempting to settle such cases. The endless interpretations of written and non-verbal signs in the law across the world constitutes a new realm for legal semiotics in the area of Generative AI and defamation. The present analysis examines existing civil liability articles in the Jordanian code to shed light on the litigation and defenses afforded in the defamation realm with respect to Generative AI content. The key finding is that like other countries, civil codes in Jordan are outdated concerning Generative AI content opening a plethora of liability scenarios in libel or slander cases. More importantly, the exercise of semiotic interpretation generates several defenses salvaging users and developers under strict sets of conditions. In sum, new amendments and updated legislative frameworks are needed to protect the healthy development of Generative AI while preserving citizens from damaging defamation, libel, and slander.","2024-09-19","2024-10-27 16:14:04","2024-10-27 16:14:04","","","","","","","","","","","","","","","English","","","","WOS:001316759400006","","","","","","","LAW; ARTIFICIAL-INTELLIGENCE; Generative AI; AGE; ARAB; Contracts; Duty of care; Jordan; Liability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PCB2DJU5","journalArticle","2024","Shih, S; Chang, ECR","THE APPLICATION OF AI IN ARBITRATION: HOW FAR AWAY ARE WE FROM AI ARBITRATORS?","CONTEMPORARY ASIA ARBITRATION JOURNAL","","1999-9747","","","With highly humanlike responding abilities enabled by generative artificial intelligence (hereinafter ""AI""), ChatGPT astonished the world instantly after its launch on November 30, 2022. As ChatGPT has demonstrated the capabilities of AI to analyze and solve complex tasks, we are one step closer to the point where AI will have the technological capability of serving as an arbitrator to analyze legal issues and apply the correct laws and rules to the facts. In light of the technological advancement of AI, instead of the previous question of whether AI will be able to serve as an arbitrator, the current question seems to be when AI will be able to serve as an arbitrator. This article discusses the potential of AI serving as arbitrators from both a technological and legal perspective. We find that AI technologies still have some way to go before reaching the maturity to serve as arbitrators. But even when AI reaches the required maturity, we believe whether AI can serve as an arbitrator will eventually depend on the public's trust in AI to make potentially life -changing decisions.","2024","2024-10-27 16:14:04","2024-10-27 16:14:04","","69-90","","1","17","","","","","","","","","","English","","","","WOS:001250310400003","","","","","","","ChatGPT; generative AI; arbitral award; arbitrator; New York Convention","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5XAP86V7","journalArticle","2023","Kahveci, ZU","Attribution problem of generative AI: a view from US copyright law","JOURNAL OF INTELLECTUAL PROPERTY LAW & PRACTICE","","1747-1532","10.1093/jiplp/jpad076","","center dot Three significant lawsuits concerning generative Artificial Intelligence (AI) were filed in the USA, starting the first wave of lawsuits against AI: (i) coders filed claims for the alleged use of their codes by OpenAI's CoPilot, (ii) visual artists filed claims against companies using Stable Diffusion and (iii) Getty Images filed claims against Stability AI, which uses Stable Diffusion. Following the lead of these lawsuits, copyright owners of literary works filed four other lawsuits against OpenAI, Meta and Alphabet (Google)'s large language models. All of these lawsuits are pending at the time of writing. center dot Among other things, plaintiffs filed claims challenging generative AI's lack of attribution to copyright owners of in-copyright works in its training data. As US copyright law does not protect moral rights strongly, a federal rule granting a right of attribution to all copyright owners does not exist. Yet, there are some provisions providing quasi-protection. Section 1202 of the Digital Millennium Copyright Act (DMCA) is one of them and protects copyright owners against removal/modification of the Copyright Management Information in connection with their works. center dot This article lays down the limitations of moral rights protection in the USA and demonstrates the difficulties faced by the plaintiffs of the pending lawsuits. The limitations of Section 1202 DMCA are explained to demonstrate its difference from a classic moral right of attribution. The outcomes of these lawsuits will be significant in building case law on generative AI for the first time in the USA. This article evaluates the benefits and disadvantages of courts' possible acceptance of plaintiffs' claims regarding attribution.","2023-11-22","2024-10-27 16:14:04","2024-10-27 16:14:04","","796-807","","11","18","","","","","","","","","","English","","","","WOS:001067646900001","","","","","","","PROPERTY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I8W25BFF","journalArticle","2024","Arnett, C","Dystopian Dreams, Utopian Nightmares: AI and the Permanence of Racism","GEORGETOWN LAW JOURNAL","","0016-8092","","","This Essay draws connections between Octavia Butler's Parable series ( Parable of the Sower and Parable of the Talents), ), HBO's Westworld, , and Derrick Bell's Faces at the Bottom of the Well: The Permanence of Racism to highlight how the reconfiguration and transmutation of race through technological change is facilitated by corresponding shifts in legal doctrine, theory, policy, and practice. It takes the overlapping threads from these three sources, which struggle with the idea of change within larger systems of unavoidable, repetitive destruction, and ties them to the law's role in helping to shield race through the storms of change by being similarly nimble, flexible, and perseverant. The Essay identifies a theme found in both the selected Afrofuturistic works and in tech-centered legal doctrine, regulation, and theory that illuminate the law's role in reconstituting the fraught relationship between race and technology: the promise of utopia. The Essay explores this concept in the context of emerging debates on the function, utility, and harm of generative artificial intelligence (AI), which has been promoted as the latest tool toward a transhumanist future devoid of the trappings of humanity's biggest flaws. It proposes four emanating values, Ustopia, Sankofa, Data Justice, and Data Power, which should help guide advocacy, policymaking, and resistance in an increasingly AI dominated future. It ultimately concludes that an Afrofuturistic lens is not only important for understanding the potential harms of AI and developing regulatory frameworks but also necessary for imagining how such technologies could serve the interests of radical Black futures. The Essay contributes to a burgeoning literature using Afrofuturism-which situates the Black struggle in persistent yet continuously changing structural disparities and power relations-as an important departure point for expressing data precarity and reimagining new modes of data protection.","2024-06","2024-10-27 16:14:04","2024-10-27 16:14:04","","1299-1342","","6","112","","","","","","","","","","English","","","","WOS:001322838000002","","","","","","","LAW; OLD","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RJKALKJT","journalArticle","2023","Srivastava, AK","Landscape of Indian Legal Research","KRYTYKA PRAWA-NIEZALEZNE STUDIA NAD PRAWEM","","2080-1084","10.7206/kp.2080-1084.617","","Francis Bacon says knowledge is power. The creation of knowledge and its dissemination largely depends on the creation of literary works. The great works of Shakespeare, da Vinci, Homer, Picasso, Milton, Tagore etc. have been a treasure trove of mankind. Human beings have enjoyed the work, been inspired by the work, taken joy and eternal bliss in such works. However, the creation of knowledge is dependent on pre-existing knowledge. Creators create a work which requires hard work, imagination, creativity and which is incentivised by recognition of their work. The legal order of a couth society affords protection to such a work by copyright law & fair use. Fair use allows a person to use a work by duly acknowledging and referencing the work. Issue of plagiarism and abuse of fair use was aggravated by human greed. The economic implication of copyright infringement aggravated the whole issue. Referencing turned into war. The Bluebook, the Maroonbook, the ALWD, the APA and OSCOLA citation styles engaged in some kind of a war. Reference management systems like Zotero, Endnote, Mendeley etc. just fanned the flame. Disruptive and generative artificial intelligence has created a serious challenge to academic research. In this paper, the author attempts to delve into the inter-linkage of academic writing, research, citation, copyright, referencing mechanism and plagiarism in contemporary society, and the aftermath of it. The author attempts to investigate the challenges of writing and the protection of works vis-a-vis referencing tools and techniques.","2023","2024-10-27 16:14:04","2024-10-27 16:14:04","","14-30","","3","15","","","","","","","","","","English","","","","WOS:001222883100004","","","","","","","academic integrity; citation; legal research; plagiarism; technology","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R78YNMTB","journalArticle","2024","Thongmeensuk, S","Rethinking copyright exceptions in the era of generative AI: Balancing innovation and intellectual property protection","JOURNAL OF WORLD INTELLECTUAL PROPERTY","","1422-2213","10.1111/jwip.12301","","Generative artificial intelligence (AI) systems, together with text and data mining (TDM), introduce complex challenges at the junction of data utilization and copyright laws. The inherent reliance of AI on large quantities of data, often encompassing copyrighted materials, results in multifaceted legal quandaries. Issues surface from the unfeasible task of securing permission from each copyright holder for AI training, further muddled by ambiguities in interpreting copyright laws and fair use provisions. Adding to the conundrum, the clandestine practices of data collection in proprietary AI systems obstruct copyright owners from detecting unauthorized use of their materials. The paper explores the exceptions to copyright laws for TDM in the European Union, the United Kingdom, and Japan, recognizing their crucial role in fostering AI development. The EU has a two-pronged approach under the Directive on Copyright in the Digital Single Market, with one exception catering specifically to research organizations, and another, more generalized one, that can be restricted by rightsholders. The UK allows noncommercial TDM research without infringement but rejected a broader copyright exception due to concerns from the creative sector. Japan has the broadest TDM exception globally, permitting the nonenjoyment use of works without permission, though this can potentially overlook the rights of copyright owners. Notably, the applicability of TDM exceptions to AI-produced copies remains unclear, creating potential legal challenges. Furthermore, an exploration of the fair use doctrine in the United States provides insight into its potential application in AI development. It focuses on the transformative aspect of usage and its impact on the original work's potential market. This exploration underscores the necessity for clear, practical guidelines. In response to these identified challenges, this paper proposes a hybrid model for TDM exceptions emerges, along with recommended specific mechanisms. The model divides exceptions into noncommercial and commercial uses, providing a nuanced solution to complex copyright issues in AI training. Recommendations incorporate mandatory exceptions for noncommercial uses, an opt-out clause for commercial uses, enhanced transparency measures, and a searchable portal for copyright owners. In conclusion, striking a delicate equilibrium between technological progress and the incentive for creative expression is of paramount importance. These suggested solutions aim to establish a harmonious foundation that nurtures innovation and creativity while honoring creators' rights, facilitating AI development, promoting transparency, and ensuring fair compensation for creators.","2024-07","2024-10-27 16:14:04","2024-10-27 16:14:04","","278-295","","2","27","","","","","","","","","","English","","","","WOS:001205221800001","","","","","","","generative AI; copyright infringement; fair use doctrine; text and data mining exception","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HGFDR7CE","journalArticle","2024","Dermawan, A","Text and data mining exceptions in the development of generative AI models: What the EU member states could learn from the Japanese ""nonenjoyment"" purposes?","JOURNAL OF WORLD INTELLECTUAL PROPERTY","","1422-2213","10.1111/jwip.12285","","The European Union (EU) text and data mining (TDM) provisions are a progressive move, but the horizon is still uncertain for both generative artificial intelligence (GenAI) models researchers and developers. This article suggests that to drive innovation and further the commitment to the digital single market, during the national implementation, EU Member States could consider taking the Japanese broad, all-encompassing and ""nonenjoyment-based"" TDM as an example. The Japanese ""nonenjoyment"" purposes, however, are not foreign to the European continental view of copyright. A similar concept can be found under the German concept of ""Freier Werkgenuss"" or enjoyment of the work. A flexible TDM exception built upon the German notion of nonenjoyment purposes could become an opening clause to foster innovation and creativity in the age of GenAI. Moreover, the article argues that an opening clause allowing TDM with ""nonenjoyment"" purposes could be permissible under the so-called three-step test. This article further suggests, if there is no political will to safeguard ""the right to read should be the right to mine"" and to provide a welcoming environment for GenAI researchers and developers, when shaping the legal interpretation through national case law, the EU Member States could consider the following: (1) advocate for 72 h of response if technological protection measures (TPMs) are preventing TDM, and (2) Robot Exclusion Standard (robot.txt) as a warning when TDM is not allowed on a website. It is now in the hands of the EU Member States, whether to protect the interests of rightholders or to create a balance between safeguarding ""the right to read should be the right to mine,"" protecting rightholders exclusivity, and creating a supportive environment for the GenAI models researcher and developers.","2024-03","2024-10-27 16:14:04","2024-10-27 16:14:04","","44-68","","1","27","","","","","","","","","","English","","","","WOS:000995626800001","","","","","","","copyright and related rights; freier werkgenuss; generative AI models; innovation; text and data mining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"77EZ7RAR","journalArticle","2024","Olimid, AP; Georgescu, CM; Olimid, DA","LEGAL ANALYSIS OF EU ARTIFICIAL INTELLIGENCE ACT (2024): INSIGHTS FROM PERSONAL DATA GOVERNANCE AND HEALTH POLICY","ACCESS TO JUSTICE IN EASTERN EUROPE","","2663-0575","10.33327/AJEE-18-7.4-a000103","","Background: This study correlates the up-to-date ethical, functional and legal evaluations related to the management and governance of artificial intelligence (AI) under European Union (EU) law, particularly impacting the health data sector and medical standards as provided by the Artificial Intelligence Act within the Regulation adopted by the European Council in May 2024. The initial proposal for the management and governance of the AI sector was submitted in April 2021. Three years later, on 13 March 2024, the European Union Artificial Intelligence Act (EU AIA) was adopted by the European Parliament. Subsequently, on 21 May 2024, the Council adopted an innovative legislative framework that harmonises the standards and rules for AI regulation. This framework is set to take effect in May 2026, with the central objective of stimulating and motivating a fair, safe, legal single market that respects the principles of ethics and the fundamental rights of the human person. Methods: The current legal analysis focuses on the European Unions' new institutional governance involving a multistage approach to managing health data, ethical artificial intelligence, generative artificial intelligence and classification of types of AI by considering the degree of risk (e.g. artificial intelligence systems with limited risk and systems with high risk) and medical devices. It outlines the legal framework for AI regulation and governance in the EU by focusing on compliance with the previously adopted legislation in the Medical Devices Regulation (2017) and the In-Vitro Diagnostic Regulation (2017). The paper also examines the application of the newly adopted EU Artificial Intelligence Act in relation to national justice systems, previous EU regulations on medical devices and personal data protection regulation, and its correlation with the European Court of Human Rights jurisprudence. This opens up complex discussions related to judicial reform and access to justice. For this purpose, as a research objective, the legal analysis includes an innovative perspective following an integrative discussion on the latest legal reforms and regulations of the AI sector in Eastern Europe launched in 2024 with a special focus on the latest developments in the EU Candidate Countries namely Ukraine and the Republic of Moldova. Results and conclusions: The present research facilitates the exploration of the real benefits of managing innovative AI systems for medical data, research, and development, as well as within the medical technology industry.","2024-09-02","2024-10-27 16:14:04","2024-10-27 16:30:38","","","","","","","","","","","","","","","English","","","","WOS:001304269100001","","","","","","","AI; artificial intelligence; ethical AI; EU legislation; generative AI; medical data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4F6J93BV","journalArticle","2022","Garvey, JB","LET'S GET REAL: WEAK ARTIFICIAL INTELLIGENCE HAS FREE SPEECH RIGHTS","FORDHAM LAW REVIEW","","0015-704X","","","The right to free speech is a strongly protected constitutional right under the First Amendment to the U.S. Constitution. In 2010, the U.S. Supreme Court significantly expanded free speech protections for corporations in Citizens United v. FEC. This case prompted the question: could other nonhuman actors also be eligible for free speech protection under the First Amendment? This inquiry is no longer a mere intellectual exercise: sophisticated artificial intelligence (AI) may soon be capable of producing speech. As such, there are novel and complex questions surrounding the application of the First Amendment to AI. Some commentators argue that AI should be granted free speech rights because AI speech may soon be sufficiently comparable to human speech. Others disagree and argue that First Amendment rights should not be extended to AI because there are traits in human speech that AI speech could not replicate. This Note explores the application of First Amendment jurisprudence to AI. Introducing relevant philosophical literature, this Note examines theories of human intelligence and decision-making in order to better understand the process that humans use to produce speech, and whether AI produces speech in a similar manner. In light of the legal and philosophical literature, as well as the Supreme Court's current First Amendment jurisprudence, this Note proposes that some types of AI are eligible for free speech protection under the First Amendment.","2022-12","2024-10-27 16:14:16","2024-10-27 16:14:16","","953-991","","3","91","","","","","","","","","","English","","","","WOS:000892560400005","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZEZP8KNI","journalArticle","2023","Khan, A; Jiliani, MAHS","EXPANDING THE BOUNDARIES OF JURISPRUDENCE IN THE ERA OF TECHNOLOGICAL ADVANCEMENTS","IIUM LAW JOURNAL","","0128-2530","","","In the current era of advanced technology, the convergence of artificial intelligence (AI) and big data presents intricate challenges in the technical and doctrinal aspects of law and the fundamental principles of jurisprudence. Addressing this challenge entails three potential approaches: reevaluating the independent status of specific foundational categories, reconfiguring the interpretation of such categories, or steadfastly defending and enhancing our understanding of specific classifications. The reconstruction of the essential concept of ""law"" remains uncertain and necessitates further deliberation. Although the new technological era has not introduced entirely novel jurisprudential dilemmas, it has reconsidered existing perspectives. Swiftly and effectively responding to these challenges becomes paramount in seizing fresh opportunities for the independent advancement of Chinese jurisprudence. The purpose of the study is to push the boundaries of jurisprudence by exploring and addressing legal issues arising in the era of technological advancements. The qualitative research methodology has been applied in this article.","2023","2024-10-27 16:14:17","2024-10-27 16:14:17","","393-426","","2","31","","","","","","","","","","English","","","","WOS:001125185300014","","","","","","","LAW; INFORMATION; ARTIFICIAL-INTELLIGENCE; Artificial Intelligence; PROPERTY; ETHICS; Big Data Basic; JUDGES; Jurisprudence Response; New Technology Era; NORMS; PARTICIPATION; Scope of Jurisprudence; SOCIOLOGY; TRANSFORMATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2BIQT2ZZ","journalArticle","2022","Chatterjee, S; Sreenivasulu, NS","Artificial intelligence and human rights: a comprehensive study from Indian legal and policy perspective","INTERNATIONAL JOURNAL OF LAW AND MANAGEMENT","","1754-243X","10.1108/IJLMA-02-2021-0049","","Purpose - The purpose of this study is to investigate the impact of artificial intelligence (AI) on the human rights issue. This study has also examined issues with AI for business and its civil and criminal liability. This study has provided inputs to the policymakers and government authorities to overcome different challenges. Design/methodology/approach - This study has analysed different international and Indian laws on human rights issues and the impacts of these laws to protect the human rights of the individual, which could be under threat due to the advancement of AI technology. This study has used descriptive doctrinal legal research methods to examine and understand the insights of existing laws and regulations in India to protect human rights and how these laws could be further developed to protect human rights under the Indian jurisprudence, which is under threat due to rapid advancement of AI-related technology. Findings - The study provides a comprehensive insight on the influence of AI on human rights issues and the existing laws in India. The study also shows different policy initiatives by the Government of India to regulate AI. Research limitations/implications - The study highlights some of the key policy recommendations helpful to regulate AI. Moreover, this study provides inputs to the regulatory authorities and legal fraternity to draft a much-needed comprehensive policy to regulate AI in the context of the protection of human rights of the citizens. Originality/value - AI is constantly posing entangled challenges to human rights. There is no comprehensive study, which investigated the emergence of AI and its influence on human rights issues, especially from the Indian legal perspective. So there is a research gap. This study provides a unique insight of the emergence of AI applications and its influence on human rights issues and provides inputs to the policymaker to help them to draft an effective regulation on AI to protect the human rights of Indian citizens. Thus, this study is considered a unique study that adds value towards the overall literature.","2022-01-07","2024-10-27 16:14:17","2024-10-27 16:14:17","","110-134","","1","64","","","","","","","","","","English","","","","WOS:000663042700001","","","","","","","Jurisprudence; Law; AI; Technology; TECHNOLOGY; Data privacy law; GOVERNANCE; Governance and ethics; India; INTERNET; Law and regulation; Policy; Policy and law; Regulation; Technology law","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q4HMTKFE","journalArticle","2022","Devany, BE","Clearview AI's First Amendment: A Dangerous Reality?","TEXAS LAW REVIEW","","0040-4411","","","On May 9, 2022, Clearview AI and the ACLU settled a two-year long dispute over the Illinois Biometric Information Privacy Act (BIPA), which prohibits companies like Clearview from scraping mass amounts of data from the internet. The ACLU sued Clearview for collecting billions of our personal- but publicly available-photos, a violation not only of BIPA but also of the user agreements of websites like Facebook, LinkedIn, and Twitter. Clearview uses these photos to create the largest known facial recognition database. Clearview's technology, which it licenses to law enforcement agencies across the country, can identify a face in a matter of seconds. As privacy and technology continue to clash, ACLU v. Clearview, Inc. provided an opportunity to address the underlying constitutional tension between the First Amendment and privacy. But since the suit settled, these questions remain unanswered.Clearview claims it has a First Amendment right to scrape data and sell its facial recognition service. Legal scholars have disposed of this argument as ""simplistic,"" ""at odds with long-established First Amendment doctrine,"" ""far from convincing,"" and even ""dangerous."" But whether we like it or not, Clearview's claims might not be so far off from current First Amendment jurisprudence, which has recently taken an aggressive and deregulatory turn. This Note explores current First Amendment jurisprudence and Clearview AI's interpretation of the First Amendment, which might be a reality. This Note also addresses the advantages and risks associated with facial recognition technology (FRT). Finally, this Note proposes a template for legislation that can regulate FRT in a way that is consistent with modern notions of privacy and current First Amendment doctrine.","2022-12","2024-10-27 16:14:17","2024-10-27 16:30:21","","473-507","","2","101","","","","","","","","","","English","","","","WOS:000967921300001","","","","","","","PRIVACY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9BATA95V","journalArticle","2023","Ferreira, DB; Gromova, EA","Hyperrealistic Jurisprudence: The Digital Age and the (Un)Certainty of Judge Analytics","INTERNATIONAL JOURNAL FOR THE SEMIOTICS OF LAW-REVUE INTERNATIONALE DE SEMIOTIQUE JURIDIQUE","","0952-8059","10.1007/s11196-023-10015-0","","This article is the first attempt to justify the ""next"" milestone in the development of legal realism: hyperrealism. The implications of digitalization have become the new fuel for the legal realist's jurisprudence prediction theory, that is, empirical research to predict the judge's or the court's decision. Indeed, that was impossible for American realists in the early twentieth century, and all the attempts failed. Therefore, tools such as Judicial Analytics allow us to prove that personal motives and prejudices affect a dispute's resolution. Based on a systemic, comparative, and interdisciplinary analysis that intermingles legal theory, data analytics and digital technologies, the article substantiates the concept of hyperrealism itself. It evaluates the advantages and disadvantages of its primary tool-judicial analytics. The authors state the necessity of creating regulatory mechanisms of ""curbing"" to use them to improve justice and minimize the risk of rights violations. They propose using tools of expert evaluation, standardization, and ethical regulation of forensic analysis.","2023-12","2024-10-27 16:14:17","2024-10-27 16:14:17","","2261-2281","","6","36","","","","","","","","","","English","","","","WOS:000992332200001","","","","","","","LAW; AI; Data analytics; CONCEPTIONS; Hyperrealism; Judge analytics; JURIMETRICS; Legal decision making; Legal realism; LEGAL REALISM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q328MQ9E","journalArticle","2023","Januário, TFX","Corporate Internal Investigations 4.0: on the criminal procedural aspects of applying artificial intelligence in the reactive corporate compliance","REVISTA BRASILEIRA DE DIREITO PROCESSUAL PENAL","","2359-3881","10.22197/rbdpp.v9i2.837","","The aim of the present paper is to analyze the criminal procedural implications of applying artificial intelligence systems in the context of internal investigations. More specifically, we will seek to answer the following questions: how can AI be used in these procedures and which are its legal boundaries? In case of effective use of this technology, how can it, in a future criminal proceeding, affect the admissibility and valuation of elements of information derived from internal investigations? In order to address these questions, we will apply the deductive methodology with a review of European and Brazilian legislation, doctrine and jurisprudence. At the end of the paper, we will demonstrate the limits to be observed for the processing of data and the use of AI in the scope of internal investigations, as well as the requirements and limits of sharing the information obtained from them with criminal proceedings.","2023-05","2024-10-27 16:14:17","2024-10-27 16:14:17","","723-785","","2","9","","","","","","","","","","English","","","","WOS:001025630100007","","","","","","","artificial intelligence; compliance; Corporate criminal law; criminal procedure; internal investigations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C43ZIYVT","journalArticle","2023","Mrcela, M; Vuletic, I","RETHINKING THE PRIVILEGE AGAINST SELF-INCRIMINATION IN TERMS OF EMERGING NEURO-TECHNOLOGY: COMPARING THE EUROPEAN AND UNITED STATES PERSPECTIVE","CROATIAN YEARBOOK OF EUROPEAN LAW & POLICY","","1845-5662","10.3935/cyelp.19.2023.504","","This paper analyses new fact-finding methods in criminal proceedings, using state-of-the-art innovations in neuroscience and artificial intelligence (AI). It will outline the existing methods and explain their effects. Then it will address the criminal-law aspects of the use of such methods as evidence in criminal proceedings, with an emphasis on the assessment of their admissibility from the perspective of the right to a fair trial and the privilege against self-incrimination. This topic will be observed from the perspective of US and European law, highlighting the existing jurisprudence of the European Court of Human Rights (ECtHR) and the legal standards established by the court in relation to the privilege against self-incrimination. Based on this analysis, the authors will formulate a conclusion suggesting that the use of current AI technologies should be juxtaposed to the relevant benchmark of the privilege against self-incrimination as the requisite standard of the right to a fair trial.","2023","2024-10-27 16:14:17","2024-10-27 16:14:17","","206-223","","","19","","","","","","","","","","English","","","","WOS:001144675100001","","","","","","","artificial intelligence; evidence; fair trial; lie detector; LIE-DETECTOR; neuroscience; self-incrimination; testimonial; TRIALS; truth","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EHKZZ6NB","journalArticle","2024","Paget, A","(SYNTHETIC) STUMP SPEECH: CRAFTING GENERATIVE AI DISCLOSURE REGULATIONS FOR POLITICAL ADVERTISEMENTS","FORDHAM LAW REVIEW","","0015-704X","","","Synthetic media, or content generated using artificial intelligence, has begun to infect political advertising. Federal legislation has spent most of its time stalled in committees, but states and online platforms have rapidly implemented regulations. Although synthetic media may pose harms through voter manipulation and democratic distortion, it also can lower campaign costs and more vividly illustrate conceptions of a political choice's consequences. Some governments and commentators have sought to prohibit the most harmful forms, while others have focused more on transparent approaches to regulation. In the face of yet another contentious election cycle, the question of how to ensure choices are made based on belief and not manipulation looms large. This Note assesses the current regulatory landscape for synthetic media in political advertising to analyze the benefits and drawbacks of greater regulation. Based on current and emerging regulatory approaches, this Note examines how governments and private actors have limited synthetic media usage within existing First Amendment jurisprudence. Although initial prohibitions served a necessary role, this Note proposes that transparency enforcement is the best approach and should be built upon by creating a repository that contains information on an advertisement's synthetic content.","2024-10","2024-10-27 16:14:17","2024-10-27 16:14:17","","321-358","","1","93","","","","","","","","","","English","","","","WOS:001328710900008","","","","","","","DEMOCRACY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NB4UK8W6","journalArticle","2023","Chucha, SY","ARTIFICIAL INTELLIGENCE IN JUSTICE: LEGAL AND PSYCHOLOGICAL ASPECTS OF LAW ENFORCEMENT","PRAVOPRIMENENIE-LAW ENFORCEMENT REVIEW","","2542-1514","10.52468/2542-1514.2023.7(2).116-124","","The subject. Artificial intelligence is considered as an interdisciplinary legal and psychologi-cal phenomenon. The special need to strengthen the psychological component in legal re-search of artificial intelligence and its introduction into the practice of law enforcement and justice, in particular, is substantiated.The main goal of the study is to confirm or refute hypothesis that AI may be implemented in justice and to substantiate the legal limits of such implementation.The methodology. Based on the comparison of the current legislation, the practice of its application, and other empirical data, internal and external legal and psychological factors of legal regulation and the use of artificial intelligence in jurisprudence and judicial proceed-ings are identified.The main results, scope of application. The analysis of legal and doctrinal definitions of ar-tificial intelligence in jurisprudence has shown that their defining and integral part is rela-tionships that are the result of psychological practices and the subject of psychological sci-ence (internal factors). Legal studies of artificial intelligence are based on a psychological conceptual apparatus, all of them legally describe artificial intelligence, first of all, as a psy-chological phenomenon and build an analogy between the psychology of a living intelligent subject and an inanimate object, humanizing the latter. The federal legislator is also follow-ing the path of using the psychological conceptual apparatus. Such categories like human cognitive functions and intellectual activity are applied in Russian Federal Law ""On conduct-ing an experiment to establish special regulation in order to create the necessary conditions for the development and implementation of artificial intelligence technologies in the sub-ject of the Russian Federation -the federal city of Moscow and amending Articles 6 and 10 of the Federal Law ""On Personal Data"". The legal and psychological analysis of the practice of using elements of artificial intelligence in corporate governance, justice, labor relations, social insurance, electoral procedures has been subjected.The conclusion is substantiated that an indispensable condition for the introduction of arti-ficial intelligence and its elements into justice is trust on the part of the disputing parties and the court. Such trust is provided with a real possibility of verifying the actions and de-cisions made with artificial intelligence by psychologically acceptable and legally formalized methods (external factors). The use of artificial intelligence in law enforcement in general and justice in particular is possible in two directions: (1) solving problems related to the approximation of specialized artificial intelligence systems in legal proceedings to human capabilities and their integration to enhance intelligence; (2) creating artificial intelligence, which is the integration of already created elements of artificial intelligence into a single system capable of participating in justice, but does not have the properties of free will and does not acquire legal personality. Law enforcement using artificial intelligence should com-ply with the principles enshrined in the European Ethical Charter on the Use of Artificial Intelligence in Judicial Systems and their environment, the provisions of which should be implemented in domestic legislation, having previously been revised in accordance with the national legal tradition.","2023","2024-10-27 16:14:17","2024-10-27 16:14:17","","116-124","","2","7","","","","","","","","","","English","","","","WOS:001027805400012","","","","","","","Artificial intelligence (AI); concept; law enforcement; corporate governance; efficiency; justice; labor activity; legal psychology; remote work; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YBE28GAS","journalArticle","2023","Vuletic, I","Corporate Criminal Liability: An Overview of the Croatian Model after 20 Years of Practice","LAWS","","2075-471X","10.3390/laws12020027","","The Croatian legislators introduced the concept of criminal liability for legal entities already in 2003 with the adoption of the Law on Criminal Liability of Legal Entities. Influenced by the writing of esteemed domestic scholars, and inspired by French law, the legislators opted for a system linking the liability of corporations to the liability of the responsible person. There were very few cases in practice during the first years of its application, and the situation changed after the first prominent indictment of this type against the ruling political party for economic crimes. Since then, the legislation has been amended several times and a significant body of jurisprudence has developed. In the first part of this paper, I will describe the chronology of the development and formation of the Croatian legislative model of corporate criminal liability. The second part will analyze 31 available final court judgments, which will be the basis for the conclusion about the issues in the practical application of the legislative model and, more generally, the phenomenon of criminal offenses committed by legal entities in Croatia. Based on this analysis, I will indicate the potential deficiencies of such a concept. In the context of future development, special attention will be given to the problem of economic crimes committed by AI corporate systems.","2023-04","2024-10-27 16:14:17","2024-10-27 16:14:17","","","","2","12","","","","","","","","","","English","","","","WOS:000977697000001","","","","","","","artificial intelligence; corporation; culpability; guilt; sanction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GP8RBRWN","journalArticle","2021","Wachter, S; Mittelstadt, B; Russell, C","Why fairness cannot be automated: Bridging the gap between EU non-discrimination law and AI","COMPUTER LAW & SECURITY REVIEW","","0267-3649","10.1016/j.clsr.2021.105567","","In recent years a substantial literature has emerged concerning bias, discrimination, and fairness in artificial intelligence (AI) and machine learning. Connecting this work to existing legal non-discrimination frameworks is essential to create tools and methods that are practically useful across divergent legal regimes. While much work has been undertaken from an American legal perspective, comparatively little has mapped the effects and requirements of EU law. This Article addresses this critical gap between legal, technical, and organisational notions of algorithmic fairness. Through analysis of EU non-discrimination law and jurisprudence of the European Court of Justice (ECJ) and national courts, we identify a critical incompatibility between European notions of discrimination and existing work on algorithmic and automated fairness. A clear gap exists between statistical measures of fairness as embedded in myriad fairness toolkits and governance mechanisms and the context-sensitive, often intuitive and ambiguous discrimination metrics and evidential requirements used by the ECJ; we refer to this approach as ""contextual equality."" This Article makes three contributions. First, we review the evidential requirements to bring a claim under EU non-discrimination law. Due to the disparate nature of algorithmic and human discrimination, the EU's current requirements are too contextual, reliant on intuition, and open to judicial interpretation to be automated. Many of the concepts fundamental to bringing a claim, such as the composition of the disadvantaged and advantaged group, the severity and type of harm suffered, and requirements for the relevance and admissibility of evidence, require normative or political choices to be made by the judiciary on a caseby-case basis. We show that automating fairness or non-discrimination in Europe may be impossible because the law, by design, does not provide a static or homogenous framework suited to testing for discrimination in AI systems. Second, we show how the legal protection offered by non-discrimination law is challenged when AI, not humans, discriminate. Humans discriminate due to negative attitudes (e.g. stereotypes, prejudice) and unintentional biases (e.g. organisational practices or internalised stereotypes) which can act as a signal to victims that discrimination has occurred. Equivalent signalling mechanisms and agency do not exist in algorithmic systems. Compared to traditional forms of discrimination, automated discrimination is more abstract and unintuitive, subtle, intangible, and difficult to detect. The increasing use of algorithms disrupts traditional legal remedies and procedures for detection, investigation, prevention, and correction of discrimination which have predominantly relied upon intuition. Consistent assessment procedures that define a common standard for statistical evidence to detect and assess prima facie automated discrimination are urgently needed to support judges, regulators, system controllers and developers, and claimants. Finally, we examine how existing work on fairness in machine learning lines up with procedures for assessing cases under EU non-discrimination law. A 'gold standard' for assessment of prima facie discrimination has been advanced by the European Court of Justice but not yet translated into standard assessment procedures for automated discrimination. We propose 'conditional demographic disparity' (CDD) as a standard baseline statistical measurement that aligns with the Court's 'gold standard'. Establishing a standard set of statistical evidence for automated discrimination cases can help ensure consistent procedures for assessment, but not judicial interpretation, of cases involving AI and automated systems. Through this proposal for procedural regularity in the identification and assessment of automated discrimination, we clarify how to build considerations of fairness into automated systems as far as possible while still respecting and enabling the contextual approach to judicial interpretation practiced under EU non-discrimination law.","2021-07","2024-10-27 16:14:17","2024-10-27 16:14:17","","","","","41","","","","","","","","","","English","","","","WOS:000685463100019","","","","","","","Machine learning; Law; BIG DATA; Artificial intelligence; ETHICS; DISCRIMINATION; BIAS; Fairness; IMPACT; Discrimination; Algorithm; Bias; Demographic; European union; Non-discrimination; parity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""