<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns:z="http://www.zotero.org/namespaces/export#"
 xmlns:dcterms="http://purl.org/dc/terms/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:bib="http://purl.org/net/biblio#"
 xmlns:foaf="http://xmlns.com/foaf/0.1/"
 xmlns:prism="http://prismstandard.org/namespaces/1.2/basic/">
    <rdf:Description rdf:about="urn:isbn:978-172816926-2%20(ISBN)">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:identifier>ISBN 978-172816926-2 (ISBN)</dc:identifier>
                <dc:title>Proc Int Jt Conf Neural Networks</dc:title>
                <dc:identifier>DOI 10.1109/IJCNN48605.2020.9207528</dc:identifier>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <foaf:name>Institute of Electrical and Electronics Engineers Inc.</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hong</foaf:surname>
                        <foaf:givenName>Z.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zhou</foaf:surname>
                        <foaf:givenName>Q.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zhang</foaf:surname>
                        <foaf:givenName>R.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Li</foaf:surname>
                        <foaf:givenName>W.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Mo</foaf:surname>
                        <foaf:givenName>T.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_1495"/>
        <dc:subject>Deep learning</dc:subject>
        <dc:subject>Semantics</dc:subject>
        <dc:subject>Neural networks</dc:subject>
        <dc:subject>Similar case</dc:subject>
        <dc:subject>Legal case</dc:subject>
        <dc:subject>Attention mechanism</dc:subject>
        <dc:subject>BERT</dc:subject>
        <dc:subject>Enhanced semantics</dc:subject>
        <dc:subject>Feature vectors</dc:subject>
        <dc:subject>Law intelligence</dc:subject>
        <dc:subject>Learning models</dc:subject>
        <dc:subject>Long-range dependencies</dc:subject>
        <dc:subject>Public dataset</dc:subject>
        <dc:subject>Semantic Web</dc:subject>
        <dc:subject>Similar case matching</dc:subject>
        <dc:subject>Text-matching</dc:subject>
        <dc:title>Legal Feature Enhanced Semantic Matching Network for Similar Case Matching</dc:title>
        <dcterms:abstract>Similar case matching (SCM) aims to determine whether legal case documents are similar or not. In fact, SCM is an extension of the semantic text matching. Various deep learning models are proposed to solve the semantic text matching problems. However, the main difference between the case documents may be subtle, and the length of documents can be quite long. Moreover, the case documents are written in structural format and contain plenty of legal terms. To address these challenges, we propose a novel model in this paper. Accordingly, the legal feature vector is introduced into the semantic text matching model, and BERT is adopted as the encoding layer to capture long-range dependencies in the case documents. We conduct several experiments to evaluate the performance of our proposed model. The results show that our model outperforms other existing methods on the public dataset CAIL2019-SCM. © 2020 IEEE.</dcterms:abstract>
        <dc:date>2020</dc:date>
        <z:language>English</z:language>
        <z:archive>Scopus</z:archive>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093864460&amp;doi=10.1109%2fIJCNN48605.2020.9207528&amp;partnerID=40&amp;md5=e6ad15744d5ebe9321c6415398f56c7f</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>Journal Abbreviation: Proc Int Jt Conf Neural Networks</dc:description>
        <bib:presentedAt>
            <bib:Conference>
                <dc:title>Proceedings of the International Joint Conference on Neural Networks</dc:title>
            </bib:Conference>
        </bib:presentedAt>
    </rdf:Description>
    <bib:Memo rdf:about="#item_1495">
        <rdf:value>&lt;p&gt;Export Date: 18 December 2024; Cited By: 26; Conference name: 2020 International Joint Conference on Neural Networks, IJCNN 2020; Conference date: 19 July 2020 through 24 July 2020; Conference code: 163566; CODEN: 85OFA&lt;/p&gt;</rdf:value>
    </bib:Memo>
    <rdf:Description rdf:about="urn:isbn:978-195073761-1%20(ISBN)">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <dc:identifier>ISBN 978-195073761-1 (ISBN)</dc:identifier>
                <dc:title>SIGDIAL - Annu. Meet. Spec. Interest Group Discourse Dial. - Proc. Conf.</dc:title>
                <dc:identifier>DOI 10.18653/v1/w19-5930</dc:identifier>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <foaf:name>Association for Computational Linguistics (ACL)</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Alloatti</foaf:surname>
                        <foaf:givenName>F.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Caro</foaf:surname>
                        <foaf:givenName>L.D.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sportelli</foaf:surname>
                        <foaf:givenName>G.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_1498"/>
        <dc:subject>Deep learning</dc:subject>
        <dc:subject>Natural language processing systems</dc:subject>
        <dc:subject>Laws and legislation</dc:subject>
        <dc:subject>Computational linguistics</dc:subject>
        <dc:subject>Language model</dc:subject>
        <dc:subject>Text processing</dc:subject>
        <dc:subject>Classification (of information)</dc:subject>
        <dc:subject>Text classification</dc:subject>
        <dc:subject>Automatic systems</dc:subject>
        <dc:subject>Question answering systems</dc:subject>
        <dc:subject>Real-life applications</dc:subject>
        <dc:subject>Restricted-domain</dc:subject>
        <dc:subject>Specific tasks</dc:subject>
        <dc:subject>Test corpus</dc:subject>
        <dc:subject>Training corpus</dc:subject>
        <dc:title>Real life application of a question answering system using bert language model</dc:title>
        <dcterms:abstract>Real life scenarios are often left untouched by the newest advances in research. They usually require the resolution of some specific task applied to a restricted domain, all the while providing small amounts of data to begin with. In this study we apply one of the newest innovations in Deep Learning to a task of text classification. The goal is to create a question answering system in Italian that provides information about a specific subject, e-invoicing and digital billing. Italy recently introduced a new legislation about e-invoicing and people have some legit doubts, therefore a large share of professionals could benefit from this tool. We gathered few pairs of question and answers; afterwards, we expanded the data, using it as a training corpus for BERT language model. Through a separate test corpus we evaluated the accuracy of the answer provided. Values show that the automatic system alone performs surprisingly well. The demo interface is hosted on Telegram, which makes the system immediately available to test. ©2019 Association for Computational Linguistics</dcterms:abstract>
        <dc:date>2019</dc:date>
        <z:language>English</z:language>
        <z:archive>Scopus</z:archive>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091584760&amp;doi=10.18653%2fv1%2fw19-5930&amp;partnerID=40&amp;md5=917a2b7cbb130185fdb9ea82a80eee11</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>Journal Abbreviation: SIGDIAL - Annu. Meet. Spec. Interest Group Discourse Dial. - Proc. Conf.</dc:description>
        <bib:pages>250-253</bib:pages>
        <bib:presentedAt>
            <bib:Conference>
                <dc:title>SIGDIAL 2019 - 20th Annual Meeting of the Special Interest Group Discourse Dialogue - Proceedings of the Conference</dc:title>
            </bib:Conference>
        </bib:presentedAt>
    </rdf:Description>
    <bib:Memo rdf:about="#item_1498">
        <rdf:value>&lt;p&gt;Export Date: 18 December 2024; Cited By: 12; Conference name: 20th Annual Meeting of the Special Interest Group on Discourse and Dialogue, SIGDIAL 2019; Conference date: 11 September 2019 through 13 September 2019; Conference code: 161400&lt;/p&gt;</rdf:value>
    </bib:Memo>
    <bib:Article rdf:about="https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048523859&amp;doi=10.1016%2fj.landusepol.2018.05.002&amp;partnerID=40&amp;md5=de03f09b1dd5f5f967aabde959d56b02">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:02648377%20(ISSN)"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Linkous</foaf:surname>
                        <foaf:givenName>E.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Skuzinski</foaf:surname>
                        <foaf:givenName>T.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_1502"/>
        <dc:subject>decision making</dc:subject>
        <dc:subject>United States</dc:subject>
        <dc:subject>dispute resolution</dc:subject>
        <dc:subject>Dispute resolution</dc:subject>
        <dc:subject>Florida</dc:subject>
        <dc:subject>Florida [United States]</dc:subject>
        <dc:subject>Institutional analysis and development</dc:subject>
        <dc:subject>institutional development</dc:subject>
        <dc:subject>Land use law</dc:subject>
        <dc:subject>land use planning</dc:subject>
        <dc:subject>legislation</dc:subject>
        <dc:subject>local government</dc:subject>
        <dc:subject>property rights</dc:subject>
        <dc:subject>Property rights</dc:subject>
        <dc:subject>state</dc:subject>
        <dc:title>Land use decision-making in the wake of state property rights legislation: Examining the institutional response to Florida's Harris Act</dc:title>
        <dcterms:abstract>Land use scholars hypothesize that state property rights legislation—adopted by more than half of U.S. states as a way to buttress the protections of landowners against uncompensated regulatory takings—negatively impacts the ability of local governments to regulate land use. This theorized impact can happen in two ways. First, compensation provisions may “chill” land use regulation due to increased risk of liability from adverse adjudication. Second, settlement and dispute resolution processes may limit public participation and abrogate decisions made in the public interest. However, there is little empirical or theoretical treatment of these concerns. To address this gap, we examine local land use decision-making in Florida in the more than two decades since the 1995 enactment of the Bert J. Harris, Jr. Private Property Rights Act [Act], one of the strongest state property rights laws in the United States. We use the Institutional Analysis and Development (IAD) framework to understand the system of rules and norms that operate within and between institutional actors in Florida's land use arena and animate decisions related to the Act. Drawing on key informant interviews and public documents, we show how contextual conditions and institutions mediate the impact of state private property laws. In Florida, institutions and transactions costs limit litigation under the Act—and consequently mitigate the Act's chilling effect—although unevenly depending on local context. The Act's compensation provision does little to reconfigure institutional arrangements and outcomes in property rights disputes; however, settlement and dispute resolution processes triggered by the Act effectively resolve local process and political challenges. Our findings suggest that dispute resolution is a more impactful and socially optimal approach to state property rights laws compared to compensation, and can enhance land use decision-making and outcomes for planning, the public interest, and landowners. © 2018 Elsevier Ltd</dcterms:abstract>
        <dc:date>2018</dc:date>
        <z:language>English</z:language>
        <z:archive>Scopus</z:archive>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048523859&amp;doi=10.1016%2fj.landusepol.2018.05.002&amp;partnerID=40&amp;md5=de03f09b1dd5f5f967aabde959d56b02</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>Publisher: Elsevier Ltd</dc:description>
        <bib:pages>603-612</bib:pages>
    </bib:Article>
    <bib:Journal rdf:about="urn:issn:02648377%20(ISSN)">
        <prism:volume>77</prism:volume>
        <dc:title>Land Use Policy</dc:title>
        <dc:identifier>DOI 10.1016/j.landusepol.2018.05.002</dc:identifier>
        <dcterms:alternative>Land Use Policy</dcterms:alternative>
        <dc:identifier>ISSN 02648377 (ISSN)</dc:identifier>
    </bib:Journal>
    <bib:Memo rdf:about="#item_1502">
        <rdf:value>&lt;p&gt;Export Date: 18 December 2024; Cited By: 7; Correspondence Address: E. Linkous; University of South Florida, School of Public Affairs, Tampa, 4202 East Fowler Avenue, SOC 107, 33620, United States; email: elinkous@usf.edu&lt;/p&gt;</rdf:value>
    </bib:Memo>
    <bib:Article rdf:about="https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153204653&amp;doi=10.5114%2fBIOLSPORT.2023.125623&amp;partnerID=40&amp;md5=72f951f36288364372691a144dec3114">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:0860021X%20(ISSN)"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dergaa</foaf:surname>
                        <foaf:givenName>I.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Chamari</foaf:surname>
                        <foaf:givenName>K.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zmijewski</foaf:surname>
                        <foaf:givenName>P.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Saad</foaf:surname>
                        <foaf:givenName>H.B.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_1513"/>
        <dc:subject>NLP</dc:subject>
        <dc:subject>Artificial Intelligence</dc:subject>
        <dc:subject>Machine Learning</dc:subject>
        <dc:subject>Chatbot</dc:subject>
        <dc:subject>Natural Language Processing</dc:subject>
        <dc:subject>Deep Learning</dc:subject>
        <dc:subject>LLaMA</dc:subject>
        <dc:subject>LLM</dc:subject>
        <dc:subject>Google Bard</dc:subject>
        <dc:subject>Higher Education</dc:subject>
        <dc:subject>NLM</dc:subject>
        <dc:subject>Paperpal</dc:subject>
        <dc:subject>Peer Review</dc:subject>
        <dc:subject>QuillBot</dc:subject>
        <dc:subject>Rayyan</dc:subject>
        <dc:subject>Research</dc:subject>
        <dc:subject>Sports Medicine</dc:subject>
        <dc:title>From human writing to artificial intelligence generated text: examining the prospects and potential threats of ChatGPT in academic writing</dc:title>
        <dcterms:abstract>Natural language processing (NLP) has been studied in computing for decades. Recent technological advancements have led to the development of sophisticated artificial intelligence (AI) models, such as Chat Generative Pre-trained Transformer (ChatGPT). These models can perform a range of language tasks and generate human-like responses, which offers exciting prospects for academic efficiency. This manuscript aims at (i) exploring the potential benefits and threats of ChatGPT and other NLP technologies in academic writing and research publications; (ii) highlights the ethical considerations involved in using these tools, and (iii) consider the impact they may have on the authenticity and credibility of academic work. This study involved a literature review of relevant scholarly articles published in peer-reviewed journals indexed in Scopus as quartile 1. The search used keywords such as “ChatGPT,” “AI-generated text,” “academic writing,” and “natural language processing.” The analysis was carried out using a quasi-qualitative approach, which involved reading and critically evaluating the sources and identifying relevant data to support the research questions. The study found that ChatGPT and other NLP technologies have the potential to enhance academic writing and research efficiency. However, their use also raises concerns about the impact on the authenticity and credibility of academic work. The study highlights the need for comprehensive discussions on the potential use, threats, and limitations of these tools, emphasizing the importance of ethical and academic principles, with human intelligence and critical thinking at the forefront of the research process. This study highlights the need for comprehensive debates and ethical considerations involved in their use. The study also recommends that academics exercise caution when using these tools and ensure transparency in their use, emphasizing the importance of human intelligence and critical thinking in academic work. © 2023 Institute of Sport. All rights reserved.</dcterms:abstract>
        <dc:date>2023</dc:date>
        <z:language>English</z:language>
        <z:archive>Scopus</z:archive>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153204653&amp;doi=10.5114%2fBIOLSPORT.2023.125623&amp;partnerID=40&amp;md5=72f951f36288364372691a144dec3114</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>Publisher: Institute of Sport</dc:description>
        <bib:pages>615-622</bib:pages>
    </bib:Article>
    <bib:Journal rdf:about="urn:issn:0860021X%20(ISSN)">
        <prism:volume>40</prism:volume>
        <dc:title>Biology of Sport</dc:title>
        <dc:identifier>DOI 10.5114/BIOLSPORT.2023.125623</dc:identifier>
        <prism:number>2</prism:number>
        <dcterms:alternative>Biol. Sport</dcterms:alternative>
        <dc:identifier>ISSN 0860021X (ISSN)</dc:identifier>
    </bib:Journal>
    <bib:Memo rdf:about="#item_1513">
        <rdf:value>&lt;p&gt;Export Date: 18 December 2024; Cited By: 217; Correspondence Address: H.B. Saad; University of Sousse, Farhat HACHED Hospital, Research Laboratory LR12SP09 «Heart Failure», Sousse, Tunisia; email: helmi.bensaad@rns.tn&lt;/p&gt;</rdf:value>
    </bib:Memo>
    <bib:Article rdf:about="https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148608599&amp;doi=10.37074%2fjalt.2023.6.1.9&amp;partnerID=40&amp;md5=5aed8395fdc3cde275b039226634df1f">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:2591801X%20(ISSN)"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Rudolph</foaf:surname>
                        <foaf:givenName>J.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Tan</foaf:surname>
                        <foaf:givenName>S.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Tan</foaf:surname>
                        <foaf:givenName>S.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_1515"/>
        <dc:subject>Artificial Intelligence (AI)</dc:subject>
        <dc:subject>ChatGPT</dc:subject>
        <dc:subject>higher education</dc:subject>
        <dc:subject>natural language processing (NLP)</dc:subject>
        <dc:subject>Artificial Intelligence in Education (AIEd)</dc:subject>
        <dc:subject>assessment</dc:subject>
        <dc:subject>Generative Pre-trained Transformer 3 (GPT-3)</dc:subject>
        <dc:subject>learning &amp; teaching</dc:subject>
        <dc:title>ChatGPT: Bullshit spewer or the end of traditional assessments in higher education?</dc:title>
        <dcterms:abstract>ChatGPT is the world’s most advanced chatbot thus far. Unlike other chatbots, it can create impressive prose within seconds, and it has created much hype and doomsday predictions when it comes to student assessment in higher education and a host of other matters. ChatGPT is a state-of-the-art language model (a variant of OpenAI’s Generative Pretrained Transformer (GPT) language model) designed to generate text that can be indistinguishable from text written by humans. It can engage in conversation with users in a seemingly natural and intuitive way. In this article, we briefly tell the story of OpenAI, the organisation behind ChatGPT. We highlight the fundamental change from a not-for-profit organisation to a commercial business model. In terms of our methods, we conducted an extensive literature review and experimented with this artificial intelligence (AI) software. Our literature review shows our review to be amongst the first peer-reviewed academic journal articles to explore ChatGPT and its relevance for higher education (especially assessment, learning and teaching). After a description of ChatGPT’s functionality and a summary of its strengths and limitations, we focus on the technology’s implications for higher education and discuss what is the future of learning, teaching and assessment in higher education in the context of AI chatbots such as ChatGPT. We position ChatGPT in the context of current Artificial Intelligence in Education (AIEd) research, discuss student-facing, teacher-facing and system-facing applications, and analyse opportunities and threats. We conclude the article with recommendations for students, teachers and higher education institutions. Many of them focus on assessment. © 2023. Jürgen Rudolph, Samson Tan and Shannon Tan.</dcterms:abstract>
        <dc:date>2023</dc:date>
        <z:language>English</z:language>
        <z:archive>Scopus</z:archive>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148608599&amp;doi=10.37074%2fjalt.2023.6.1.9&amp;partnerID=40&amp;md5=5aed8395fdc3cde275b039226634df1f</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>Publisher: Kaplan Singapore</dc:description>
        <bib:pages>342-363</bib:pages>
    </bib:Article>
    <bib:Journal rdf:about="urn:issn:2591801X%20(ISSN)">
        <prism:volume>6</prism:volume>
        <dc:title>Journal of Applied Learning and Teaching</dc:title>
        <dc:identifier>DOI 10.37074/jalt.2023.6.1.9</dc:identifier>
        <prism:number>1</prism:number>
        <dcterms:alternative>J. Appl. Learn. Teach.</dcterms:alternative>
        <dc:identifier>ISSN 2591801X (ISSN)</dc:identifier>
    </bib:Journal>
    <bib:Memo rdf:about="#item_1515">
        <rdf:value>&lt;p&gt;Export Date: 18 December 2024; Cited By: 646&lt;/p&gt;</rdf:value>
    </bib:Memo>
    <bib:Article rdf:about="https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163727625&amp;doi=10.3390%2ffi15060192&amp;partnerID=40&amp;md5=983680a889ad15454028f841da828a9f">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:19995903%20(ISSN)"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Roumeliotis</foaf:surname>
                        <foaf:givenName>K.I.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Tselikas</foaf:surname>
                        <foaf:givenName>N.D.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_1521"/>
        <dc:subject>Natural language processing</dc:subject>
        <dc:subject>natural language processing</dc:subject>
        <dc:subject>GPT-4</dc:subject>
        <dc:subject>ChatGPT</dc:subject>
        <dc:subject>generative pre-trained transformer</dc:subject>
        <dc:subject>Learning algorithms</dc:subject>
        <dc:subject>Natural language processing systems</dc:subject>
        <dc:subject>Language processing</dc:subject>
        <dc:subject>Natural languages</dc:subject>
        <dc:subject>Reinforcement learning</dc:subject>
        <dc:subject>Reinforcement learnings</dc:subject>
        <dc:subject>ChatGPT review</dc:subject>
        <dc:subject>Generative pre-trained transformer</dc:subject>
        <dc:subject>Literature reviews</dc:subject>
        <dc:subject>Training process</dc:subject>
        <dc:title>ChatGPT and Open-AI Models: A Preliminary Review</dc:title>
        <dcterms:abstract>According to numerous reports, ChatGPT represents a significant breakthrough in the field of artificial intelligence. ChatGPT is a pre-trained AI model designed to engage in natural language conversations, utilizing sophisticated techniques from Natural Language Processing (NLP), Supervised Learning, and Reinforcement Learning to comprehend and generate text comparable to human-generated text. This article provides an overview of the training process and fundamental functionality of ChatGPT, accompanied by a preliminary review of the relevant literature. Notably, this article presents the first comprehensive literature review of this technology at the time of publication, aiming to aggregate all the available pertinent articles to facilitate further developments in the field. Ultimately, the authors aim to offer an appraisal of the technology’s potential implications on existing knowledge and technology, along with potential challenges that must be addressed. © 2023 by the authors.</dcterms:abstract>
        <dc:date>2023</dc:date>
        <z:language>English</z:language>
        <z:archive>Scopus</z:archive>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163727625&amp;doi=10.3390%2ffi15060192&amp;partnerID=40&amp;md5=983680a889ad15454028f841da828a9f</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>Publisher: MDPI</dc:description>
    </bib:Article>
    <bib:Journal rdf:about="urn:issn:19995903%20(ISSN)">
        <prism:volume>15</prism:volume>
        <dc:title>Future Internet</dc:title>
        <dc:identifier>DOI 10.3390/fi15060192</dc:identifier>
        <prism:number>6</prism:number>
        <dcterms:alternative>Future Internet</dcterms:alternative>
        <dc:identifier>ISSN 19995903 (ISSN)</dc:identifier>
    </bib:Journal>
    <bib:Memo rdf:about="#item_1521">
        <rdf:value>&lt;p&gt;Export Date: 18 December 2024; Cited By: 197; Correspondence Address: N.D. Tselikas; Department of Informatics and Telecommunications, University of Peloponnese, Tripoli, 221 00, Greece; email: ntsel@uop.gr&lt;/p&gt;</rdf:value>
    </bib:Memo>
    <rdf:Description rdf:about="urn:isbn:10495258%20(ISSN)">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <prism:volume>2020-December</prism:volume>
                <dc:identifier>ISBN 10495258 (ISSN)</dc:identifier>
                <dc:title>Adv. neural inf. proces. syst.</dc:title>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <foaf:name>Neural information processing systems foundation</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zaheer</foaf:surname>
                        <foaf:givenName>M.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Guruganesh</foaf:surname>
                        <foaf:givenName>G.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Dubey</foaf:surname>
                        <foaf:givenName>A.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ainslie</foaf:surname>
                        <foaf:givenName>J.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Alberti</foaf:surname>
                        <foaf:givenName>C.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ontanon</foaf:surname>
                        <foaf:givenName>S.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Pham</foaf:surname>
                        <foaf:givenName>P.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ravula</foaf:surname>
                        <foaf:givenName>A.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Wang</foaf:surname>
                        <foaf:givenName>Q.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Yang</foaf:surname>
                        <foaf:givenName>L.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ahmed</foaf:surname>
                        <foaf:givenName>A.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_1544"/>
        <dc:subject>Deep learning</dc:subject>
        <dc:subject>Natural language processing systems</dc:subject>
        <dc:subject>Question Answering</dc:subject>
        <dc:subject>Learning models</dc:subject>
        <dc:subject>Attention mechanisms</dc:subject>
        <dc:subject>Attention model</dc:subject>
        <dc:subject>Novel applications</dc:subject>
        <dc:subject>Sequence lengths</dc:subject>
        <dc:subject>Turing-complete</dc:subject>
        <dc:subject>Universal approximators</dc:subject>
        <dc:title>Big bird: Transformers for longer sequences</dc:title>
        <dcterms:abstract>Transformers-based models, such as BERT, have been one of the most successful deep learning models for NLP. Unfortunately, one of their core limitations is the quadratic dependency (mainly in terms of memory) on the sequence length due to their full attention mechanism. To remedy this, we propose, BIGBIRD, a sparse attention mechanism that reduces this quadratic dependency to linear. We show that BIGBIRD is a universal approximator of sequence functions and is Turing complete, thereby preserving these properties of the quadratic, full attention model. Along the way, our theoretical analysis reveals some of the benefits of having O(1) global tokens (such as CLS), that attend to the entire sequence as part of the sparse attention mechanism. The proposed sparse attention can handle sequences of length up to 8x of what was previously possible using similar hardware. As a consequence of the capability to handle longer context, BIGBIRD drastically improves performance on various NLP tasks such as question answering and summarization. We also propose novel applications to genomics data. © 2020 Neural information processing systems foundation. All rights reserved.</dcterms:abstract>
        <dc:date>2020</dc:date>
        <z:language>English</z:language>
        <z:archive>Scopus</z:archive>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097333449&amp;partnerID=40&amp;md5=45a008708bb4033f27b1b4f818cc9724</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>Journal Abbreviation: Adv. neural inf. proces. syst.</dc:description>
        <bib:presentedAt>
            <bib:Conference>
                <dc:title>Advances in Neural Information Processing Systems</dc:title>
            </bib:Conference>
        </bib:presentedAt>
    </rdf:Description>
    <bib:Memo rdf:about="#item_1544">
        <rdf:value>&lt;p&gt;Export Date: 18 December 2024; Cited By: 996; Conference name: 34th Conference on Neural Information Processing Systems, NeurIPS 2020; Conference date: 6 December 2020 through 12 December 2020; Conference code: 169463&lt;/p&gt;</rdf:value>
    </bib:Memo>
    <bib:Article rdf:about="https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092733644&amp;partnerID=40&amp;md5=df1a6dc84cf71b099f2476907f7c8e17">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:15324435%20(ISSN)"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Raffel</foaf:surname>
                        <foaf:givenName>C.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Shazeer</foaf:surname>
                        <foaf:givenName>N.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Roberts</foaf:surname>
                        <foaf:givenName>A.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Lee</foaf:surname>
                        <foaf:givenName>K.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Narang</foaf:surname>
                        <foaf:givenName>S.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Matena</foaf:surname>
                        <foaf:givenName>M.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zhou</foaf:surname>
                        <foaf:givenName>Y.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Li</foaf:surname>
                        <foaf:givenName>W.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Liu</foaf:surname>
                        <foaf:givenName>P.J.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_1549"/>
        <dc:subject>Natural language processing</dc:subject>
        <dc:subject>Deep learning</dc:subject>
        <dc:subject>Natural language processing systems</dc:subject>
        <dc:subject>Learning systems</dc:subject>
        <dc:subject>Transfer learning</dc:subject>
        <dc:subject>Unified framework</dc:subject>
        <dc:subject>Question Answering</dc:subject>
        <dc:subject>Text processing</dc:subject>
        <dc:subject>Language understanding</dc:subject>
        <dc:subject>NAtural language processing</dc:subject>
        <dc:subject>Classification (of information)</dc:subject>
        <dc:subject>Text classification</dc:subject>
        <dc:subject>Multi-task learning</dc:subject>
        <dc:subject>Learning techniques</dc:subject>
        <dc:subject>Attentionbased models</dc:subject>
        <dc:subject>Language problems</dc:subject>
        <dc:subject>Systematic study</dc:subject>
        <dc:title>Exploring the limits of transfer learning with a unified text-to-text transformer</dc:title>
        <dcterms:abstract>Transfer learning, where a model is first pre-trained on a data-rich task before being finetuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new &quot;Colossal Clean Crawled Corpus&quot;, we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our data set, pre-trained models, and code. ©2020 Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu.</dcterms:abstract>
        <dc:date>2020</dc:date>
        <z:language>English</z:language>
        <z:archive>Scopus</z:archive>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092733644&amp;partnerID=40&amp;md5=df1a6dc84cf71b099f2476907f7c8e17</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>Publisher: Microtome Publishing</dc:description>
    </bib:Article>
    <bib:Journal rdf:about="urn:issn:15324435%20(ISSN)">
        <prism:volume>21</prism:volume>
        <dc:title>Journal of Machine Learning Research</dc:title>
        <dcterms:alternative>J. Mach. Learn. Res.</dcterms:alternative>
        <dc:identifier>ISSN 15324435 (ISSN)</dc:identifier>
    </bib:Journal>
    <bib:Memo rdf:about="#item_1549">
        <rdf:value>&lt;p&gt;Export Date: 18 December 2024; Cited By: 9121; Correspondence Address: C. Raffel; Google, Mountain View, 94043, United States; email: craffel@gmail.com&lt;/p&gt;</rdf:value>
    </bib:Memo>
    <rdf:Description rdf:about="urn:isbn:978-194562675-3%20(ISBN)">
        <z:itemType>conferencePaper</z:itemType>
        <dcterms:isPartOf>
            <bib:Journal>
                <prism:volume>1</prism:volume>
                <dc:identifier>ISBN 978-194562675-3 (ISBN)</dc:identifier>
                <dc:title>ACL - Annu. Meet. Assoc. Comput. Linguist., Proc. Conf. (Long Papers)</dc:title>
                <dc:identifier>DOI 10.18653/v1/P17-1019</dc:identifier>
            </bib:Journal>
        </dcterms:isPartOf>
        <dc:publisher>
            <foaf:Organization>
                <foaf:name>Association for Computational Linguistics (ACL)</foaf:name>
            </foaf:Organization>
        </dc:publisher>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>He</foaf:surname>
                        <foaf:givenName>S.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Liu</foaf:surname>
                        <foaf:givenName>C.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Liu</foaf:surname>
                        <foaf:givenName>K.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Zhao</foaf:surname>
                        <foaf:givenName>J.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_1657"/>
        <dcterms:isReferencedBy rdf:resource="#item_2294"/>
        <dc:subject>Artificial intelligence</dc:subject>
        <dc:subject>Semantics</dc:subject>
        <dc:subject>Natural language processing systems</dc:subject>
        <dc:subject>Computational linguistics</dc:subject>
        <dc:subject>Natural languages</dc:subject>
        <dc:subject>Linguistics</dc:subject>
        <dc:subject>Knowledge based systems</dc:subject>
        <dc:subject>Question answering systems</dc:subject>
        <dc:subject>Sequence learning</dc:subject>
        <dc:subject>Encoder-decoder</dc:subject>
        <dc:subject>Empirical studies</dc:subject>
        <dc:subject>Knowledge base</dc:subject>
        <dc:subject>Natural response</dc:subject>
        <dc:subject>Real-world datasets</dc:subject>
        <dc:title>Generating natural answers by incorporating copying and retrieving mechanisms in sequence-to-sequence learning</dc:title>
        <dcterms:abstract>Generating answer with natural language sentence is very important in real-world question answering systems, which needs to obtain a right answer as well as a coherent natural response. In this paper, we propose an end-to-end question answering system called COREQA in sequence-to-sequence learning, which incorporates copying and retrieving mechanisms to generate natural answers within an encoder-decoder framework. Specifically, in COREQA, the semantic units (words, phrases and entities) in a natural answer are dynamically predicted from the vocabulary, copied from the given question and/or retrieved from the corresponding knowledge base jointly. Our empirical study on both synthetic and real-world datasets demonstrates the efficiency of COREQA, which is able to generate correct, coherent and natural answers for knowledge inquired questions. © 2017 Association for Computational Linguistics.</dcterms:abstract>
        <dc:date>2017</dc:date>
        <z:language>English</z:language>
        <z:archive>Scopus</z:archive>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040946732&amp;doi=10.18653%2fv1%2fP17-1019&amp;partnerID=40&amp;md5=a322d03968175ebb9ab98478bfd2c3c4</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>Journal Abbreviation: ACL - Annu. Meet. Assoc. Comput. Linguist., Proc. Conf. (Long Papers)</dc:description>
        <bib:pages>199-208</bib:pages>
        <bib:presentedAt>
            <bib:Conference>
                <dc:title>ACL 2017 - 55th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers)</dc:title>
            </bib:Conference>
        </bib:presentedAt>
    </rdf:Description>
    <bib:Memo rdf:about="#item_1657">
        <rdf:value>&lt;p&gt;Export Date: 18 December 2024; Cited By: 104; Conference name: 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017; Conference date: 30 July 2017 through 4 August 2017; Conference code: 132950&lt;/p&gt;</rdf:value>
    </bib:Memo>
    <bib:Memo rdf:about="#item_2294">
        <rdf:value>&lt;div data-schema-version=&quot;9&quot;&gt;&lt;p&gt;Não se enquadra no âmbito do tema 2: tecnologias e abordagens&lt;/p&gt;
&lt;/div&gt;</rdf:value>
    </bib:Memo>
    <bib:Article rdf:about="https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027923512&amp;doi=10.1016%2fj.ipm.2016.06.006&amp;partnerID=40&amp;md5=0bc9131b66bff800ad04a151931fd850">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:03064573%20(ISSN)"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Hazrina</foaf:surname>
                        <foaf:givenName>S.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Sharef</foaf:surname>
                        <foaf:givenName>N.M.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Ibrahim</foaf:surname>
                        <foaf:givenName>H.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Murad</foaf:surname>
                        <foaf:givenName>M.A.A.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Noah</foaf:surname>
                        <foaf:givenName>S.A.M.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_1656"/>
        <dc:subject>Artificial intelligence</dc:subject>
        <dc:subject>Semantics</dc:subject>
        <dc:subject>Natural language processing systems</dc:subject>
        <dc:subject>Question Answering</dc:subject>
        <dc:subject>Linguistics</dc:subject>
        <dc:subject>Natural language questions</dc:subject>
        <dc:subject>Question answering systems</dc:subject>
        <dc:subject>Question processing</dc:subject>
        <dc:subject>Ambiguity types</dc:subject>
        <dc:subject>Conceptual frameworks</dc:subject>
        <dc:subject>Linked open data (LOD)</dc:subject>
        <dc:subject>Natural language question</dc:subject>
        <dc:subject>Semantic question answering</dc:subject>
        <dc:subject>SQA disambiguation solution</dc:subject>
        <dc:subject>Structure complexity</dc:subject>
        <dc:title>Review on the advancements of disambiguation in semantic question answering system</dc:title>
        <dcterms:abstract>Ambiguity is a potential problem in any semantic question answering (SQA) system due to the nature of idiosyncrasy in composing natural language (NL) question and semantic resources. Thus, disambiguation of SQA systems is a field of ongoing research. Ambiguity occurs in SQA because a word or a sentence can have more than one meaning or multiple words in the same language can share the same meaning. Therefore, an SQA system needs disambiguation solutions to select the correct meaning when the linguistic triples matched with multiple KB concepts, and enumerate similar words especially when linguistic triples do not match with any KB concept. The latest development in this field is a solution for SQA systems that is able to process a complex NL question while accessing open-domain data from linked open data (LOD). The contributions in this paper include (1) formulating an SQA conceptual framework based on an in-depth study of existing SQA processes; (2) identifying the ambiguity types, specifically in English based on an interdisciplinary literature review; (3) highlighting the ambiguity types that had been resolved by the previous SQA studies; and (4) analysing the results of the existing SQA disambiguation solutions, the complexity of NL question processing, and the complexity of data retrieval from KB(s) or LOD. The results of this review demonstrated that out of thirteen types of ambiguity identified in the literature, only six types had been successfully resolved by the previous studies. Efforts to improve the disambiguation are in progress for the remaining unresolved ambiguity types to improve the accuracy of the formulated answers by the SQA system. The remaining ambiguity types are potentially resolved in the identified SQA process based on ambiguity scenarios elaborated in this paper. The results of this review also demonstrated that most existing research on SQA systems have treated the processing of the NL question complexity separate from the processing of the KB structure complexity. © 2016 Elsevier Ltd</dcterms:abstract>
        <dc:date>2017</dc:date>
        <z:language>English</z:language>
        <z:archive>Scopus</z:archive>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027923512&amp;doi=10.1016%2fj.ipm.2016.06.006&amp;partnerID=40&amp;md5=0bc9131b66bff800ad04a151931fd850</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>Publisher: Elsevier Ltd</dc:description>
        <bib:pages>52-69</bib:pages>
    </bib:Article>
    <bib:Journal rdf:about="urn:issn:03064573%20(ISSN)">
        <prism:volume>53</prism:volume>
        <dc:title>Information Processing and Management</dc:title>
        <dc:identifier>DOI 10.1016/j.ipm.2016.06.006</dc:identifier>
        <prism:number>1</prism:number>
        <dcterms:alternative>Inf. Process. Manage.</dcterms:alternative>
        <dc:identifier>ISSN 03064573 (ISSN)</dc:identifier>
    </bib:Journal>
    <bib:Memo rdf:about="#item_1656">
        <rdf:value>&lt;p&gt;Export Date: 18 December 2024; Cited By: 32; Correspondence Address: S. Hazrina; Department of Computer Science, Faculty of Computer Science and Information Technology, University Putra Malaysia, Selangor, Malaysia; email: hazrina@gmail.com; CODEN: IPMAD&lt;/p&gt;</rdf:value>
    </bib:Memo>
    <bib:Article rdf:about="https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189943350&amp;doi=10.14569%2fIJACSA.2024.0150379&amp;partnerID=40&amp;md5=b3c38533a1a335a606e07d42a7489644">
        <z:itemType>journalArticle</z:itemType>
        <dcterms:isPartOf rdf:resource="urn:issn:2158107X%20(ISSN)"/>
        <bib:authors>
            <rdf:Seq>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Muludi</foaf:surname>
                        <foaf:givenName>K.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Fitria</foaf:surname>
                        <foaf:givenName>K.M.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
                <rdf:li>
                    <foaf:Person>
                        <foaf:surname>Triloka</foaf:surname>
                        <foaf:givenName>J.</foaf:givenName>
                    </foaf:Person>
                </rdf:li>
            </rdf:Seq>
        </bib:authors>
        <dcterms:isReferencedBy rdf:resource="#item_1585"/>
        <dc:subject>Natural language processing</dc:subject>
        <dc:subject>GPT</dc:subject>
        <dc:subject>Natural language processing systems</dc:subject>
        <dc:subject>Search engines</dc:subject>
        <dc:subject>Computational linguistics</dc:subject>
        <dc:subject>Language model</dc:subject>
        <dc:subject>Language processing</dc:subject>
        <dc:subject>Natural languages</dc:subject>
        <dc:subject>Data handling</dc:subject>
        <dc:subject>Large language model</dc:subject>
        <dc:subject>Question Answering</dc:subject>
        <dc:subject>Natural Language Processing</dc:subject>
        <dc:subject>Knowledge representation</dc:subject>
        <dc:subject>Question answering systems</dc:subject>
        <dc:subject>Statistical tests</dc:subject>
        <dc:subject>Competition</dc:subject>
        <dc:subject>Generation method</dc:subject>
        <dc:subject>Large Language Model</dc:subject>
        <dc:subject>Retrieval augmented generation</dc:subject>
        <dc:subject>Retrieval Augmented Generation</dc:subject>
        <dc:title>Retrieval-Augmented Generation Approach: Document Question Answering using Large Language Model</dc:title>
        <dcterms:abstract>This study introduces the Retrieval Augmented Generation (RAG) method to improve Question-Answering (QA) systems by addressing document processing in Natural Language Processing problems. It represents the latest breakthrough in applying RAG to document question and answer applications, overcoming previous QA system obstacles. RAG combines search techniques in vector store and text generation mechanism developed by Large Language Models, offering a time-efficient alternative to manual reading limitations. The research evaluates RAG's that use Generative Pre-trained Transformer 3.5 or GPT-3.5-turbo from the ChatGPT model and its impact on document data processing, comparing it with other applications. This research also provides datasets to test the capabilities of the QA document system. The proposed dataset and Stanford Question Answering Dataset (SQuAD) are used for performance testing. The study contributes theoretically by advancing methodologies and knowledge representation, supporting benchmarking in research communities. Results highlight RAG's superiority: achieving a precision of 0.74 in Recall-Oriented Understudy for Gisting Evaluation (ROUGE) testing, outperforming others at 0.5; obtaining an F1 score of 0.88 in BERTScore, surpassing other QA apps at 0.81; attaining a precision of 0.28 in Bilingual Evaluation Understudy (BLEU) testing, surpassing others with a precision of 0.09; and scoring 0.33 in Jaccard Similarity, outshining others at 0.04. These findings underscore RAG's efficiency and competitiveness, promising a positive impact on various industrial sectors through advanced Artificial Intelligence (AI) technology. © (2024), (Science and Information Organization). All Rights Reserved.</dcterms:abstract>
        <dc:date>2024</dc:date>
        <z:language>English</z:language>
        <z:archive>Scopus</z:archive>
        <dc:identifier>
            <dcterms:URI>
                <rdf:value>https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189943350&amp;doi=10.14569%2fIJACSA.2024.0150379&amp;partnerID=40&amp;md5=b3c38533a1a335a606e07d42a7489644</rdf:value>
            </dcterms:URI>
        </dc:identifier>
        <dc:description>Publisher: Science and Information Organization</dc:description>
        <bib:pages>776-785</bib:pages>
    </bib:Article>
    <bib:Journal rdf:about="urn:issn:2158107X%20(ISSN)">
        <prism:volume>15</prism:volume>
        <dc:title>International Journal of Advanced Computer Science and Applications</dc:title>
        <dc:identifier>DOI 10.14569/IJACSA.2024.0150379</dc:identifier>
        <prism:number>3</prism:number>
        <dcterms:alternative>Intl. J. Adv.  Comput. Sci. Appl.</dcterms:alternative>
        <dc:identifier>ISSN 2158107X (ISSN)</dc:identifier>
    </bib:Journal>
    <bib:Memo rdf:about="#item_1585">
        <rdf:value>&lt;p&gt;Export Date: 18 December 2024; Cited By: 2&lt;/p&gt;</rdf:value>
    </bib:Memo>
</rdf:RDF>
