TY  - JOUR
AU  - Sheik, R.
AU  - Ganta, S.R.
AU  - Nirmala, S.J.
TI  - Legal sentence boundary detection using hybrid deep learning and statistical models
PY  - 2024
T2  - Artificial Intelligence and Law
DO  - 10.1007/s10506-024-09394-x
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187640087&doi=10.1007%2fs10506-024-09394-x&partnerID=40&md5=6ce9186926329c2f9e69abe5d221d13d
AD  - National Institute of Technology, Trichy, Tamil Nadu, Tiruchirappalli, India
AB  - Sentence boundary detection (SBD) represents an important first step in natural language processing since accurately identifying sentence boundaries significantly impacts downstream applications. Nevertheless, detecting sentence boundaries within legal texts poses a unique and challenging problem due to their distinct structural and linguistic features. Our approach utilizes deep learning models to leverage delimiter and surrounding context information as input, enabling precise detection of sentence boundaries in English legal texts. We evaluate various deep learning models, including domain-specific transformer models like LegalBERT and CaseLawBERT. To assess the efficacy of our deep learning models, we compare them with a state-of-the-art domain-specific statistical conditional random field (CRF) model. After considering model size, F1-score, and inference time, we identify the Convolutional Neural Network Model (CNN) as the top-performing deep learning model. To further enhance performance, we integrate the features of the CNN model into the subsequent CRF model, creating a hybrid architecture that combines the strengths of both models. Our experiments demonstrate that the hybrid model outperforms the baseline model, achieving a 4% improvement in the F1-score. Additional experiments showcase the superiority of the hybrid model over SBD open-source libraries when confronted with an out-of-domain test set. These findings underscore the importance of efficient SBD in legal texts and emphasize the advantages of employing deep learning models and hybrid architectures to achieve optimal performance. © The Author(s), under exclusive licence to Springer Nature B.V. 2024.
KW  - CaseLawBERT
KW  - CNN
KW  - CRF
KW  - Deep learning
KW  - LegalBERT
KW  - Natural language processing
KW  - Sentence boundary detection
KW  - Transformer
PB  - Springer Nature
SN  - 09248463 (ISSN)
LA  - English
J2  - Artif Intell Law
M3  - Article
DB  - Scopus
N1  - Export Date: 01 December 2024; Cited By: 0; Correspondence Address: R. Sheik; National Institute of Technology, Trichy, Tiruchirappalli, Tamil Nadu, India; email: rezmasheik@gmail.com; CODEN: AINLE
ER  -

TY  - JOUR
AU  - Greco, C.M.
AU  - Tagarelli, A.
TI  - Bringing order into the realm of Transformer-based language models for artificial intelligence and law
PY  - 2024
T2  - Artificial Intelligence and Law
VL  - 32
IS  - 4
SP  - 863
EP  - 1010
DO  - 10.1007/s10506-023-09374-7
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177190521&doi=10.1007%2fs10506-023-09374-7&partnerID=40&md5=3822d4420cb24a7e06097a61863aac01
AD  - Department of Computer Engineering, Modeling, Electronics, and Systems Engineering, (DIMES) - University of Calabria, CS, Rende, 87036, Italy
AB  - Transformer-based language models (TLMs) have widely been recognized to be a cutting-edge technology for the successful development of deep-learning-based solutions to problems and applications that require natural language processing and understanding. Like for other textual domains, TLMs have indeed pushed the state-of-the-art of AI approaches for many tasks of interest in the legal domain. Despite the first Transformer model being proposed about six years ago, there has been a rapid progress of this technology at an unprecedented rate, whereby BERT and related models represent a major reference, also in the legal domain. This article provides the first systematic overview of TLM-based methods for AI-driven problems and tasks in the legal sphere. A major goal is to highlight research advances in this field so as to understand, on the one hand, how the Transformers have contributed to the success of AI in supporting legal processes, and on the other hand, what are the current limitations and opportunities for further research development. © The Author(s) 2023.
KW  - AI for law
KW  - Benchmarks
KW  - BERT
KW  - Caselaw data
KW  - Entailment
KW  - GPT
KW  - Inference
KW  - Language models
KW  - Legal document review
KW  - Legal outcome prediction
KW  - Legal search
KW  - Retrieval
KW  - Statutory law data
KW  - Computational linguistics
KW  - Cutting
KW  - Natural language processing systems
KW  - AI for law
KW  - Benchmark
KW  - BERT
KW  - Caselaw
KW  - Caselaw data
KW  - Document review
KW  - Entailment
KW  - GPT
KW  - Inference
KW  - Language model
KW  - Legal document review
KW  - Legal documents
KW  - Legal outcome prediction
KW  - Legal search
KW  - Outcome prediction
KW  - Retrieval
KW  - Statutory law data
KW  - Deep learning
PB  - Springer Nature
SN  - 09248463 (ISSN)
LA  - English
J2  - Artif Intell Law
M3  - Review
DB  - Scopus
N1  - Export Date: 01 December 2024; Cited By: 4; Correspondence Address: A. Tagarelli; Department of Computer Engineering, Modeling, Electronics, and Systems Engineering, (DIMES) - University of Calabria, Rende, CS, 87036, Italy; email: andrea.tagarelli@unical.it; CODEN: AINLE
ER  -

