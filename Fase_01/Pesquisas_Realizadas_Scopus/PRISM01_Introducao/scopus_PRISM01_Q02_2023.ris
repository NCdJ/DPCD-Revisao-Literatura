TY  - JOUR
AU  - Samuelson, P.
TI  - Generative AI meets copyright: Ongoing lawsuits could affect everyone who uses generative AI
PY  - 2023
T2  - Science
VL  - 381
IS  - 6654
SP  - 158
EP  - 161
DO  - 10.1126/science.adi0656
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164843653&doi=10.1126%2fscience.adi0656&partnerID=40&md5=bb4b9e18faef35e0326defeaf9a7fe09
AD  - Berkeley Law School, University of California Berkeley, Berkeley, CA, United States
AB  - Generative artificial intelligence (AI) is a disruptive technology that is widely adopted by members of the general public as well as scientists and technologists who are enthusiastic about the potential to accelerate research in a wide variety of fields. But some professional artists, writers, and programmers fiercely object to the use of their creations as training data for generative AI systems and to outputs that may compete with or displace their works (1, 2). Lack of attribution and compensation for use of their original creations are other sources of aggravation to critics of generative AI.  Copyright lawsuits that are now underway in the United States have substantial implications for the future of generative AI systems. If the plaintiffs prevail, the only generative AI systems that may be lawful in the United States would be those trained on public domain works or under licenses, which will affect everyone who deploys generative AI, integrates it into their products, and uses it for scientific research.
KW  - Copyright
KW  - artificial intelligence
KW  - research work
KW  - technology adoption
KW  - article
KW  - artificial intelligence
KW  - compensation
KW  - disruptive technology
KW  - human
KW  - law suit
KW  - publishing
PB  - American Association for the Advancement of Science
SN  - 00368075 (ISSN)
C2  - 37440639
LA  - English
J2  - Sci.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 62; Correspondence Address: P. Samuelson; Berkeley Law School, University of California Berkeley, Berkeley, United States; email: psamuelson@berkeley.edu; CODEN: SCIEA
ER  -

TY  - JOUR
AU  - Grassini, S.
TI  - Shaping the Future of Education: Exploring the Potential and Consequences of AI and ChatGPT in Educational Settings
PY  - 2023
T2  - Education Sciences
VL  - 13
IS  - 7
C7  - 692
DO  - 10.3390/educsci13070692
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167348375&doi=10.3390%2feducsci13070692&partnerID=40&md5=5509b88120e85bf11de6455f583a1d16
AD  - Department of Psychosocial Science, University of Bergen, Bergen, 5020, Norway
AB  - Over the last decade, technological advancements, especially artificial intelligence (AI), have significantly transformed educational practices. Recently, the development and adoption of Generative Pre-trained Transformers (GPT), particularly OpenAI’s ChatGPT, has sparked considerable interest. The unprecedented capabilities of these models, such as generating humanlike text and facilitating automated conversations, have broad implications in various sectors, including education and health. Despite their immense potential, concerns regarding their widespread use and opacity have been raised within the scientific community. ChatGPT, the latest version of the GPT series, has displayed remarkable proficiency, passed the US bar law exam, and amassed over a million subscribers shortly after its launch. However, its impact on the education sector has elicited mixed reactions, with some educators heralding it as a progressive step and others raising alarms over its potential to reduce analytical skills and promote misconduct. This paper aims to delve into these discussions, exploring the potential and problems associated with applying advanced AI models in education. It builds on extant literature and contributes to understanding how these technologies reshape educational norms in the “new AI gold rush” era. © 2023 by the author.
KW  - artificial intelligence (AI)
KW  - ChatGPT
KW  - educational technology
KW  - university education
PB  - Multidisciplinary Digital Publishing Institute (MDPI)
SN  - 22277102 (ISSN)
LA  - English
J2  - Educ. Sci.
M3  - Review
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 277; Correspondence Address: S. Grassini; Department of Psychosocial Science, University of Bergen, Bergen, 5020, Norway; email: simone.grassini@uib.no
ER  -

TY  - JOUR
AU  - Epstein, Z.
AU  - Hertzmann, A.
AU  - Akten, M.
AU  - Farid, H.
AU  - Fjeld, J.
AU  - Frank, M.R.
AU  - Groh, M.
AU  - Herman, L.
AU  - Leach, N.
AU  - Mahari, R.
AU  - Pentland, A.
AU  - Russakovsky, O.
AU  - Schroeder, H.
AU  - Smith, A.
TI  - Art and the science of generative AI
PY  - 2023
T2  - Science
VL  - 380
IS  - 6650
SP  - 1110
EP  - 1111
DO  - 10.1126/science.adh4451
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163904509&doi=10.1126%2fscience.adh4451&partnerID=40&md5=56e2fb474ae7033e3da4abf51acf3158
AD  - Massachusetts Institute of Technology, Cambridge, MA, United States
AD  - Adobe Research, San Francisco, CA, United States
AD  - University of Washington, Seattle, WA, United States
AD  - University of California, San Diego, San Diego, CA, United States
AD  - University of California, Berkeley, Berkeley, CA, United States
AD  - Harvard Law School, Cambridge, MA, United States
AD  - University of Pittsburgh, Pittsburgh, PA, United States
AD  - University of Oxford, Oxford, United Kingdom
AD  - Adobe, Inc., London, United Kingdom
AD  - Florida International University, Miami, FL, United States
AD  - Princeton University, Princeton, NJ, United States
AD  - Queen Mary University of London, London, United Kingdom
KW  - Artificial Intelligence
KW  - Ecosystem
KW  - artificial intelligence
KW  - research work
KW  - art
KW  - Article
KW  - artificial intelligence
KW  - automation
KW  - human
KW  - image quality
KW  - information processing
KW  - law
KW  - legal aspect
KW  - literature
KW  - music
KW  - patent
KW  - research
KW  - technology
KW  - videorecording
KW  - ecosystem
PB  - American Association for the Advancement of Science
SN  - 00368075 (ISSN)
C2  - 37319193
LA  - English
J2  - Sci.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 138; Correspondence Address: Z. Epstein; Massachusetts Institute of Technology, Cambridge, United States; email: zive@mit.edu; CODEN: SCIEA
ER  -

TY  - JOUR
AU  - Lee, J.Y.
TI  - Can an artificial intelligence chatbot be the author of a scholarly article?
PY  - 2023
T2  - Journal of Educational Evaluation for Health Professions
VL  - 20
C7  - 6
DO  - 10.3352/jeehp.2023.20.6
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149054141&doi=10.3352%2fjeehp.2023.20.6&partnerID=40&md5=0d8d4031df90c9452dc4d30508bc2dd3
AD  - Hanyang University School of Law, Seoul, South Korea
AB  - At the end of 2022, the appearance of ChatGPT, an artificial intelligence (AI) chatbot with amazing writing ability, caused a great sensation in academia. The chatbot turned out to be very capable, but also capable of deception, and the news broke that several researchers had listed the chatbot (including its earlier version) as co-authors of their academic papers. In response, Nature and Science expressed their position that this chatbot cannot be listed as an author in the papers they publish. Since an AI chatbot is not a human being, in the current legal system, the text automatically generated by an AI chatbot cannot be a copyrighted work; thus, an AI chatbot cannot be an author of a copyrighted work. Current AI chatbots such as ChatGPT are much more advanced than search engines in that they produce original text, but they still remain at the level of a search engine in that they cannot take responsibility for their writing. For this reason, they also cannot be authors from the perspective of research ethics. © 2023 Korea Health Personnel Licensing Examination Institute.
KW  - Artificial intelligence
KW  - Authorship
KW  - Chatbot
KW  - Copyright
KW  - Research ethics
KW  - Artificial Intelligence
KW  - Humans
KW  - Publishing
KW  - Software
KW  - artificial intelligence
KW  - human
KW  - publishing
KW  - software
PB  - Korea Health Personnel Licensing Examination Institute
SN  - 19755937 (ISSN)
C2  - 36842449
LA  - English
J2  - J. Edu. Eval. Health Prof.
M3  - Review
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 67; Correspondence Address: J.Y. Lee; Hanyang University School of Law, Seoul, South Korea; email: rosa729@hanyang.ac.kr
ER  -

TY  - JOUR
AU  - Desislavov, R.
AU  - Martínez-Plumed, F.
AU  - Hernández-Orallo, J.
TI  - Trends in AI inference energy consumption: Beyond the performance-vs-parameter laws of deep learning
PY  - 2023
T2  - Sustainable Computing: Informatics and Systems
VL  - 38
C7  - 100857
DO  - 10.1016/j.suscom.2023.100857
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149369873&doi=10.1016%2fj.suscom.2023.100857&partnerID=40&md5=3d5531eb21c00745c9ed34cb6d5fc743
AD  - VRAIN, Universitat Politecnica de Valencia, Spain
AB  - The progress of some AI paradigms such as deep learning is said to be linked to an exponential growth in the number of parameters. There are many studies corroborating these trends, but does this translate into an exponential increase in energy consumption? In order to answer this question we focus on inference costs rather than training costs, as the former account for most of the computing effort, solely because of the multiplicative factors. Also, apart from algorithmic innovations, we account for more specific and powerful hardware (leading to higher FLOPS) that is usually accompanied with important energy efficiency optimisations. We also move the focus from the first implementation of a breakthrough paper towards the consolidated version of the techniques one or two year later. Under this distinctive and comprehensive perspective, we analyse relevant models in the areas of computer vision and natural language processing: for a sustained increase in performance we see a much softer growth in energy consumption than previously anticipated. The only caveat is, yet again, the multiplicative factor, as future AI increases penetration and becomes more pervasive. © 2023 The Author(s)
KW  - AI progress
KW  - Artificial Intelligence
KW  - Deep learning
KW  - Energy consumption
KW  - Inference
KW  - Performance analysis
KW  - Performance evaluation
KW  - Deep learning
KW  - Energy efficiency
KW  - Natural language processing systems
KW  - AI progress
KW  - Deep learning
KW  - Energy-consumption
KW  - Exponential growth
KW  - Exponential increase
KW  - Inference
KW  - Multiplicative factors
KW  - Performance
KW  - Performances analysis
KW  - Performances evaluation
KW  - Energy utilization
PB  - Elsevier Inc.
SN  - 22105379 (ISSN)
LA  - English
J2  - Sustainable Computing: Informatics and Systems
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 71; Correspondence Address: F. Martínez-Plumed; email: fmartinez@dsic.upv.es
ER  -

TY  - JOUR
AU  - Díaz-Rodríguez, N.
AU  - Del Ser, J.
AU  - Coeckelbergh, M.
AU  - López de Prado, M.
AU  - Herrera-Viedma, E.
AU  - Herrera, F.
TI  - Connecting the dots in trustworthy Artificial Intelligence: From AI principles, ethics, and key requirements to responsible AI systems and regulation
PY  - 2023
T2  - Information Fusion
VL  - 99
C7  - 101896
DO  - 10.1016/j.inffus.2023.101896
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165229141&doi=10.1016%2fj.inffus.2023.101896&partnerID=40&md5=227e799a222807d695482be476e999d8
AD  - Department of Computer Science and Artificial Intelligence, DaSCI Andalusian Institute in Data Science and Computational Intelligence, University of Granada, Granada, 18071, Spain
AD  - TECNALIA, Basque Research and Technology Alliance (BRTA), Derio, 48160, Spain
AD  - Department of Communications Engineering, University of the Basque Country (UPV/EHU), Bilbao, 48013, Spain
AD  - Department of Philosophy, University of Vienna, Vienna, 1010, Austria
AD  - School of Engineering, Cornell University, Ithaca, 14850, NY, United States
AD  - ADIA Lab, Al Maryah Island, Abu Dhabi, United Arab Emirates
AD  - Department of Mathematics, Khalifa University of Science and Technology, Abu Dhabi, United Arab Emirates
AB  - Trustworthy Artificial Intelligence (AI) is based on seven technical requirements sustained over three main pillars that should be met throughout the system's entire life cycle: it should be (1) lawful, (2) ethical, and (3) robust, both from a technical and a social perspective. However, attaining truly trustworthy AI concerns a wider vision that comprises the trustworthiness of all processes and actors that are part of the system's life cycle, and considers previous aspects from different lenses. A more holistic vision contemplates four essential axes: the global principles for ethical use and development of AI-based systems, a philosophical take on AI ethics, a risk-based approach to AI regulation, and the mentioned pillars and requirements. The seven requirements (human agency and oversight; robustness and safety; privacy and data governance; transparency; diversity, non-discrimination and fairness; societal and environmental wellbeing; and accountability) are analyzed from a triple perspective: What each requirement for trustworthy AI is, Why it is needed, and How each requirement can be implemented in practice. On the other hand, a practical approach to implement trustworthy AI systems allows defining the concept of responsibility of AI-based systems facing the law, through a given auditing process. Therefore, a responsible AI system is the resulting notion we introduce in this work, and a concept of utmost necessity that can be realized through auditing processes, subject to the challenges posed by the use of regulatory sandboxes. Our multidisciplinary vision of trustworthy AI culminates in a debate on the diverging views published lately about the future of AI. Our reflections in this matter conclude that regulation is a key for reaching a consensus among these views, and that trustworthy and responsible AI systems will be crucial for the present and future of our society. © 2023 The Author(s)
KW  - AI ethics
KW  - AI regulation
KW  - Regulatory sandbox
KW  - Responsible AI systems
KW  - Trustworthy AI
KW  - Ethical technology
KW  - Life cycle
KW  - Artificial intelligence ethic
KW  - Artificial intelligence regulation
KW  - Artificial intelligence systems
KW  - Auditing process
KW  - Entire life cycles
KW  - Regulatory sandbox
KW  - Responsible artificial intelligence system
KW  - Social perspective
KW  - Technical requirement
KW  - Trustworthy artificial intelligence
KW  - Artificial intelligence
PB  - Elsevier B.V.
SN  - 15662535 (ISSN)
LA  - English
J2  - Inf. Fusion
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 128; Correspondence Address: N. Díaz-Rodríguez; Department of Computer Science and Artificial Intelligence, DaSCI Andalusian Institute in Data Science and Computational Intelligence, University of Granada, Granada, 18071, Spain; email: nataliadiaz@ugr.es; J. Del Ser; Department of Computer Science and Artificial Intelligence, DaSCI Andalusian Institute in Data Science and Computational Intelligence, University of Granada, Granada, 18071, Spain; email: javier.delser@ehu.eus
ER  -

TY  - JOUR
AU  - Zhang, J.
AU  - Zhang, Z.-M.
TI  - Ethics and governance of trustworthy medical artificial intelligence
PY  - 2023
T2  - BMC Medical Informatics and Decision Making
VL  - 23
IS  - 1
C7  - 7
DO  - 10.1186/s12911-023-02103-9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146278182&doi=10.1186%2fs12911-023-02103-9&partnerID=40&md5=0ab4729ed84e430bdec9d013c5f6179d
AD  - Institute of Literature in Chinese Medicine, Nanjing University of Chinese Medicine, Nanjing, 210023, China
AD  - Nantong University Xinglin College, Nantong, 226236, China
AD  - Research Center of Chinese Medicine Culture, Nanjing University of Chinese Medicine, Nanjing, 210023, China
AB  - Background: The growing application of artificial intelligence (AI) in healthcare has brought technological breakthroughs to traditional diagnosis and treatment, but it is accompanied by many risks and challenges. These adverse effects are also seen as ethical issues and affect trustworthiness in medical AI and need to be managed through identification, prognosis and monitoring. Methods: We adopted a multidisciplinary approach and summarized five subjects that influence the trustworthiness of medical AI: data quality, algorithmic bias, opacity, safety and security, and responsibility attribution, and discussed these factors from the perspectives of technology, law, and healthcare stakeholders and institutions. The ethical framework of ethical values-ethical principles-ethical norms is used to propose corresponding ethical governance countermeasures for trustworthy medical AI from the ethical, legal, and regulatory aspects. Results: Medical data are primarily unstructured, lacking uniform and standardized annotation, and data quality will directly affect the quality of medical AI algorithm models. Algorithmic bias can affect AI clinical predictions and exacerbate health disparities. The opacity of algorithms affects patients’ and doctors’ trust in medical AI, and algorithmic errors or security vulnerabilities can pose significant risks and harm to patients. The involvement of medical AI in clinical practices may threaten doctors ‘and patients’ autonomy and dignity. When accidents occur with medical AI, the responsibility attribution is not clear. All these factors affect people’s trust in medical AI. Conclusions: In order to make medical AI trustworthy, at the ethical level, the ethical value orientation of promoting human health should first and foremost be considered as the top-level design. At the legal level, current medical AI does not have moral status and humans remain the duty bearers. At the regulatory level, strengthening data quality management, improving algorithm transparency and traceability to reduce algorithm bias, and regulating and reviewing the whole process of the AI industry to control risks are proposed. It is also necessary to encourage multiple parties to discuss and assess AI risks and social impacts, and to strengthen international cooperation and communication. © 2023, The Author(s).
KW  - Algorithms
KW  - Artificial intelligence
KW  - Data
KW  - Ethics
KW  - Governance
KW  - Healthcare
KW  - Regulation
KW  - Responsibility attribution
KW  - Algorithms
KW  - Artificial Intelligence
KW  - Data Management
KW  - Delivery of Health Care
KW  - Humans
KW  - Prognosis
KW  - accident
KW  - adult
KW  - algorithm bias
KW  - article
KW  - artificial intelligence
KW  - clinical article
KW  - clinical practice
KW  - controlled study
KW  - data quality
KW  - ethics
KW  - female
KW  - health disparity
KW  - human
KW  - human dignity
KW  - international cooperation
KW  - male
KW  - moral status
KW  - prediction
KW  - responsibility
KW  - risk assessment
KW  - security
KW  - trust
KW  - value orientation
KW  - vulnerability
KW  - algorithm
KW  - health care delivery
KW  - information processing
KW  - prognosis
PB  - BioMed Central Ltd
SN  - 14726947 (ISSN)
C2  - 36639799
LA  - English
J2  - BMC Med. Informatics Decis. Mak.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 118; Correspondence Address: Z.-M. Zhang; Research Center of Chinese Medicine Culture, Nanjing University of Chinese Medicine, Nanjing, 210023, China; email: zhangzongming23@163.com
ER  -

TY  - JOUR
AU  - Dave, T.
AU  - Athaluri, S.A.
AU  - Singh, S.
TI  - ChatGPT in medicine: an overview of its applications, advantages, limitations, future prospects, and ethical considerations
PY  - 2023
T2  - Frontiers in Artificial Intelligence
VL  - 6
C7  - 1169595
DO  - 10.3389/frai.2023.1169595
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159929831&doi=10.3389%2ffrai.2023.1169595&partnerID=40&md5=eba03afa56e5f070623fe4f8ef51c4a8
AD  - Internal Medicine, Bukovinian State Medical University, Chernivtsi, Ukraine
AD  - Rangaraya Medical College, Andhra Pradesh, Kakinada, India
AD  - GSVM Medical College, Uttar Pradesh, Kanpur, India
AB  - This paper presents an analysis of the advantages, limitations, ethical considerations, future prospects, and practical applications of ChatGPT and artificial intelligence (AI) in the healthcare and medical domains. ChatGPT is an advanced language model that uses deep learning techniques to produce human-like responses to natural language inputs. It is part of the family of generative pre-training transformer (GPT) models developed by OpenAI and is currently one of the largest publicly available language models. ChatGPT is capable of capturing the nuances and intricacies of human language, allowing it to generate appropriate and contextually relevant responses across a broad spectrum of prompts. The potential applications of ChatGPT in the medical field range from identifying potential research topics to assisting professionals in clinical and laboratory diagnosis. Additionally, it can be used to help medical students, doctors, nurses, and all members of the healthcare fraternity to know about updates and new developments in their respective fields. The development of virtual assistants to aid patients in managing their health is another important application of ChatGPT in medicine. Despite its potential applications, the use of ChatGPT and other AI tools in medical writing also poses ethical and legal concerns. These include possible infringement of copyright laws, medico-legal complications, and the need for transparency in AI-generated content. In conclusion, ChatGPT has several potential applications in the medical and healthcare fields. However, these applications come with several limitations and ethical considerations which are presented in detail along with future prospects in medicine and healthcare. Copyright © 2023 Dave, Athaluri and Singh.
KW  - AI
KW  - artificial intelligence
KW  - ChatGPT
KW  - generative pre-training transformer
KW  - healthcare
KW  - medicine
KW  - natural language processing
PB  - Frontiers Media S.A.
SN  - 26248212 (ISSN)
LA  - English
J2  - Frontier. Artif. Intell.
M3  - Short survey
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 484; Correspondence Address: T. Dave; Internal Medicine, Bukovinian State Medical University, Chernivtsi, Ukraine; email: tirth.snehal.dave@gmail.com
ER  -

TY  - CONF
AU  - Hacker, P.
AU  - Engel, A.
AU  - Mauer, M.
TI  - Regulating ChatGPT and other Large Generative AI Models
PY  - 2023
T2  - ACM International Conference Proceeding Series
SP  - 1112
EP  - 1123
DO  - 10.1145/3593013.3594067
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163696061&doi=10.1145%2f3593013.3594067&partnerID=40&md5=143c89dfe19e5fd9fa0d4c16b9a44336
AD  - European New School of Digital Studies, European University Viadrina, Germany
AD  - Faculty of Law, Heidelberg University, Germany
AD  - Faculty of Law, Humboldt-University of Berlin, Germany
AB  - Large generative AI models (LGAIMs), such as ChatGPT, GPT-4 or Stable Diffusion, are rapidly transforming the way we communicate, illustrate, and create. However, AI regulation, in the EU and beyond, has primarily focused on conventional AI models, not LGAIMs. This paper will situate these new generative models in the current debate on trustworthy AI regulation, and ask how the law can be tailored to their capabilities. After laying technical foundations, the legal part of the paper proceeds in four steps, covering (1) direct regulation, (2) data protection, (3) content moderation, and (4) policy proposals. It suggests a novel terminology to capture the AI value chain in LGAIM settings by differentiating between LGAIM developers, deployers, professional and non-professional users, as well as recipients of LGAIM output. We tailor regulatory duties to these different actors along the value chain and suggest strategies to ensure that LGAIMs are trustworthy and deployed for the benefit of society at large. Rules in the AI Act and other direct regulation must match the specificities of pre-trained models. The paper argues for three layers of obligations concerning LGAIMs (minimum standards for all LGAIMs; high-risk obligations for high-risk use cases; collaborations along the AI value chain). In general, regulation should focus on concrete high-risk applications, and not the pre-trained model itself, and should include (i) obligations regarding transparency and (ii) risk management. Non-discrimination provisions (iii) may, however, apply to LGAIM developers. Lastly, (iv) the core of the DSA's content moderation rules should be expanded to cover LGAIMs. This includes notice and action mechanisms, and trusted flaggers. © 2023 Owner/Author.
KW  - Laws and legislation
KW  - 'current
KW  - Action mechanisms
KW  - Generative model
KW  - Model outputs
KW  - Non-professional users
KW  - Risks management
KW  - Three-layer
KW  - Value chains
KW  - Risk management
PB  - Association for Computing Machinery
SN  - 978-145037252-7 (ISBN)
LA  - English
J2  - ACM Int. Conf. Proc. Ser.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 151; Conference name: 6th ACM Conference on Fairness, Accountability, and Transparency, FAccT 2023; Conference date: 12 June 2023 through 15 June 2023; Conference code: 189310
ER  -

TY  - JOUR
AU  - Zhang, P.
AU  - Kamel Boulos, M.N.
TI  - Generative AI in Medicine and Healthcare: Promises, Opportunities and Challenges
PY  - 2023
T2  - Future Internet
VL  - 15
IS  - 9
C7  - 286
DO  - 10.3390/fi15090286
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172098857&doi=10.3390%2ffi15090286&partnerID=40&md5=51a4bb61407a6aa6e76da3490a218e68
AD  - Department of Computer Science and Data Science Institute, Vanderbilt University, Nashville, 37240, TN, United States
AD  - School of Medicine, University of Lisbon, Lisbon, 1649-028, Portugal
AB  - Generative AI (artificial intelligence) refers to algorithms and models, such as OpenAI’s ChatGPT, that can be prompted to generate various types of content. In this narrative review, we present a selection of representative examples of generative AI applications in medicine and healthcare. We then briefly discuss some associated issues, such as trust, veracity, clinical safety and reliability, privacy, copyrights, ownership, and opportunities, e.g., AI-driven conversational user interfaces for friendlier human-computer interaction. We conclude that generative AI will play an increasingly important role in medicine and healthcare as it further evolves and gets better tailored to the unique settings and requirements of the medical domain and as the laws, policies and regulatory frameworks surrounding its use start taking shape. © 2023 by the authors.
KW  - artificial intelligence
KW  - ChatGPT
KW  - generative AI
KW  - healthcare
KW  - human health
KW  - large language models
KW  - medicine
KW  - Artificial intelligence
KW  - Health care
KW  - Human computer interaction
KW  - Artificial intelligence in medicine
KW  - ChatGPT
KW  - Generative artificial intelligence
KW  - Healthcare
KW  - Human health
KW  - Language model
KW  - Large language model
KW  - Medical domains
KW  - Policy framework
KW  - Regulatory frameworks
KW  - User interfaces
PB  - Multidisciplinary Digital Publishing Institute (MDPI)
SN  - 19995903 (ISSN)
LA  - English
J2  - Future Internet
M3  - Review
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 78; Correspondence Address: M.N. Kamel Boulos; School of Medicine, University of Lisbon, Lisbon, 1649-028, Portugal; email: mnkboulos@ieee.org
ER  -

