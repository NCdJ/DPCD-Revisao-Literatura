TY  - JOUR
AU  - Mökander, J.
AU  - Floridi, L.
TI  - Ethics-Based Auditing to Develop Trustworthy AI
PY  - 2021
T2  - Minds and Machines
VL  - 31
IS  - 2
SP  - 323
EP  - 327
DO  - 10.1007/s11023-021-09557-8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101235767&doi=10.1007%2fs11023-021-09557-8&partnerID=40&md5=fd0798bd641fc40ff798d32dbbed2c5e
AD  - Oxford Internet Institute, University of Oxford, 1 St Giles’, Oxford, OX1 3JS, United Kingdom
AD  - Alan Turing Institute, British Library, 96 Euston Rd, London, NW1 2DB, United Kingdom
AB  - A series of recent developments points towards auditing as a promising mechanism to bridge the gap between principles and practice in AI ethics. Building on ongoing discussions concerning ethics-based auditing, we offer three contributions. First, we argue that ethics-based auditing can improve the quality of decision making, increase user satisfaction, unlock growth potential, enable law-making, and relieve human suffering. Second, we highlight current best practices to support the design and implementation of ethics-based auditing: To be feasible and effective, ethics-based auditing should take the form of a continuous and constructive process, approach ethical alignment from a system perspective, and be aligned with public policies and incentives for ethically desirable behaviour. Third, we identify and discuss the constraints associated with ethics-based auditing. Only by understanding and accounting for these constraints can ethics-based auditing facilitate ethical alignment of AI, while enabling society to reap the full economic and social benefits of automation. © 2021, The Author(s).
KW  - Artificial intelligence
KW  - Auditing
KW  - Best practice
KW  - Ethics
KW  - Governance
KW  - Process
PB  - Springer Science and Business Media B.V.
SN  - 09246495 (ISSN)
LA  - English
J2  - Minds Mach
M3  - Note
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 70; Correspondence Address: J. Mökander; Oxford Internet Institute, University of Oxford, Oxford, 1 St Giles’, OX1 3JS, United Kingdom; email: jakob.mokander@oii.ox.ac.uk; CODEN: MMACE
ER  -

TY  - CONF
AU  - Saxena, M.
AU  - Bagga, T.
AU  - Gupta, S.
TI  - Hr during covid-19 era: Study on recent HR transformations through technological tools and trends
PY  - 2021
T2  - Proceedings of the Confluence 2021: 11th International Conference on Cloud Computing, Data Science and Engineering
C7  - 9377167
SP  - 110
EP  - 113
DO  - 10.1109/Confluence51648.2021.9377167
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103851615&doi=10.1109%2fConfluence51648.2021.9377167&partnerID=40&md5=3523940bbf959f258503ded943006898
AD  - ABS, Amity University, Noida, India
AD  - Amity Business School, Amity University, Noida, India
AD  - M.E.R.I, Delhi, India
AB  - The recent COVID-19 pandemic has created grand challenges for many be it a health and pharmaceutical industry, law chambers, educational institutions, FMCG, banking, small – micro units or suppliers - transportation units. Every single organization of any size or category, faced challenges in one or other form, leaving workforce to adapt and adopt the new online work culture and advocate technology integration to their profiles. AI, Machine Learning, Talent Analytics, Automation, IoT, Gamification are recent up gradations for HRs, where HRs are pushing hard to keep up with the pace of technologies to manage employees remotely, cost cutting and developing Culture-Tech platform. The primary study was made with 64 HRs of Indian Service Industry to study the recent HR technology integration during COVID-19 to able to manage crisis, employees, projects and their own jobs. © 2021 IEEE
KW  - AI
KW  - COVID-19
KW  - HRM
KW  - Machine Learning
KW  - People Analytics
KW  - Technology
KW  - Cloud computing
KW  - Data Science
KW  - Service industry
KW  - Cost cuttings
KW  - Educational institutions
KW  - Grand Challenge
KW  - Online work
KW  - Pharmaceutical industry
KW  - Technological tools
KW  - Technology Integration
KW  - Up gradations
KW  - Personnel
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-073813160-3 (ISBN)
LA  - English
J2  - Proc. Conflu.: Int. Conf. Cloud Comput., Data Sci. Eng.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 8; Conference name: 11th International Conference on Cloud Computing, Data Science and Engineering, Confluence 2021; Conference date: 28 January 2021 through 29 January 2021; Conference code: 167955
ER  -

TY  - JOUR
AU  - Vermesan, O.
AU  - John, R.
AU  - Pype, P.
AU  - Daalderop, G.
AU  - Kriegel, K.
AU  - Mitic, G.
AU  - Lorentz, V.
AU  - Bahr, R.
AU  - Sand, H.E.
AU  - Bockrath, S.
AU  - Waldhör, S.
TI  - Automotive Intelligence Embedded in Electric Connected Autonomous and Shared Vehicles Technology for Sustainable Green Mobility
PY  - 2021
T2  - Frontiers in Future Transportation
VL  - 2
C7  - 688482
DO  - 10.3389/ffutr.2021.688482
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136929816&doi=10.3389%2fffutr.2021.688482&partnerID=40&md5=22a2f1ad043bfa9dcced49a387c06364
AD  - SINTEF Digital AS, Oslo, Norway
AD  - AVL List GmbH, Graz, Austria
AD  - NXP Semiconductors, Leuven, Belgium
AD  - Siemens AG, Munich, Germany
AD  - Fraunhofer IISB, Erlangen, Germany
AD  - NxTech AS, Fredrikstad, Norway
AB  - The automotive sector digitalization accelerates the technology convergence of perception, computing processing, connectivity, propulsion, and data fusion for electric connected autonomous and shared (ECAS) vehicles. This brings cutting-edge computing paradigms with embedded cognitive capabilities into vehicle domains and data infrastructure to provide holistic intrinsic and extrinsic intelligence for new mobility applications. Digital technologies are a significant enabler in achieving the sustainability goals of the green transformation of the mobility and transportation sectors. Innovation occurs predominantly in ECAS vehicles’ architecture, operations, intelligent functions, and automotive digital infrastructure. The traditional ownership model is moving toward multimodal and shared mobility services. The ECAS vehicle’s technology allows for the development of virtual automotive functions that run on shared hardware platforms with data unlocking value, and for introducing new, shared computing-based automotive features. Facilitating vehicle automation, vehicle electrification, vehicle-to-everything (V2X) communication is accomplished by the convergence of artificial intelligence (AI), cellular/wireless connectivity, edge computing, the Internet of things (IoT), the Internet of intelligent things (IoIT), digital twins (DTs), virtual/augmented reality (VR/AR) and distributed ledger technologies (DLTs). Vehicles become more intelligent, connected, functioning as edge micro servers on wheels, powered by sensors/actuators, hardware (HW), software (SW) and smart virtual functions that are integrated into the digital infrastructure. Electrification, automation, connectivity, digitalization, decarbonization, decentralization, and standardization are the main drivers that unlock intelligent vehicles' potential for sustainable green mobility applications. ECAS vehicles act as autonomous agents using swarm intelligence to communicate and exchange information, either directly or indirectly, with each other and the infrastructure, accessing independent services such as energy, high-definition maps, routes, infrastructure information, traffic lights, tolls, parking (micropayments), and finding emergent/intelligent solutions. The article gives an overview of the advances in AI technologies and applications to realize intelligent functions and optimize vehicle performance, control, and decision-making for future ECAS vehicles to support the acceleration of deployment in various mobility scenarios. ECAS vehicles, systems, sub-systems, and components are subjected to stringent regulatory frameworks, which set rigorous requirements for autonomous vehicles. An in-depth assessment of existing standards, regulations, and laws, including a thorough gap analysis, is required. Global guidelines must be provided on how to fulfill the requirements. ECAS vehicle technology trustworthiness, including AI-based HW/SW and algorithms, is necessary for developing ECAS systems across the entire automotive ecosystem. The safety and transparency of AI-based technology and the explainability of the purpose, use, benefits, and limitations of AI systems are critical for fulfilling trustworthiness requirements. The article presents ECAS vehicles’ evolution toward domain controller, zonal vehicle, and federated vehicle/edge/cloud-centric based on distributed intelligence in the vehicle and infrastructure level architectures and the role of AI techniques and methods to implement the different autonomous driving and optimization functions for sustainable green mobility. Copyright © 2021 Vermesan, John, Pype, Daalderop, Kriegel, Mitic, Lorentz, Bahr, Sand, Bockrath and Waldhör.
KW  - artificial intelligence
KW  - automotive architectures
KW  - edge computing
KW  - electric connected autonomous and shared vehicles
KW  - green mobility
KW  - internet of vehicles
KW  - swarm intelligence
KW  - vehicle-to-everything communication
PB  - Frontiers Media SA
SN  - 26735210 (ISSN)
LA  - English
J2  - Front. Future Transp.
M3  - Review
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 28; Correspondence Address: O. Vermesan; SINTEF Digital AS, Oslo, Norway; email: Ovidiu.Vermesan@sintef.no
ER  -

TY  - CONF
AU  - Mitrou, L.
AU  - Janssen, M.
AU  - Loukis, E.
TI  - Human Control and Discretion in AI-driven Decision-making in Government
PY  - 2021
T2  - ACM International Conference Proceeding Series
SP  - 10
EP  - 16
DO  - 10.1145/3494193.3494195
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122976069&doi=10.1145%2f3494193.3494195&partnerID=40&md5=8e06abd8160154e401b34da9d56e715b
AD  - University of the Aegean, Greece
AD  - Delft University of Technology, Netherlands
AB  - Traditionally public decision-makers have been given discretion in many of the decisions they have to make in how to comply with legislation and policies. In this way, the context and specific circumstances can be taken into account when making decisions. This enables more acceptable solutions, but at the same time, discretion might result in treating individuals differently. With the advance of AI-based decisions, the role of the decision-makers is changing. The automation might result in fully automated decisions, humans-in-the-loop or AI might only be used as recommender systems in which humans have the discretion to deviate from the suggested decision. The predictability of and the accountability of the decisions might vary in these circumstances, although humans always remain accountable. Hence, there is a need for human-control and the decision-makers should be given sufficient authority to control the system and deal with undesired outcomes. In this direction this paper analyzes the degree of discretion and human control needed in AI-driven decision-making in government. Our analysis is based on the legal requirements set/posed to the administration, by the extensive legal frameworks that have been created for its operation, concerning the rule of law, the fairness-non-discrimination, the justifiability and accountability, and the certainty/predictability.  © 2021 ACM.
KW  - Artificial intelligence
KW  - Laws and legislation
KW  - Decision makers
KW  - Decisions makings
KW  - Fully automated
KW  - Human control
KW  - Human-in-the-loop
KW  - Legal frameworks
KW  - Legal requirements
KW  - Making decision
KW  - Paper analysis
KW  - Decision making
A2  - Loukis E.
PB  - Association for Computing Machinery
SN  - 978-145039011-8 (ISBN)
LA  - English
J2  - ACM Int. Conf. Proc. Ser.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 6; Conference name: 14th International Conference on Theory and Practice of Electronic Governance, ICEGOV 2021; Conference date: 6 October 2021 through 8 October 2021; Conference code: 176270
ER  -

TY  - JOUR
AU  - Calderon-Valencia, F.
AU  - Perez-Montoya, J.J.
AU  - De Morais, F.S.
TI  - AI Systems in Brazilian Supreme Federal Court and the Colombian Constitutional Court Experiences: Prospective Analysis
ST  - Sistemas De Ia En La Experiencia Del Supremo Tribunal Federal BrasileÑO Y La Corte Constitucional Colombiana: AnÁLisis Prospectivo
PY  - 2021
T2  - Revista de Direito, Estado e Telecomunicacoes
VL  - 13
IS  - 1
SP  - 143
EP  - 169
DO  - 10.26512/lstr.v13i1.35614
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107534301&doi=10.26512%2flstr.v13i1.35614&partnerID=40&md5=78ff65d45c0aa95acbd85ba4ebb69e21
AD  - Universidad de Medellín, Colombia
AD  - Universidad Externado de Colombia, Colombia
AB  - Purpose-To carry out a prospective analysis of the experience of the Supreme Federal Court (STF) and the Colombian Constitutional Court (CCC) with Artificial Intelligence (AI). Methodology-In terms of methodology, we use the qualitative approach, where the data analysis technique is discourse analysis and the unit of analysis are official documents and reports related to disruptive technologies for judicial use, emphasizing those dedicated to "experience"Colombian with the Pretoria AI. Findings-In Latin America, AI Systems, such as Victor and PretorIA, are automation tools supporting synthesis and prediction tasks in the supreme courts in Brazil and Colombia. However, they are not magic solutions to solve judicial congestion, although the 4th Industrial Revolution bring progress for positive changes. The significant challenges, however, are also in law theory through an ethical framework for the development, design, and operational work of AI. Nevertheless, our comprehension of those systems remains limited. For this reason, supreme courts must observe positive law and ethics to avoid a tyranny of the code, avoiding their impact over law sources', preventing an algorithm from "deciding"the criteria for applying the law. Thus, supreme courts need to calibrate and influence its design, preventing its obsolescence, but, above all, preventing human dignity obsolescence, human labor, and power of deliberation. All these are essential for shaping version 4.0 of the Social Rule of Law. Practical implications-Promote the engagement of magistrates and citizenship in design and programming of AI Systems for supreme courts' use, within an ethical framework that prevents human beings, their values, and their rights' obsolescence. Originality-This paper analyzes AI Systems used to solve supreme courts' problems in Brazil and Colombia, studying how they work, but also its additional features considering theories that allow affirming that programming and design are subject to the Rule of Law rules and a Human Rights oriented ethical framework. © 2021 The Author(s).
KW  - AI Systems
KW  - Brazilian Supreme Federal Court's Victor
KW  - Colombian Constitutional Court's PretorIA
KW  - Ethical framework of AI
KW  - Justice and 4th Industrial Revolution
PB  - Universidade de Brasilia
SN  - 19849729 (ISSN)
LA  - Spanish
J2  - Rev. Direito Estado Telecomunicacoes
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 5
ER  -

TY  - CONF
AU  - Ehsan, U.
AU  - Wintersberger, P.
AU  - Liao, Q.V.
AU  - Mara, M.
AU  - Streit, M.
AU  - Wachter, S.
AU  - Riener, A.
AU  - Riedl, M.O.
TI  - Operationalizing Human-Centered Perspectives in Explainable AI
PY  - 2021
T2  - Conference on Human Factors in Computing Systems - Proceedings
DO  - 10.1145/3411763.3441342
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105803279&doi=10.1145%2f3411763.3441342&partnerID=40&md5=e41ca57fde9fe93f5f9919d289225a73
AD  - Georgia Institute OfGeorgia, Institute of Technology, Atlanta, GA, United States
AD  - Carissma Technische Hochschule Ingolstadt (THI) Ingolstadt, Bavaria, Germany
AD  - Ibm Research Ai Yorktown, Heights, NY, United States
AD  - Johannes Kepler University Linz, Linz Upper, Austria
AD  - Johannes Kepler University LinzJohannes Kepler, University Linz, Linz Upper, Austria
AD  - Oxford Internet Institute, University of Oxford Oxford England, United Kingdom
AD  - Technische Hochschule Ingolstadt (THI) Ingolstadt, Bavaria, Germany
AD  - Georgia Institute of Technology, Atlanta, GA, United States
AB  - The realm of Artificial Intelligence (AI)'s impact on our lives is far reaching - with AI systems proliferating high-stakes domains such as healthcare, finance, mobility, law, etc., these systems must be able to explain their decision to diverse end-users comprehensibly. Yet the discourse of Explainable AI (XAI) has been predominantly focused on algorithm-centered approaches, suffering from gaps in meeting user needs and exacerbating issues of algorithmic opacity. To address these issues, researchers have called for human-centered approaches to XAI. There is a need to chart the domain and shape the discourse of XAI with reflective discussions from diverse stakeholders. The goal of this workshop is to examine how human-centered perspectives in XAI can be operationalized at the conceptual, methodological, and technical levels. Encouraging holistic (historical, sociological, and technical) approaches, we put an emphasis on "operationalizing", aiming to produce actionable frameworks, transferable evaluation methods, concrete design guidelines, and articulate a coordinated research agenda for XAI. © 2021 Owner/Author.
KW  - Algorithmic Fairness
KW  - Artificial Intelligence
KW  - Critical Technical Practice
KW  - Explainable Artificial Intelligence
KW  - Human-centered Computing
KW  - Interpretability
KW  - Interpretable Machine Learning
KW  - Trust in Automation
KW  - Human engineering
KW  - AI systems
KW  - Concrete design
KW  - End users
KW  - Evaluation methods
KW  - Research agenda
KW  - Technical levels
KW  - User need
KW  - Artificial intelligence
PB  - Association for Computing Machinery
SN  - 978-145038095-9 (ISBN)
LA  - English
J2  - Conf Hum Fact Comput Syst Proc
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 77; Conference name: 2021 CHI Conference on Human Factors in Computing Systems: Making Waves, Combining Strengths, CHI EA 2021; Conference date: 8 May 2021 through 13 May 2021; Conference code: 168787
ER  -

TY  - CONF
AU  - Wong, A.
TI  - Ethics and Regulation of Artificial Intelligence
PY  - 2021
T2  - IFIP Advances in Information and Communication Technology
VL  - 614
SP  - 1
EP  - 18
DO  - 10.1007/978-3-030-80847-1_1
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112133856&doi=10.1007%2f978-3-030-80847-1_1&partnerID=40&md5=f9de980b8df61e854efcb347459b6b56
AD  - AGW Legal & Advisory, Sydney, Australia
AD  - IFIP, Laxenburg, Austria
AD  - Australian Computer Society (ACS), Sydney, Australia
AB  - Over the last few years, the world has deliberated and developed numerous ethical principles and frameworks. It is the general opinion that the time has arrived to move from principles and to operationalize on the ethical practice of AI. It is now recognized that principles and standards can play a universal harmonizing role for the development of AI-related legal norms across the globe. However, how do we translate and embrace these articulated values, principles and actions to guide Nation States around the world to formulate their regulatory systems, policies or other legal instruments regarding AI? Our regulatory systems have attempted to keep abreast of new technologies by recalibrating and adapting our regulatory frameworks to provide for new opportunities and risks, to confer rights and duties, safety and liability frameworks, and to ensure legal certainty for businesses. These past adaptations have been reactive and sometimes piecemeal, often with artificial delineation on rights and responsibilities and with unintended flow-on consequences. Previously, technologies have been deployed more like tools, but as autonomy and self-learning capabilities increase, robots and intelligent AI systems will feel less and less like machines and tools. There is now a significant difference, because machine learning AI systems have the ability ‘to learn’, adapt their performances and ‘make decisions’ from data and ‘life experiences’. This paper presented at the International Joint Conference on Artificial Intelligence - Pacific Rim International Conference on Artificial Intelligence in 2021 provides brief insights on some selected topical developments in ethical principles and frameworks, our regulatory systems and the current debates on some of the risks and challenges from the use and actions of AI, autonomous and intelligent systems [1]. © 2021, IFIP International Federation for Information Processing.
KW  - AI
KW  - Automation
KW  - Data protection
KW  - Employment
KW  - Ethics
KW  - Explainability
KW  - Job transition
KW  - Law
KW  - Legal personhood
KW  - Liability
KW  - Privacy
KW  - Regulation
KW  - Robots
KW  - Transparency
KW  - End effectors
KW  - Intelligent systems
KW  - Knowledge management
KW  - Philosophical aspects
KW  - Ethical practices
KW  - Ethical principles
KW  - Legal instruments
KW  - Life experiences
KW  - Regulatory frameworks
KW  - Regulatory systems
KW  - Rights and responsibilities
KW  - Self-learning capability
KW  - Learning systems
A2  - Mercier-Laurent E.
A2  - Owoc M.L.
A2  - Özgür Kayalica M.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 18684238 (ISSN); 978-303080846-4 (ISBN)
LA  - English
J2  - IFIP Advances in Information and Communication Technology
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 6; Correspondence Address: A. Wong; AGW Legal & Advisory, Sydney, Australia; email: anthonywong@agwconsult.com; Conference name: 8th IFIP WG 12.6 International Workshop on Artificial Intelligence for Knowledge Management, AI4KM 2021 held in conjunction with International Joint Conference on Artificial Intelligence, IJCAI 2020; Conference date: 7 January 2021 through 8 January 2021; Conference code: 262349
ER  -

TY  - JOUR
AU  - Wachter, S.
AU  - Mittelstadt, B.
AU  - Russell, C.
TI  - Why fairness cannot be automated: Bridging the gap between EU non-discrimination law and AI
PY  - 2021
T2  - Computer Law and Security Review
VL  - 41
C7  - 105567
DO  - 10.1016/j.clsr.2021.105567
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108316631&doi=10.1016%2fj.clsr.2021.105567&partnerID=40&md5=34104bb46ea042af72034b8f55518dc9
AD  - Oxford Internet Institute, University of Oxford, 1St. Giles, Oxford, OX1 3JS, United Kingdom
AD  - Harvard Law School, Harvard University, Cambridge, 02138, MA, United States
AD  - The Alan Turing Institute, British Library, 96 Euston Road, London, NW1 2DB, United Kingdom
AD  - Department of Electrical and Electronic Engineering, University of Surrey, Guildford, GU2 7HX, United Kingdom
AB  - In recent years a substantial literature has emerged concerning bias, discrimination, and fairness in artificial intelligence (AI) and machine learning. Connecting this work to existing legal non-discrimination frameworks is essential to create tools and methods that are practically useful across divergent legal regimes. While much work has been undertaken from an American legal perspective, comparatively little has mapped the effects and requirements of EU law. This Article addresses this critical gap between legal, technical, and organisational notions of algorithmic fairness. Through analysis of EU non-discrimination law and jurisprudence of the European Court of Justice (ECJ) and national courts, we identify a critical incompatibility between European notions of discrimination and existing work on algorithmic and automated fairness. A clear gap exists between statistical measures of fairness as embedded in myriad fairness toolkits and governance mechanisms and the context-sensitive, often intuitive and ambiguous discrimination metrics and evidential requirements used by the ECJ; we refer to this approach as “contextual equality.” This Article makes three contributions. First, we review the evidential requirements to bring a claim under EU non-discrimination law. Due to the disparate nature of algorithmic and human discrimination, the EU's current requirements are too contextual, reliant on intuition, and open to judicial interpretation to be automated. Many of the concepts fundamental to bringing a claim, such as the composition of the disadvantaged and advantaged group, the severity and type of harm suffered, and requirements for the relevance and admissibility of evidence, require normative or political choices to be made by the judiciary on a case-by-case basis. We show that automating fairness or non-discrimination in Europe may be impossible because the law, by design, does not provide a static or homogenous framework suited to testing for discrimination in AI systems. Second, we show how the legal protection offered by non-discrimination law is challenged when AI, not humans, discriminate. Humans discriminate due to negative attitudes (e.g. stereotypes, prejudice) and unintentional biases (e.g. organisational practices or internalised stereotypes) which can act as a signal to victims that discrimination has occurred. Equivalent signalling mechanisms and agency do not exist in algorithmic systems. Compared to traditional forms of discrimination, automated discrimination is more abstract and unintuitive, subtle, intangible, and difficult to detect. The increasing use of algorithms disrupts traditional legal remedies and procedures for detection, investigation, prevention, and correction of discrimination which have predominantly relied upon intuition. Consistent assessment procedures that define a common standard for statistical evidence to detect and assess prima facie automated discrimination are urgently needed to support judges, regulators, system controllers and developers, and claimants. Finally, we examine how existing work on fairness in machine learning lines up with procedures for assessing cases under EU non-discrimination law. A ‘gold standard’ for assessment of prima facie discrimination has been advanced by the European Court of Justice but not yet translated into standard assessment procedures for automated discrimination. We propose ‘conditional demographic disparity’ (CDD) as a standard baseline statistical measurement that aligns with the Court's ‘gold standard’. Establishing a standard set of statistical evidence for automated discrimination cases can help ensure consistent procedures for assessment, but not judicial interpretation, of cases involving AI and automated systems. Through this proposal for procedural regularity in the identification and assessment of automated discrimination, we clarify how to build considerations of fairness into automated systems as far as possible while still respecting and enabling the contextual approach to judicial interpretation practiced under EU non-discrimination law. © 2021 The Authors
KW  - Algorithm
KW  - Artificial intelligence
KW  - Bias
KW  - Demographic parity
KW  - Discrimination
KW  - European union
KW  - Fairness
KW  - Law
KW  - Machine learning
KW  - Non-discrimination
KW  - Data privacy
KW  - Laws and legislation
KW  - Machine learning
KW  - Network security
KW  - Assessment procedure
KW  - Consistent procedures
KW  - Discrimination law
KW  - European Court of Justice
KW  - Governance mechanisms
KW  - Signalling mechanisms
KW  - Statistical evidence
KW  - Statistical measures
KW  - Automation
PB  - Elsevier Ltd
SN  - 02673649 (ISSN)
LA  - English
J2  - Comput Law Secur. Rev.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 160; Correspondence Address: S. Wachter; Oxford Internet Institute, University of Oxford, Oxford, 1St. Giles, OX1 3JS, United Kingdom; email: sandra.wachter@oii.ox.ac.uk; CODEN: CLSRE
ER  -

TY  - JOUR
AU  - Whitehead, D.
AU  - Cowell, C.R.
AU  - Lavorgna, A.
AU  - Middleton, S.E.
TI  - Countering plant crime online: Cross-disciplinary collaboration in the FloraGuard study
PY  - 2021
T2  - Forensic Science International: Animals and Environments
VL  - 1
C7  - 100007
DO  - 10.1016/j.fsiae.2021.100007
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147341258&doi=10.1016%2fj.fsiae.2021.100007&partnerID=40&md5=8f707589341e4b8595ffa1a49c91f7a3
AD  - Kew Science, Royal Botanic Gardens Kew, Richmond, United Kingdom
AD  - Department of Sociology, Social Policy & Criminology, University of Southampton, United Kingdom
AD  - School of Electronics and Computer Science, University of Southampton, United Kingdom
AB  - The illegal online trade in plants has potentially devastating impacts upon species poached for sale in digital markets, yet the scale of this threat to endangered species of flora remains relatively undetermined. Effectively monitoring and analysing the online trade in plants, requires an efficient means of searching the vastness of cyberspace, and the expertise to differentiate legal from potentially illegal wildlife trade (IWT). Artificial Intelligence (AI) offers a means of improving the efficiency of both search and analysis techniques, although the complexities of wildlife trade, and the need to monitor thousands of different species, makes the automation of this technology extremely challenging. In this contribution, we review a novel socio-technical approach to addressing this problem. Combining expertise in information and communications technology, criminology, law enforcement and conservation science, this cross-disciplinary technique combines AI algorithms with human judgement and expertise, to search for and iteratively analyse potentially relevant online content. We suggest that by coupling the scalability of search algorithms with a sufficient level of human input required to evaluate wildlife trade data, the proposed methodological approach offers significant advantages over manual search techniques. We conclude by examining the high level of cross-disciplinary collaboration required to develop this technique, which may provide a useful case study for conservation practitioners and law enforcement agencies, seeking to tackle this technology-driven threat to biodiversity. © 2021 The Authors
KW  - Artificial intelligence
KW  - CITES
KW  - Cross-disciplinary
KW  - Cybercrime
KW  - Illegal wildlife trade
KW  - Natural language processing
PB  - Elsevier B.V.
SN  - 26669374 (ISSN)
LA  - English
J2  - Forensic Sci. Int.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 14; Correspondence Address: D. Whitehead; Kew Science, Royal Botanic Gardens Kew, Richmond, United Kingdom; email: d.whitehead@kew.org
ER  -

TY  - JOUR
AU  - Mazzacuva, F.
TI  - The impact of ai on corporate criminal liability: Algorithmic misconduct in the prism of derivative and holistic theories
PY  - 2021
T2  - Revue Internationale de Droit Penal
VL  - 92
IS  - 1
SP  - 143
EP  - 158
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120573455&partnerID=40&md5=2eac837061375049884e0875de500686
AD  - University of Milan-Bicocca, Department of Business and Law, Milan, Italy
AB  - While the issues related to artificial intelligence (AI) accountability are largely discussed by scholars, algorithmic corporate liability may represent a problem equally important and urgent to deal with, since the main risks come from the use of new technologies by corporations. This article precisely reviews the interplay between AI and the main systems of corporate criminal liability: the focus is on purely algorithmic corporate misconduct, rather than the cases where employees purposely, knowingly, or recklessly design AI systems to break the law. To this end, the most common regimes of corporate criminal liability will be considered: strict and vicarious liability; the principle of identification and, finally, the responsibility based on organizational fault or corporate culture. Some concluding remarks follow on the opportunity of an ad hoc regulation in order to incentivize corporations to accelerate their embrace of automation and, at the same time, to promote compliance. © 2021 Editions Eres. All rights reserved.
PB  - Maklu Publishers
SN  - 02235404 (ISSN)
LA  - English
J2  - Rev. Int. Droit Penal
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 4; Correspondence Address: F. Mazzacuva; University of Milan-Bicocca, Department of Business and Law, Milan, Italy; email: federico.mazzacuva@unimib.it
ER  -

