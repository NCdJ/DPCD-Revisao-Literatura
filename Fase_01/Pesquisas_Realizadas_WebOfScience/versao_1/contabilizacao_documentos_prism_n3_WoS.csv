"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"VRK3BU52","journalArticle","2024","Martínez, E","Re-evaluating GPT-4's bar exam performance","ARTIFICIAL INTELLIGENCE AND LAW","","0924-8463","10.1007/s10506-024-09396-9","","Perhaps the most widely touted of GPT-4's at-launch, zero-shot capabilities has been its reported 90th-percentile performance on the Uniform Bar Exam. This paper begins by investigating the methodological challenges in documenting and verifying the 90th-percentile claim, presenting four sets of findings that indicate that OpenAI's estimates of GPT-4's UBE percentile are overinflated. First, although GPT-4's UBE score nears the 90th percentile when examining approximate conversions from February administrations of the Illinois Bar Exam, these estimates are heavily skewed towards repeat test-takers who failed the July administration and score significantly lower than the general test-taking population. Second, data from a recent July administration of the same exam suggests GPT-4's overall UBE percentile was below the 69th percentile, and similar to \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\sim$$\end{document} 48th percentile on essays. Third, examining official NCBE data and using several conservative statistical assumptions, GPT-4's performance against first-time test takers is estimated to be similar to \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\sim$$\end{document} 62nd percentile, including similar to \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\sim$$\end{document} 42nd percentile on essays. Fourth, when examining only those who passed the exam (i.e. licensed or license-pending attorneys), GPT-4's performance is estimated to drop to similar to \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\sim$$\end{document} 48th percentile overall, and similar to \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\sim$$\end{document} 15th percentile on essays. In addition to investigating the validity of the percentile claim, the paper also investigates the validity of GPT-4's reported scaled UBE score of 298. The paper successfully replicates the MBE score, but highlights several methodological issues in the grading of the MPT + MEE components of the exam, which call into question the validity of the reported essay score. Finally, the paper investigates the effect of different hyperparameter combinations on GPT-4's MBE performance, finding no significant effect of adjusting temperature settings, and a significant effect of few-shot chain-of-thought prompting over basic zero-shot prompting. Taken together, these findings carry timely insights for the desirability and feasibility of outsourcing legally relevant tasks to AI models, as well as for the importance for AI developers to implement rigorous and transparent capabilities evaluations to help secure safe and trustworthy AI.","2024-03-30","2024-10-27 16:07:35","2024-10-27 16:30:49","","","","","","","","","","","","","","","English","","","","WOS:001194581100001","","","","","","","Artificial intelligence; Artificial intelligence and law; LAW; Law and technology; Legal analytics; Legal NLP; Legal profession; Machine learning; Natural language processing; NLP","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZZJC3EME","journalArticle","2024","Egger, C; Caselli, T; Tziafas, G; Phalle, ED; Vries, WD","Extracting and classifying exceptional COVID-19 measures from multilingual legal texts: The merits and limitations of automated approaches","REGULATION & GOVERNANCE","","1748-5983","10.1111/rego.12557","","This paper contributes to ongoing scholarly debates on the merits and limitations of computational legal text analysis by reflecting on the results of a research project documenting exceptional COVID-19 management measures in Europe. The variety of exceptional measures adopted in countries characterized by different legal systems and natural languages, as well as the rapid evolution of such measures, pose considerable challenges to manual textual analysis methods traditionally used in the social sciences. To address these challenges, we develop a supervised classifier to support the manual coding of exceptional policies by a multinational team of human coders. After presenting the results of various natural language processing (NLP) experiments, we show that human-in-the-loop approaches to computational text analysis outperform unsupervised approaches in accurately extracting policy events from legal texts. We draw lessons from our experience to ensure the successful integration of NLP methods into social science research agendas.","2024-07","2024-10-27 16:12:58","2024-10-27 16:30:29","","704-723","","3","18","","","","","","","","","","English","","","","WOS:001079523000001","","","","","","","computational text analysis; COVID-19; crisis governance; EMERGENCY; law-as-data; natural language processing; SCIENCE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HUM5JFDV","conferencePaper","2021","Razeira, RM; Rodello, IA","A LSTM Recurrent Neural Network Implementation for Classifying Entities on Brazilian Legal Documents","Universidade de Sao Paulo","0302-9743","","10.1007/978-3-030-86960-1_48","","Although the use of Natural Language Processing and Named Entity Recognition methods to deal with classification problems in the most diverse areas is something well-established, applications in Law offer challenges due to the specific terminology, broader vocabulary and the presence of more complex semantic and syntactic structures compared to spoken Portuguese. In this short paper, we present a Recurrent Neural Network implementation using LSTM to classify entities such as class, subject, value, individuals, among others items, in lawsuits. The initial dataset focused on a sample of 100 thousand lawsuits of Sao Paulo state court, in Brazil. The proposed method achieved an accuracy and F1-score of approximately 90% in the tested data. Such preliminary results indicate that it is possible to create a model capable of generalizing such classifications on a large scale even regarding the specifics of Brazilian legal texts terminology.","2021","2024-10-27 16:12:58","2024-10-27 16:12:58","","648-656","","","12950","","","","","","","","","","English","","","","WOS:000722379800048","","","","","","","Natural Language Processing; Legal documents; Named entity recognition","","Gervasi, O; Murgante, B; Misra, S; Garau, C; Blecic, I; Taniar, D; Apduhan, BO; Rocha, AMAC; Tarantino, E; Torre, CM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","COMPUTATIONAL SCIENCE AND ITS APPLICATIONS, ICCSA 2021, PT II","","","","","","","","","","","","","","",""
"UMHSRT3B","conferencePaper","2022","Núñez-Robinson, D; Talavera-Montalto, J; Ugarte, W","A Comparative Analysis on the Summarization of Legal Texts Using Transformer Models","Universidad Peruana de Ciencias Aplicadas (UPC)","1865-0929","","10.1007/978-3-031-20319-0_28","","Transformer models have evolved natural language processing tasks in machine learning and set a new standard for the state of the art. Thanks to the self-attention component, these models have achieved significant improvements in text generation tasks (such as extractive and abstractive text summarization). However, research works involving text summarization and the legal domain are still in their infancy, and as such, benchmarks and a comparative analysis of these state of the art models is important for the future of text summarization of this highly specialized task. In order to contribute to these research works, the researchers propose a comparative analysis of different, fine-tuned Transformer models and datasets in order to provide a better understanding of the task at hand and the challenges ahead. The results show that Transformer models have improved upon the text summarization task, however, consistent and generalized learning is a challenge that still exists when training the models with large text dimensions. Finally, after analyzing the correlation between objective results and human opinion, the team concludes that the Recall-Oriented Understudy for Gisting Evaluation (ROUGE) [13] metrics used in the current state of the art are limited and do not reflect the precise quality of a generated summary.","2022","2024-10-27 16:12:58","2024-10-27 16:12:58","","372-386","","","1675","","","","","","","","","","English","","","","WOS:000921196400028","","","","","","","Natural language processing; Deep learning; Transformers; Abstractive text summarization; Benchmark","","Guarda, T; Portela, F; Augusto, MF","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","ADVANCED RESEARCH IN TECHNOLOGIES, INFORMATION, INNOVATION AND SUSTAINABILITY, ARTIIS 2022, PT I","","","","","","","","","","","","","","",""
"937LKRL6","journalArticle","2024","Tóth, E; Gal, Z","Optimizing Text Clustering Efficiency through Flexible Latent Dirichlet Allocation Method: Exploring the Impact of Data Features and Threshold Modification","INFOCOMMUNICATIONS JOURNAL","","2061-2079","10.36244/ICJ.2024.5.7","","A parallel corpus comprising Croatian EU legisla tive documents Automatically translated into English spans 28 years and is enriched with metadata, including creation year and hierarchical classifier tags denoting descriptors, document types, and fields. However, nearly two-thirds of the approxi- mately 1.5 thousand tests lack complete metadata, necessitating labor intensive manual efforts that pose challenges for human administration. This incompleteness issue can be observed in the case of official legal sites functioning as regular service provi- sioning databases. In response, this paper introduces an artifi cial cognitive and multilabel classification approach to expedite the tagging process with only a fraction of the manual effort. Leveraging the Latent Dirichlet Allocation (LDA) algorithm. our method assigns field values or tags to incompletely labeled documents. We Esplement a Flexible LDA variant, inco & gcy;& rcy;& ocy;- rating the influence of topics close to the most probable topic, regulated by a relative probability threshold (RPT). We evalu- ate the LDA prediction's de a's dependen & scy;& iecy; & ocy;n document prefiltering and RPT values. Furthermore, we investigate the dependence of quantitative linguistic properties on the type and speciality of pre-processing tasks. Our algorithm, built on error-correcting optimizing codes, successfully predicts a mixture of topic prob- abilities for these legal texts. This prediction is achieved. by cal- by cal culating the Hanming distance of binary feature vectors created using the legal fields of the EUROVOC multilingual thesaurus.","2024","2024-10-27 16:12:58","2024-10-27 16:12:58","","58-66","","","","","","","","","","","","","English","","","","WOS:001318875600008","","","","","","","Natural Language Processing; Artificial Intelligence; Latent Dirichlet Allocation; Legal text clustering; Multilabel classification; Quantitative linguistics; Supervised learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TP89XXWD","journalArticle","2022","Vu, ST; Nguyen, ML; Satoh, K","Abstract meaning representation for legal documents: an empirical research on a human-annotated dataset","ARTIFICIAL INTELLIGENCE AND LAW","","0924-8463","10.1007/s10506-021-09292-6","","Natural language processing techniques contribute more and more in analyzing legal documents recently, which supports the implementation of laws and rules using computers. Previous approaches in representing a legal sentence often based on logical patterns that illustrate the relations between concepts in the sentence, often consist of multiple words. Those representations cause the lack of semantic information at the word level. In our work, we aim to tackle such shortcomings by representing legal texts in the form of abstract meaning representation (AMR), a graph-based semantic representation that gains lots of polarity in NLP community recently. We present our study in AMR Parsing (producing AMR from natural language) and AMR-to-text Generation (producing natural language from AMR) specifically for legal domain. We also introduce JCivilCode, a human-annotated legal AMR dataset which was created and verified by a group of linguistic and legal experts. We conduct an empirical evaluation of various approaches in parsing and generating AMR on our own dataset and show the current challenges. Based on our observation, we propose our domain adaptation method applying in the training phase and decoding phase of a neural AMR-to-text generation model. Our method improves the quality of text generated from AMR graph compared to the baseline model. (This work is extended from our two previous papers: ""An Empirical Evaluation of AMR Parsing for Legal Documents"", published in the Twelfth International Workshop on Juris-informatics (JURISIN) 2018; and ""Legal Text Generation from Abstract Meaning Representation"", published in the 32nd International Conference on Legal Knowledge and Information Systems (JURIX) 2019.).","2022-06","2024-10-27 16:12:58","2024-10-27 16:12:58","","221-243","","2","30","","","","","","","","","","English","","","","WOS:000671705100001","","","","","","","Abstract meaning representation; Deep neural network; Legal document; TRANSLATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RZ7Z6FCX","journalArticle","2024","Gaubiene, N","Can Artificial Intelligence Engage in the Practice of Law as the Art of Good and Justice?","FILOSOFIJA-SOCIOLOGIJA","","0235-7186","10.6001/fil-soc.2024.35.2","","This article explores whether artificial intelligence (AI) can engage in the practice of law as an art of good and justice. It examines the historical and philosophical foundations of law as the art of promoting societal harmony and resolving moral dilemmas. The research employs critical and philosophical analysis methods integrating insights from legal scholars, ethicists, technologists, and policymakers. The study identifies AI's potential to streamline legal processes, enhance access to justice, and reduce bias in decision -making. However, it also highlights ethical challenges such as transparency, accountability, and the impact on the legal workforce. The article emphasises the importance of striking a balance between technological innovation and human values, advocating for proactive regulation and interdisciplinary cooperation to ensure the ethical development and implementation of AI in law. The results of the study highlight the transformative potential of AI in revolutionising legal practice, emphasising its capacity to streamline processes, improve access to justice, and mitigate bias. However, ethical considerations such as transparency, accountability, and the preservation of human judgment are crucial to ensuring that AI integration in law upholds funda","2024","2024-10-27 16:13:10","2024-10-27 16:13:10","","54-63","","2","35","","","","","","","","","","English","","","","WOS:001278522600001","","","","","","","artificial intelligence; ethics; good and justice; law as an art; pursuit of justice","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NW6CGKGZ","journalArticle","2018","Simshaw, D","Ethical Issues in Robo-Lawyering: The Need for Guidance on Developing and Using Artificial Intelligence in the Practice of Law","HASTINGS LAW JOURNAL","","0017-8322","","","As in many other industries, artificial intelligence (""AI"") is poised to drastically transform the legal services landscape. ""Bots,"" automated expert systems, and predictive analytics are already changing the way consumers seek, and lawyers provide, legal services. Among other impacts, AI has the potential to increase access to justice in the self-help, individual, and corporate law firm markets by lowering costs and expanding services to untapped markets. A prominent question in early literature on AI in law is whether these services constitute the unauthorized practice of law. Threshold questions of whether and by whom such services should be regulated are important, but will likely not be answered (or even answerable) until AI's impact on the profession is more cognizable. In the meantime, there is currently no comprehensive guidance for attorneys on how AI should be developed, adopted, and used in ways that conform to a lawyer's ethical obligations. Without such guidance, law firms and third-party services risk designing and adopting AI-driven tools that fail to provide effective client-centered services, inhibit wide-spread access to justice, and undermine lawyers' ethical obligations to current and former clients, including the obligations to practice competently, maintain confidentiality, effectively supervise third parties, communicate with clients, and exercise independent judgment and render candid advice. This Article initiates this critical dialogue by exploring the types of AI being implemented in the profession, and identifying characteristics of these emerging services that will present ethical tensions and challenges. It rigorously examines existing guidance from the ABA and state bar authorities concerning new technology in practice, and identifies areas where this guidance is not sufficient to confront the unique ethical issues presented by AI. This article does not attempt to provide detailed or prescriptive guidance on these issues, but rather identifies the imminent challenges not currently being addressed in the literature on AI and legal ethics, or by bar authorities. The concluding recommendations will set the stage for and inform future scholarship and discussions concerning legal ethics, access to justice, and unauthorized practice of law in the age of AI.","2018-12","2024-10-27 16:13:10","2024-10-27 16:13:10","","173-212","","1","70","","","","","","","","","","English","","","","WOS:000455216800004","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"77U3HFIE","conferencePaper","2022","Henderson, P; Chugg, B; Anderson, B; Ho, DE; ACM","Beyond Ads: Sequential Decision-Making Algorithms in Law and Public Policy","Stanford University","978-1-4503-9234-1","","10.1145/3511265.3550439","","We explore the promises and challenges of employing sequential decision-making algorithms - such as bandits, reinforcement learning, and active learning - in law and public policy. While such algorithms have well-characterized performance in the private sector (e.g., online advertising), the tendency to naively apply algorithms motivated by one domain, often online advertisements, can be called the ""advertisement fallacy."" Our main thesis is that law and public policy pose distinct methodological challenges that the machine learning community has not yet addressed. Machine learning will need to address these methodological problems to move ""beyond ads."" Public law, for instance, can pose multiple objectives, necessitate batched and delayed feedback, and require systems to learn rational, causal decision-making policies, each of which presents novel questions at the research frontier. We discuss a wide range of potential applications of sequential decision-making algorithms in regulation and governance, including public health, environmental protection, tax administration, occupational safety, and benefits adjudication. We use these examples to highlight research needed to render sequential decision making policy-compliant, adaptable, and effective in the public sector. We also note the potential risks of such deployments and describe how sequential decision systems can also facilitate the discovery of harms. We hope our work inspires more investigation of sequential decision making in law and public policy, which provide unique challenges for machine learning researchers with potential for significant social benefit.","2022","2024-10-27 16:13:26","2024-10-27 16:13:26","","87-100","","","","","","","","","","","","","English","","","","WOS:001074472400009","","","","","","","GOVERNMENT; BIAS; RISK; Active Learning; AI and Society; Bandits; Law and AI; Reinforcement Learning; Responsible AI; Sequential Decision-making","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","PROCEEDINGS OF THE 2022 SYMPOSIUM ON COMPUTER SCIENCE AND LAW, CSLAW 2022","","","","","","","","","","","","","","",""
"GQCBDM3M","journalArticle","2024","Kretschmer, M; Margoni, T; Oruç, P","Copyright Law and the Lifecycle of Machine Learning Models","IIC-INTERNATIONAL REVIEW OF INTELLECTUAL PROPERTY AND COMPETITION LAW","","0018-9855","10.1007/s40319-023-01419-3","","Machine learning, a subfield of artificial intelligence (AI), relies on large corpora of data as input for learning algorithms, resulting in trained models that can perform a variety of tasks. While data or information are not subject matter within copyright law, almost all materials used to construct corpora for machine learning are protected by copyright law: texts, images, videos, and so on. There are global policy moves to address the copyright implications of machine learning, in particular in the context of so-called ""foundation models"" that underpin generative AI. This paper takes a step back, exploring empirically three technological settings through detailed case studies. We set out the established industry methodology of a lifecycle of AI (collecting data, organising data, model training, model operation) to arrive at descriptions suitable for legal analysis. This will allow an assessment of the challenges for a harmonisation of rights, exceptions and disclosure under EU copyright law. The three case studies are:Machine learning for scientific purposes, in the context of a study of regional short-term letting markets;Natural Language Processing (NLP), in the context of large language models;Computer vision, in the context of content moderation of images.We find that the nature and quality of data corpora at the input stage is central to the lifecycle of machine learning. Because of the uncertain legal status of data collection and processing, combined with the competitive advantage gained by firms not disclosing technological advances, the inputs of the models deployed are often unknown. Moreover, the ""lawful access"" requirement of the EU exception for text and data mining may turn the exception into a decision by rightholders to allow machine learning in the context of their decision to allow access. We assess policy interventions at EU level, seeking to clarify the legal status of input data via copyright exceptions, opt-outs or the forced disclosure of copyright materials. We find that the likely result is a fully copyright-licensed environment of machine learning that may have problematic effects for the structure of industry, innovation and scientific research.","2024-01","2024-10-27 16:13:26","2024-10-27 16:30:27","","110-138","","1","55","","","","","","","","","","English","","","","WOS:001155789200001","","","","","","","Artificial intelligence; Copyright; Data mining; Digital single market; EU; TEXT; Text mining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DH2MQXRU","journalArticle","2024","Madziwa, E","Advancing honour and dignity in death for victims of armed conflicts: Exploring the challenges and opportunities of AI and machine learning in humanitarian forensic action under IHL","INTERNATIONAL REVIEW OF THE RED CROSS","","1816-3831","10.1017/S181638312400033X","","With technological developments presenting tremendous opportunities, rapid developments in data-driven artificial intelligence (AI) and machine learning (ML) have the potential to significantly transform humanitarian forensic action. Yet, their role in the forensic identification of dead bodies remains unexamined. The correct and early identification of dead bodies is not only important to afford the deceased their honour and dignity and to ensure that their families know the fate of their loved ones, but also has broader implications for human rights and international humanitarian law (IHL). This article examines the opportunities and challenges of AI and ML in advancing honour and dignity in death for armed conflict victims in humanitarian forensic action under IHL. It argues that the application of AI and ML in humanitarian forensic action has the potential to revolutionize and support forensic practitioners in the identification of human remains. This will consequently guarantee that families know the fate of their loved ones and that the deceased are afforded dignified burials according to their religious and cultural rites. The article proposes recommendations for the future use of AI and ML in humanitarian forensic action, including the adoption of a legally binding international instrument governing their use, the development of guidelines for their use, the training of forensic actors in IHL and human rights law, and the use of new technologies in humanitarian action.","2024-09-27","2024-10-27 16:13:27","2024-10-27 16:13:27","","","","","","","","","","","","","","","English","","","","WOS:001320482700001","","","","","","","LAW; machine learning; artificial intelligence; human rights; HUMAN-RIGHTS; humanitarian forensic action; WAR DEAD","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5ASHR3ER","journalArticle","2023","Blackham, A","SETTING THE FRAMEWORK FOR ACCOUNTABILITY FOR ALGORITHMIC DISCRIMINATION AT WORK","MELBOURNE UNIVERSITY LAW REVIEW","","0025-8938","","","Algorithmic discrimination represents a growing challenge for equality law. While the elimination of discrimination in employment and occupation is a fundamental obligation of International Labour Organization members, Australian equality law remains ill-adapted to respond to emerging risks. This article argues that the automated application of machine learning algorithms presents five critical challenges to equality law related to the scale of data used; their speed and scale of application; lack of transparency; growth in employer control; and the complex supply chain associated with digital technologies. Considering principles from privacy and data protection law, third -party and accessorial liability, and collective solutions, this article puts forward reforms and suggestions to better set the framework for accountability for algorithmic discrimination in the workplace.","2023","2024-10-27 16:13:27","2024-10-27 16:13:27","","63-113","","1","47","","","","","","","","","","English","","","","WOS:001111483100005","","","","","","","LAW; EQUALITY; AGE; PRIVACY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M835Y5YV","journalArticle","2023","Adams-Prassl, J; Binns, R; Kelly-Lyth, A","Directly Discriminatory Algorithms","MODERN LAW REVIEW","","0026-7961","10.1111/1468-2230.12759","","Discriminatory bias in algorithmic systems is widely documented. How should the law respond? A broad consensus suggests approaching the issue principally through the lens of indirect discrimination, focusing on algorithmic systems' impact. In this article, we set out to challenge this analysis, arguing that while indirect discrimination law has an important role to play, a narrow em on this regime in the context of machine learning algorithms is both normatively undesirable and legally flawed. We illustrate how certain forms of algorithmic bias in frequently deployed algorithms might constitute direct discrimination, and explore the ramifications-both in practical terms, and the broader challenges automated decision-making systems pose to the conceptual apparatus of anti-discrimination law.","2023-01","2024-10-27 16:13:27","2024-10-27 16:13:27","","144-175","","1","86","","","","","","","","","","English","","","","WOS:000834063200001","","","","","","","FAIRNESS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4JWXK9Y9","journalArticle","2024","Walker-Munro, B","Can Autonomous Weapon Systems be Seized? Interactions with the Law of Prize and War Booty","JOURNAL OF CONFLICT & SECURITY LAW","","1467-7954","10.1093/jcsl/krad016","","The military has often been used as a proving ground for advances in technology. With the advent of machine learning, algorithms and artificial intelligence, there has been a slew of scholarship around the legal and ethical challenges of applying those technologies to the military. Nowhere has the debate been fiercer than in examining whether international law is resilient enough to impose individual and State responsibility for the misuse of these autonomous weapon systems (AWSs). However, by introducing increasing levels of electronic and digital components into weapon systems, States are also introducing opportunities for adversaries to hack, suborn or take over AWSs in a manner unthinkable compared to conventional weaponry. Yet, no academic discussion has considered how the law of prize and war booty might apply to AWSs that are captured in such a way. This article seeks to address this gap.","2024-04-27","2024-10-27 16:13:27","2024-10-27 16:13:27","","143-163","","1","29","","","","","","","","","","English","","","","WOS:001137078400001","","","","","","","CAPTURE; COURTS; KILL; POWER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E8WA542H","conferencePaper","2022","Rudzite, L; Kelli, A; UNIV LATVIA PRESS","THE INTERACTION BETWEEN ALGORITHMIC TRANSPARENCY AND LEGALITY: PERSONAL DATA PROTECTION AND PATENT LAW PERSPECTIVES","University of Tartu","978-9934-18-825-1","","10.22364/iscflul.8.2.27","","Artificial Intelligence and its sub-field Machine Learning in the European Union has been directed as one of the political priorities towards the augmentation of human prosperity. However, due to its characteristics, for instance, the ""black-box"" problem, AI may pose challenges within the existing legal framework. The article focuses on analysing the legality of algorithmic transparency in two fields in the EU-data protection (obligation to provide information to the data subject) and under the criteria of ""sufficient disclosure"" of the patent legal framework - to improve legal clarity concerning the issue.","2022","2024-10-27 16:13:27","2024-10-27 16:13:27","","400-408","","","","","","","","","","","","","English","","","","WOS:001070845700027","","","","","","","artificial intelligence; patent; transparency; data protection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","NEW LEGAL REALITY: CHALLENGES AND PERSPECTIVES. II","","","","","","","","","","","","","","",""
"N65HZHBK","conferencePaper","2022","Kesari, A; ACM","The Privacy-Fairness-Accuracy Frontier: A Computational Law & Economics Toolkit for Making Algorithmic Tradeoffs","New York University","978-1-4503-9234-1","","10.1145/3511265.3550437","","Both law and computer science are concerned with developing frameworks for protecting privacy and ensuring fairness. Both fields often consider these two values separately and develop legal doctrines and machine learning metrics in isolation from one another. Yet, privacy and fairness values can conflict, especially when considered alongside the accuracy of an algorithm. The computer science literature often treats this problem as an ""impossibility theorem"" - we can have privacy or fairness but not both. Legal doctrine is similarly constrained by a focus on the inputs to a decision - did the decisionmaker intend to use information about protected attributes. Despite these challenges, there is a way forward. The law has integrated economic frameworks to consider tradeoffs in other domains, and a similar approach can clarify policymakers' thinking around balancing accuracy, privacy, and fairnesss. This piece illustrates this idea by using a law & economics lens to formalize the notion of a Privacy-Fairness-Accuracy frontier, and demonstrating this framework on a consumer lending dataset. An open-source Python software library and GUI will be made available.","2022","2024-10-27 16:13:27","2024-10-27 16:13:27","","77-85","","","","","","","","","","","","","English","","","","WOS:001074472400008","","","","","","","privacy; consumer protection; fairness","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","PROCEEDINGS OF THE 2022 SYMPOSIUM ON COMPUTER SCIENCE AND LAW, CSLAW 2022","","","","","","","","","","","","","","",""
"PEDX3VIC","journalArticle","2024","López, JBG","Goals, Effects and Challenges of the Financial Transaction Tax : A Comparative Law Study in France, Italy and Spain","REVIEW OF EUROPEAN AND COMPARATIVE LAW","","2545-384X","10.31743/recl.17435","","The Preamble of the Spanish Financial Transactions Tax Law establishes that ""[t]he shaping of the tax follows the line taken by our neighbouring countries, including France and Italy, thus contributing to greater coordination of these taxes across Europe."" In this sense, the Spanish tax shows important similarities with those established in France and Italy in relation to the levy on the acquisition of certain shares and securities representing the capital of a company for consideration. Nevertheless, both the French and the Italian taxes apply to other types of transactions, not covered by the Spanish Law, which is why it is necessary to carry out the corresponding comparative study. Furthermore, the effects that have arisen from the application of this kind of taxes to financial transactions merited a proper analysis in order to determine if the main goals pursued by these taxes have been achieved in an efficient way. In any case, there are emerging tax challenges in financial markets connected, on the one hand, to the use of crypto-assets and distributed ledger technology, and, on the other hand, to the implementation of artificial intelligence and machine learning and the fair taxation of these operations.","2024-09-30","2024-10-27 16:13:27","2024-10-27 16:13:27","","","","","","","","","","","","","","","English","","","","WOS:001328348000001","","","","","","","artificial intelligence; distributed ledger technology; financial transaction tax; HFT; shares","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EPHS5YVR","journalArticle","2023","Lettieri, N; Guarino, A; Malandrino, D; Zaccagnino, R","Knowledge mining and social dangerousness assessment in criminal justice: metaheuristic integration of machine learning and graph-based inference","ARTIFICIAL INTELLIGENCE AND LAW","","0924-8463","10.1007/s10506-022-09334-7","","One of the main challenges for computational legal research is drawing up innovative heuristics to derive actionable knowledge from legal documents. While a large part of the research has been so far devoted to the extraction of purely legal information, less attention has been paid to seeking out in the texts the clues of more complex entities: legally relevant facts whose detection requires to link and interpret, as a unified whole, legal information and results of empirical analyses. This paper presents an ongoing research that points in this direction, trying to devise new ways to support public prosecutors in assessing the dangerousness of individuals and groups under investigation, an activity that precisely relies on the cross-sectional evaluation of legal and empirical data. A knowledge mining strategy will be outlined that lines up, into a single metaheuristic model, information extraction, network-based inference, machine learning and visual analytics. We will focus, in particular, on the integration of graph-based inference and machine learning methods used both to support classification tasks and to explore new forms of man-machine cooperation. Experiments made involving public prosecutors from the Italian Anti-Mafia Investigation Directorate and using data from real investigations have not only shown the potentialities of our approach but also offered an opportunity to reflect on the role we could assign to AI when thinking about the future of legal science and practice.","2023-12","2024-10-27 16:13:27","2024-10-27 16:13:27","","653-702","","4","31","","","","","","","","","","English","","","","WOS:000870659500001","","","","","","","NETWORK ANALYSIS; LAW; CLASSIFICATION; ARGUMENTATION; CRIME; EXTRACTION; AUGMENTED INTELLIGENCE COLLABORATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"48B3K8CI","journalArticle","2023","Nolan, P; Matulionyte, R","Artificial Intelligence in Medicine: Issues When Determining Negligence","JOURNAL OF LAW AND MEDICINE","","1320-159X","","","The introduction of novel medical technology, such as artificial intelligence (AI), into traditional clinical practice presents legal liability challenges that need to be squarely addressed by litigants and courts when something goes wrong. Some of the most promising applications for the use of AI in medicine will lead to vexed liability questions. As AI in health care is in its relative infancy, there is a paucity of case law globally upon which to draw. This article analyses medical malpractice where AI is involved, what problems arise when applying the tort of negligence - such as establishing the essential elements of breach of duty of care and causation - and how can these can be addressed. Product liability under Australian Consumer Law is beyond the scope of this article. In order to address this question, the article: (1) identifies the general problems that black box AI causes in the health care sector; (2) identifies the problems that will arise in establishing breach and causation due to the ""black box"" nature of AI, with reference to the Civil Liability Act 2002 (NSW) and common law through two hypothetical examples; and (3) considers selected legal solutions to the problems caused by ""black box"" AI.","2023","2024-10-27 16:13:27","2024-10-27 16:13:27","","","","3","30","","","","","","","","","","English","","","","WOS:001162587800004","","","","","","","machine learning; AI; artificial intelligence; RISK; black box effect; CANCER; INFORMED-CONSENT; legal liability; medical care; negligence; PERFORMANCE; reasonable foreseeability; res ipsa loquitur","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZCK8UFFU","journalArticle","2022","Jones, CC","SYSTEMATIZING DISCRIMINATION: AI VENDORS & TITLE VII ENFORCEMENT","UNIVERSITY OF PENNSYLVANIA LAW REVIEW","","0041-9907","","","For much of the last decade, scholars have highlighted both the role of AI and machine learning in reproducing inequality and the practical litigation di ffi culties such technologies create for proving intent. What the scholarship largely overlooks is the role of a handful of vendors who convert idiosyncratic biases into systematic, industry-wide barriers to employment opportunity. This capacity to scale discrimination in a way that may exclude certain groups from large segments of the labor market is a unique danger of AI vendors that warrants special scrutiny from Congress and regulators. Although underestimating the potential for harm, many scholars have also underestimated the e ff ectiveness of current law in addressing these problems. Thus, the EEOC and Congress should focus enforcement energy on AI vendors-through commissioner charges in the short term and through new legislation and regulation designed to meet the evolving challenges of AI hiring tools in the long term.","2022-12","2024-10-27 16:13:27","2024-10-27 16:13:27","","235-266","","1","171","","","","","","","","","","English","","","","WOS:001219086500005","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7Q7HZ49Q","journalArticle","2023","Greif, E; Grosz, T","To see, or not to see: Online job advertisement and EU non-discrimination law","EUROPEAN LABOUR LAW JOURNAL","","2031-9525","10.1177/20319525231172089","","The recruitment process has largely moved online. Job advertisements which used to be bound to newspapers and other print media have become an online service as part of a growing trend towards a more digitalised hiring process. Alongside increased flexibility and cost-cutting, this trend brings so previously unseen challenges. The technology behind online job portals and social media allows job ads to be shown to targeted groups of people using machine learning techniques to filter through the available data and search for the most suitable audience. The correlations that are inferred by algorithms between content and audience, however, can lead to biased outcomes. This is a serious problem since the specific risk with online job ads is that jobseekers who are considered less suitable by the algorithm will not see the ad at all. Such a result effectively hinders access to the labour market and poses the risk of perpetuating existing biases and discrimination. Those discrimination risks raise questions about the legal framework of online job advertisements. This article examines the requirements of the new EU initiatives to regulate artificial intelligence and the digital market and EU non-discrimination law regarding online job advertisements. It also proposes a low-tech solution to the high-tech problems associated with online job advertisements by introducing a legal requirement to publicly tender job ads on an online noticeboard, thus ensuring transparency and effective access to employment.","2023-09","2024-10-27 16:13:27","2024-10-27 16:13:27","","376-390","","3","14","","","","","","","","","","English","","","","WOS:001046536000003","","","","","","","AI Act; EU labour law; non-discrimination; Digital Markets Act; Digital Services Act; online job advertisements","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SQLLX5BB","journalArticle","2023","Farmaki, D","The player, the programmer and the AI: a copyright odyssey in gaming","JOURNAL OF INTELLECTUAL PROPERTY LAW & PRACTICE","","1747-1532","10.1093/jiplp/jpad095","","The advancement of machine learning and artificial intelligence (AI) technology has fundamentally altered the production and ownership of works, including video games. That is because, with the development of AI systems, machines are now capable of not only producing works that are similar to existing ones but also creating works that are truly original and creative.The question of how such works should be protected under copyright law is a complex and evolving one. It is crucial to take into account the numerous approaches that have been proposed in this regard for the copyright protection of AI-generated works alongside related criticisms. Regardless of the approach employed, the issue of copyright protection for AI-generated works becomes more complicated if one considers the exclusive rights copyright holders enjoy, such as the communication to the public right via video game streaming.It will be feasible to create a framework for the protection of AI-generated works that is fair, effective and responsive to the requirements of both creators and users by carefully examining the legal and practical challenges involved.","2023-12-23","2024-10-27 16:13:27","2024-10-27 16:13:27","","920-928","","12","18","","","","","","","","","","English","","","","WOS:001107620900001","","","","","","","ARTIFICIAL-INTELLIGENCE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KJF2A9DT","journalArticle","2023","Juliussen, BA; Rui, JP; Johansen, D","Algorithms that forget: Machine unlearning and the right to erasure","COMPUTER LAW & SECURITY REVIEW","","0267-3649","10.1016/j.clsr.2023.105885","","Article 17 of the General Data Protection Regulation (GDPR) contains a right for the data subject to obtain the erasure of personal data. The right to erasure in the GDPR gives, however, little clear guidance on how controllers processing personal data should erase the personal data to meet the requirements set out in Article 17. Machine Learning (ML) models that have been trained on personal data are downstream derivatives of the personal data used in the training data set of the ML process. A characteristic of ML is the non-deterministic nature of the learning process. The non-deterministic nature of ML poses significant difficulties in determining whether the personal data in the training data set affects the internal weights and adjusted parameters of the ML model. As a result, invoking the right to erasure in ML and to erase personal data from a ML model is a challenging task.This paper explores the complexities of enforcing and complying with the right to erasure in a ML context. It examines how novel developments in machine unlearning methods relate to Article 17 of the GDPR. Specifically, the paper delves into the intricacies of how personal data is processed in ML models and how the right to erasure could be implemented in such models. The paper also provides insights into how newly developed machine unlearning techniques could be applied to make ML models more GDPR compliant. The research aims to provide a functional understanding and contribute to a better comprehension of the applied challenges associated with the right to erasure in ML.(c) 2023 Bjorn Aslak Juliussen, Jon Petter Rui, Dag Johansen. Published by Elsevier Ltd. ( http://creativecommons.org/licenses/by/4.0/ )","2023-11","2024-10-27 16:13:27","2024-10-27 16:13:27","","","","","51","","","","","","","","","","English","","","","WOS:001081259400001","","","","","","","Machine learning; Data protection law; General data protection regulation; Machine unlearning; Privacy; The right to be forgotten; The right to erasure","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F58H6ED4","journalArticle","2023","Pacholska, M","Military Artificial Intelligence and the Principle of Distinction: A State Responsibility Perspective","ISRAEL LAW REVIEW","","0021-2237","10.1017/S0021223722000188","","Military artificial intelligence (AI)-enabled technology might still be in the relatively fledgling stages but the debate on how to regulate its use is already in full swing. Much of the discussion revolves around autonomous weapons systems (AWS) and the 'responsibility gap' they would ostensibly produce. This contribution argues that while some military AI technologies may indeed cause a range of conceptual hurdles in the realm of individual responsibility, they do not raise any unique issues under the law of state responsibility. The following analysis considers the latter regime and maps out crucial junctions in applying it to potential violations of the cornerstone of international humanitarian law (IHL) - the principle of distinction - resulting from the use of AI-enabled military technologies. It reveals that any challenges in ascribing responsibility in cases involving AWS would not be caused by the incorporation of AI, but stem from pre-existing systemic shortcomings of IHL and the unclear reverberations of mistakes thereunder. The article reiterates that state responsibility for the effects of AWS deployment is always retained through the commander's ultimate responsibility to authorise weapon deployment in accordance with IHL. It is proposed, however, that should the so-called fully autonomous weapon systems - that is, machine learning-based lethal systems that are capable of changing their own rules of operation beyond a predetermined framework - ever be fielded, it might be fairer to attribute their conduct to the fielding state, by conceptualising them as state agents, and treat them akin to state organs.","2023-03","2024-10-27 16:13:27","2024-10-27 16:13:27","","3-23","","1","56","","","","","","","","","","English","","","","WOS:001140502300001","","","","","","","artificial intelligence; autonomous weapons systems; mistake of fact; principle of distinction; state responsibility; WAR; WEAPONS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MQFGM7W2","journalArticle","2022","Van den Meerssche, D","Virtual Borders: International Law and the Elusive Inequalities of Algorithmic Association","EUROPEAN JOURNAL OF INTERNATIONAL LAW","","0938-5428","10.1093/ejil/chac007","","The use of algorithmic tools by international public authorities is changing how norms are made and enacted. This seismic shift in global governance has important distributive consequences: the digital turn not only empowers specific corporate actors and forms of expertise but also entails new modes of social sorting based on the placement of people in patterns of data. This article focuses on the emergent inequalities that machine learning and data analytics thereby import in the domain of global governance. In line with the symposium's theme, I thereby frame the importance of computational decision-making processes from a distributional, and not a procedural, perspective - from a perspective of inequality and not privacy, data protection or transparency. The empirical site for the assessment of these emergent inequalities is the 'virtual border'. By focusing on the technological tools of data extraction and algorithmic risk assessment that are reshaping practices of border control, the article makes a dual contribution: it reveals the social hierarchies engendered by these data-driven forms of grouping and grading - captured in the novel concept of 'associative inequality' - and highlights the difficulty of registering or counteracting this mode of subject-making in existing legal terms. This intervention both traces the particular distributive effects of data-driven governance and signals the challenges it poses to the prospects and emancipatory promises of collectivity, solidarity and equality entertained in modernist ideals of international law. In resisting the logic of algorithmic governance, I suggest, we should strive not for transparency but for opacity, not inclusion but incomparability, not privacy but open-ended and defiant commonality.","2022-07-30","2024-10-27 16:13:27","2024-10-27 16:13:27","","171-204","","1","33","","","","","","","","","","English","","","","WOS:000793046800001","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BBC27NHE","journalArticle","2023","Fenwick, M; Jurcys, P","Originality and the future of copyright in an age of generative AI","COMPUTER LAW & SECURITY REVIEW","","0267-3649","10.1016/j.clsr.2023.105892","","This paper takes the occasion of French DJ David Guetta's use of generative AI tools to create lyrics and a voice in the style of Eminem, which he then used in one of his concerts, as the basis for an exploration of the shifting meaning of creativity and originality in the age of generative AI. Our main contention is that the Guetta form of creativity with generative AI tools differs in certain important respects from what has come before.The paper describes an iterative, dynamic process of conception, prompting, generation, refining, and deployment to characterise creativity in this context. Nevertheless, we contend that copyright - specifically the concept of originality as articulated in US federal law - is a sufficiently durable legal mechanism that can manage these new cultural forms, and that the two basic requirements of modern copyright law (a tangible medium of expression and a modest degree of creativity) remain relevant in identifying the scope of legal protection. The paper argues that the David Guetta story reveals something more general about creativity in a digital age, namely that while hybrid-networked (i.e., human - corporate - machine) creators have always created hybridnetworked cultural forms (i.e., creations that blend human and technology-constituted elements), such hybridity becomes increasingly visible and complex in the context of a new world of generative AI. At the very least, earlier - and influential - models of creativity as human-driven involving creation ex nihilo become harder to sustain in a new age of generative AI. But this does not mean copyright or notions of originality are redundant or that copyright law cannot accommodate Guetta and other cases. Such an account seems important as it challenges the hegemonic and reductive view that AI ""generates"" artistic works autonomously and avoids reducing the copyright issues raised by such creative works to the related but distinct question of whether learning models rely on copyrighted data. As such, copyright law should remain an important mechanism to facilitate genuine creators who are using AI systems in innovative and unique ways to push the boundaries of their creativity.","2023-11","2024-10-27 16:13:27","2024-10-27 16:13:27","","","","","51","","","","","","","","","","English","","","","WOS:001111839200001","","","","","","","LAW; AI; Artificial intelligence; Copyright; Generative AI; Data; Machine Learning; Intellectual Property; ChatGPT; Authorship; Creativity; David Guetta; Feist; Input; Originality; Output","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6RALL625","journalArticle","2022","Hoffmann, H; Vogt, V; Hauer, MP; Zweig, K","Fairness by awareness? On the inclusion of protected features in algorithmic decisions","COMPUTER LAW & SECURITY REVIEW","","0267-3649","10.1016/j.clsr.2022.105658","","AI decisions are increasingly determining our everyday lives. At present, European antidiscrimination law is process-oriented; it prohibits the inclusion of sensitive data that is particularly protected. However, especially in the context of AI decisions, constellations can be identified in which the inclusion of sensitive characteristics will lead to better and sometimes even less discriminatory result. A result-oriented approach, therefore, might be a more fitting strategy for algorithmic decision making.In this paper we examine the legal framework for including sensitive features in a Support Vector Machine for a fictitious scenario and discuss the resulting challenges in practical application. It turns out that generally ignoring sensitive features - as has been the practice up to now - does not seem to be a fitting strategy for algorithmic decision making. A process-oriented procedure only supposedly comes closer to individual case justice: If one assumes that fewer errors occur when protected characteristics are included, individuals will ultimately also be assessed incorrectly less often, especially when one protected group is more prone to errors than the other. This paper aims to support the current debate about legal regulation of algorithmic decision making systems by discussing an often neglected perspective.(c) 2022 Hanna Hoffmann, Verena Vogt, Marc P. Hauer, Katharina Zweig. Published by Elsevier Ltd. All rights reserved.","2022-04","2024-10-27 16:13:27","2024-10-27 16:13:27","","","","","44","","","","","","","","","","English","","","","WOS:000791281300005","","","","","","","Machine learning; Fairness; Algorithmic decision making; Discrimination; Legal policy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2W7R7UUV","journalArticle","2024","Izarova, I; Uhrynovska, O; Khotynska-Nor, O; Prytyka, Y; Bedyukh, O; Alendar, Y","ADVANCING SUSTAINABLE JUSTICE THROUGH AI-BASED CASE LAW ANALYSIS: UKRAINIAN EXPERIENCE","ACCESS TO JUSTICE IN EASTERN EUROPE","","2663-0575","10.33327/AJEE-18-7.1-a000123","","Background: Ukraine has a unique Unified State Register of Court Decisions that publishes all court decisions in cases considered and resolved by courts in the public domain. There are more than one hundred million such documents in the register today. This provides unique opportunities for collecting, analysing, and summarising the empirical base of justice. This has the potential to form the basis for further transformation of the national model of justice. This study's impetus may have risen from the realisation that relying solely on human resources for such endeavours may present challenges.Methods: The study is based on the hypothesis that using hardware and software to analyse large data sets of state registers of court decisions and judicial statistics data can identify persistent patterns and causes of inefficient functioning of the judicial system.Results and Conclusions: The study led to the development of software with functionality that annotates court decision text, intended for further use in advanced Natural Language Processing algorithms. Furthermore, the study underscores the need to develop an algorithm for predicting risks and outcomes of court proceedings and a methodology for processing large amounts of data from the Unified State Register of Court Decisions. This is justified based on specific indicators of the effectiveness of dispute resolution. This article advocates for the use of machine learning algorithms as an innovative tool to generalise large data sets from court decision registers, particularly to obtain objective data on a large scale. The article also examines the prerequisites for establishing the Institute of National Judicial Practice and explores its functioning in the present stage of judicial reform.","2024-02","2024-10-27 16:13:27","2024-10-27 16:30:10","","127-148","","1","","","","","","","","","","","English","","","","WOS:001128775200001","","","","","","","analysis of large data sets; artificial intelligence; civil procedure; court decisions; e-justice; judicial reform; judicial statistics; judicial system; legal proceedings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XJPKZ47P","journalArticle","2023","Segate, RV; Daly, A","Encoding the Enforcement of Safety Standards into Smart Robots to Harness Their Computing Sophistication and Collaborative Potential: A Legal Risk Assessment for European Union Policymakers","EUROPEAN JOURNAL OF RISK REGULATION","","1867-299X","10.1017/err.2023.72","","Until robots and humans mostly worked in fast-paced and yet separate environments, occupational health and safety (OHS) rules could address workers' safety largely independently from robotic conduct. This is no longer the case: collaborative robots (cobots) working alongside humans warrant the design of policies ensuring the safety of both humans and robots at once, within shared spaces and upon delivery of cooperative workflows. Within the European Union (EU), the applicable regulatory framework stands at the intersection between international industry standards and legislation at the EU as well as Member State level. Not only do current standards and laws fail to satisfactorily attend to the physical and mental health challenges prompted by human-robot interaction (HRI), but they exhibit important gaps in relation to smart cobots (""SmaCobs"") more specifically. In fact, SmaCobs combine the black-box unforeseeability afforded by machine learning with more general HRI-associated risks, towards increasingly complex, mobile and interconnected operational interfaces and production chains. Against this backdrop, based on productivity and health motivations, we urge the encoding of the enforcement of OHS policies directly into SmaCobs. First, SmaCobs could harness the sophistication of quantum computing to adapt a tangled normative architecture in a responsive manner to the contingent needs of each situation. Second, entrusting them with OHS enforcement vis-a-vis both themselves and humans may paradoxically prove safer as well as more cost-effective than for humans to do so. This scenario raises profound legal, ethical and somewhat philosophical concerns around SmaCobs' legal personality, the apportionment of liability and algorithmic explainability. The first systematic proposal to tackle such questions is henceforth formulated. For the EU, we propose that this is achieved through a new binding OHS Regulation aimed at the SmaCobs age.","2023-11-06","2024-10-27 16:13:27","2024-10-27 16:13:27","","","","","","","","","","","","","","","English","","","","WOS:001098967400001","","","","","","","LAW; DESIGN; MANAGEMENT; BEHAVIOR; COMPLEX; Encoding of safety rules enforcement; INTELLIGENT; quantum computing; smart collaborative robots","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""