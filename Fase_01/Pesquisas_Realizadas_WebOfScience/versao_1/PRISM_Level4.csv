"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"FVAT9S26","conferencePaper","2024","Varma, S; Shivam, S; Natarajan, S; Biswas, S; Gupta, J","Taking Natural Language Generation and Information Extraction to Domain Specific Tasks","","2367-3370","","10.1007/978-3-031-47715-7_48","","A lot of domain-specific unstructured data is available at present. To make them available to common users, domain experts often have to extract the key points and convert them to layman's terms manually. For domains like legal, documents are often needed to be manually analyzed in order to check if all the critical information is present in them and to extract the important points if needed. All these manual domain-specific tasks can be automated with the help of different Natural Language Processing (NLP) and Natural Language Generation (NLG) techniques. In this paper, some of the tools in NLP and NLG that can be used to automate the above-mentioned processes for key information extraction are discussed. We also bring forth two such domain-specific use cases where we attempt to provide suggestions to the subject experts to make their tasks easier using the tools discussed.","2024","2024-11-03 18:35:26","2024-11-03 18:35:26","","713-728","","","824","","","","","","","","","","English","","","","WOS:001261693800048","","","","","","","Text summarization; Named entity recognition; Content automation; Custom rule-based parsing; Domain tasks; Information extraction; NAMED ENTITY RECOGNITION; Natural language generation; Text simplification","","Arai, K","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","INTELLIGENT SYSTEMS AND APPLICATIONS, VOL 3, INTELLISYS 2023","","","","","","","","","","","","","","",""
"KT5V8JS8","journalArticle","2024","Herbosch, M","Fraud by generative AI chatbots: On the thin line between deception and negligence","COMPUTER LAW & SECURITY REVIEW","","0267-3649","10.1016/j.clsr.2024.105941","","The use of generative AI systems is on the rise. As a result, we are increasingly often conversing with AI chatbots rather than with fellow humans. This increasing use of AI systems leads to legal challenges as well, particularly when the chatbot provides incorrect information. In this article, we study whether someone who decides to contract on the basis of incorrect information provided by a generative AI chatbot might invoke the fraud regime to annul the resulting contract in various legal systems. During this analysis, it becomes clear that some of the requirements that are currently being put forward from a public law perspective, such as in the European AI Act, may also naturally arise from existing private law figures. In the same vein, this analysis highlights the interesting intradisciplinary feedback between instruments of public law and other legal domains.","2024-04","2024-11-03 18:35:40","2024-11-03 18:35:40","","","","","52","","","","","","","","","","English","","","","WOS:001178316700001","","","","","","","Artificial intelligence; BLACK-BOX; Contract law; Fraud; Law of obligations; Vice of consent","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3ML8A5Y6","journalArticle","2024","Oh, E","Admitting AI Art as Demonstrative Evidence","CALIFORNIA LAW REVIEW","","0008-1221","","","Images and animations created through generative artificial intelligence (GAI) pose new possibilities and questions for the law of demonstrative evidence. AI art tools may allow parties to prepare pedagogical displays-including hyper-realistic virtual imagery- without retaining expensive third-party artists. But these programs raise evidentiary concerns such as reliability and undue prejudice, issues that remain largely unaddressed under the notoriously undeveloped law governing computer-made demonstratives. This Note explains both how artificial intelligence companies could institute initiatives for better quality assurance at the front end, and how courts can encourage such measures through new applications of existing evidentiary and procedural rules. The Note ultimately argues that the emerging use of GAI imagery may necessitate stricter standards in demonstrative evidence law.","2024-08","2024-11-03 18:35:40","2024-11-03 18:35:40","","1501-1533","","","112","","","","","","","","","","English","","","","WOS:001318203100006","","","","","","","COMPUTER-ART; INTELLIGENCE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WCDPQ2DI","journalArticle","2023","Chan, E; Gore, KN; Jiang, E","HARNESSING ARTIFICIAL INTELLIGENCE IN INTERNATIONAL ARBITRATION PRACTICE","CONTEMPORARY ASIA ARBITRATION JOURNAL","","1999-9747","","","Since the beginning of 2023, generative artificial intelligence (hereinafter ""Generative AI"") in the form of large language models (LLMs) like ChatGPT-4 has taken the world by storm. Legal practice is no exception. Among other stories, worldwide headlines have featured the fact that ChatGPT-4 is capable of passing the New York Bar Exam, that courts are adopting Generative AI in their decision-making, and that a New York lawyer has been sanctioned by a judge for relying upon non-existent case law precedent that he obtained from ChatGPT-4 and did not double-check. Yet, putting aside these newsworthy developments, tools powered by other forms of artificial intelligence (hereinafter ""AI"") have already been relied upon in legal practice for many years. This article introduces how AI supports successful international arbitration practice, including uses and methods that are already available and those that are anticipated to become helpful. This article also addresses the challenges and pitfalls that accompany these opportunities. Overall, this article concludes that the brave new world of AI in international arbitration is an exciting one that, through careful and thoughtful deployment of best practices, can add significant value to international arbitration teams in the decades to come.","2023","2024-11-03 18:35:40","2024-11-03 18:35:40","","263-299","","2","16","","","","","","","","","","English","","","","WOS:001111303600003","","","","","","","artificial intelligence practical applications in arbitration; artificial intelligence regulation in arbitration; artificially intelligent legal technology use cases in arbitration; future applications of artificial intelligence in arbitration practice; generative artificial intelligence in arbitration; large language models' use in arbitration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LZBXL3X7","journalArticle","2024","Head, A; Willis, S","Assessing law students in a GenAI world to create knowledgeable future lawyers","INTERNATIONAL JOURNAL OF THE LEGAL PROFESSION","","0969-5958","10.1080/09695958.2024.2379785","","Assessing law students has always been a challenging task, but the introduction of Generative Artificial Intelligence (GenAI), such as ChatGPT, compounds the problems already caused by increased student numbers, contract cheating and budget cuts in universities. As GenAI rapidly develops, legal educators must find ways to accommodate, and even incorporate, GenAI into their curricula and assessments so that law graduates can understand its capabilities and limitations within legal practice. Simultaneously, many jurisdictions, including Australia, have legislative obligations to deliver law graduates who satisfy legal knowledge-based ""eligibility"" requirements for admission into practice. This article introduces a knowledge framework for managing GenAI in legal education consisting of three pillars: Substantive Legal Knowledge, GenAI Ethics Knowledge, and GenAI System Knowledge. The authors argue this framework can assist legal educators in designing optimal assessments in an AI-disrupted world. The article employs the knowledge framework to examine the experiences and views of Australian law students' engagement with GenAI outputs in completing a compulsory legal ethics assessment in 2023. This empirical case study demonstrates that effective assessment design incorporating GenAI can enhance law student and graduate outcomes despite the ongoing challenges for legal educators and the profession associated with GenAI.","2024-07-18","2024-11-03 18:35:40","2024-11-03 18:35:40","","","","","","","","","","","","","","","English","","","","WOS:001272888800001","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IB2SCNM5","conferencePaper","2023","Nguyen, HT; Goebel, R; Toni, F; Stathis, K; Satoh, K","LawGiBa - Combining GPT, Knowledge Bases, and Logic Programming in a Legal Assistance System","Research Organization of Information & Systems (ROIS)","0922-6389","","10.3233/FAIA230991","","We present LawGiBa, a proof-of-concept demonstration system for legal assistance that combines GPT, legal knowledge bases, and Prolog's logic programming structure to provide explanations for legal queries. This novel combination effectively and feasibly addresses the hallucination issue of large language models (LLMs) in critical domains, such as law. Through this system, we demonstrate how incorporating a legal knowledge base and logical reasoning can enhance the accuracy and reliability of legal advice provided by AI models like GPT. Though our work is primarily a demonstration, it provides a framework to explore how knowledge bases and logic programming structures can be further integrated with generative AI systems, to achieve improved results across various natural languages and legal systems.","2023","2024-11-03 18:35:40","2024-11-03 18:35:40","","371-374","","","379","","","","","","","","","","English","","","","WOS:001175464100050","","","","","","","ChatGPT; interactive demonstration; knowledge base; legal advice; logic programming; Prolog","","Spanakis, J; VanDijck, G; Sileno, G","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","LEGAL KNOWLEDGE AND INFORMATION SYSTEMS","","","","","","","","","","","","","","",""
"EPBXPEPC","journalArticle","2023","Navarro-Dolmestch, R","Risks and Challenges Posed by Artificial Intelligence Generative Applications for Academic Integrity","DERECHO PUCP","","0251-3420","10.18800/derechopucp.202302.007","","From the perspective of a descriptive analysis, and as a starting point to a new research line, this paper examines the potential impact Generative Artificial Intelligence (GAI) technologies may have on academic integrity, manifested in the learning and evaluation processes of law classes at the university level. The article takes as its premise the definition of academic integrity as a set of values and argues that a series of risks arise from the GAI that threaten those values, such as excessive dependence and trust in the GAI, the unreallizability of the pedagogical project and the loss of competitiveness of educational institutions, among others. To minimize or nullify such risks, and thus prevent them from affecting academic integrity, four mitigation measures are identified to be applied in university environments.","2023-12","2024-11-03 18:35:40","2024-11-03 18:35:40","","231-270","","91","","","","","","","","","","","English","","","","WOS:001146757500011","","","","","","","artificial intelligence; ETHICS; chatbot; ChatGPT; Academic integrity; automatic text generation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7JJE3M3I","journalArticle","2024","Schweitzer, S; Conrads, M","The digital transformation of jurisprudence: an evaluation of ChatGPT-4's applicability to solve cases in business law","ARTIFICIAL INTELLIGENCE AND LAW","","0924-8463","10.1007/s10506-024-09406-w","","In the evolving landscape of legal information systems, ChatGPT-4 and other advanced conversational agents (CAs) offer the potential to disruptively transform the law industry. This study evaluates commercially available CAs within the German legal context, thereby assessing the generalizability of previous U.S.-based findings. Employing a unique corpus of 200 distinct legal tasks, ChatGPT-4 was benchmarked against Google Bard, Google Gemini, and its predecessor, ChatGPT-3.5. Human-expert and automated assessments of 4000 CA-generated responses reveal ChatGPT-4 to be the first CA to surpass the threshold of solving realistic legal tasks and passing a German business law exam. While ChatGPT-4 outperforms ChatGPT-3.5, Google Bard, and Google Gemini in both consistency and quality, the results demonstrate a considerable degree of variability, especially in complex cases with no predefined response options. Based on these findings, legal professionals should manually verify all texts produced by CAs before use. Novices must exercise caution with CA-generated legal advice, given the expertise needed for its assessment.","2024-07-01","2024-11-03 18:35:40","2024-11-03 18:35:40","","","","","","","","","","","","","","","English","","","","WOS:001259372900001","","","","","","","Large language models; Generative artificial intelligence; Chatbots; Conversational agents; Legal information systems; Performance assessment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"48MW4KN8","journalArticle","2024","Khawaldeh, AM","Generative AI Hallucinations and Legal Liability in Jordanian Civil Courts: Promoting the Responsible Use of Conversational Chat Bots","INTERNATIONAL JOURNAL FOR THE SEMIOTICS OF LAW-REVUE INTERNATIONALE DE SEMIOTIQUE JURIDIQUE","","0952-8059","10.1007/s11196-024-10199-z","","Generative Artificial Intelligence (AI) tools produce hallucinations exposing developers and users to a myriad of liabilities in courts. Given the absence of strict laws and regulations structuring how Generative AI content interact with potential allegations of defamation, libel, and slander, judges and attorneys are left with the semiotics of the fragmented articles and rules in each system attempting to settle such cases. The endless interpretations of written and non-verbal signs in the law across the world constitutes a new realm for legal semiotics in the area of Generative AI and defamation. The present analysis examines existing civil liability articles in the Jordanian code to shed light on the litigation and defenses afforded in the defamation realm with respect to Generative AI content. The key finding is that like other countries, civil codes in Jordan are outdated concerning Generative AI content opening a plethora of liability scenarios in libel or slander cases. More importantly, the exercise of semiotic interpretation generates several defenses salvaging users and developers under strict sets of conditions. In sum, new amendments and updated legislative frameworks are needed to protect the healthy development of Generative AI while preserving citizens from damaging defamation, libel, and slander.","2024-09-19","2024-11-03 18:35:41","2024-11-03 18:35:41","","","","","","","","","","","","","","","English","","","","WOS:001316759400006","","","","","","","LAW; ARTIFICIAL-INTELLIGENCE; Generative AI; AGE; ARAB; Contracts; Duty of care; Jordan; Liability","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L66FJHKP","journalArticle","2023","Chucha, SY","ARTIFICIAL INTELLIGENCE IN JUSTICE: LEGAL AND PSYCHOLOGICAL ASPECTS OF LAW ENFORCEMENT","PRAVOPRIMENENIE-LAW ENFORCEMENT REVIEW","","2542-1514","10.52468/2542-1514.2023.7(2).116-124","","The subject. Artificial intelligence is considered as an interdisciplinary legal and psychologi-cal phenomenon. The special need to strengthen the psychological component in legal re-search of artificial intelligence and its introduction into the practice of law enforcement and justice, in particular, is substantiated.The main goal of the study is to confirm or refute hypothesis that AI may be implemented in justice and to substantiate the legal limits of such implementation.The methodology. Based on the comparison of the current legislation, the practice of its application, and other empirical data, internal and external legal and psychological factors of legal regulation and the use of artificial intelligence in jurisprudence and judicial proceed-ings are identified.The main results, scope of application. The analysis of legal and doctrinal definitions of ar-tificial intelligence in jurisprudence has shown that their defining and integral part is rela-tionships that are the result of psychological practices and the subject of psychological sci-ence (internal factors). Legal studies of artificial intelligence are based on a psychological conceptual apparatus, all of them legally describe artificial intelligence, first of all, as a psy-chological phenomenon and build an analogy between the psychology of a living intelligent subject and an inanimate object, humanizing the latter. The federal legislator is also follow-ing the path of using the psychological conceptual apparatus. Such categories like human cognitive functions and intellectual activity are applied in Russian Federal Law ""On conduct-ing an experiment to establish special regulation in order to create the necessary conditions for the development and implementation of artificial intelligence technologies in the sub-ject of the Russian Federation -the federal city of Moscow and amending Articles 6 and 10 of the Federal Law ""On Personal Data"". The legal and psychological analysis of the practice of using elements of artificial intelligence in corporate governance, justice, labor relations, social insurance, electoral procedures has been subjected.The conclusion is substantiated that an indispensable condition for the introduction of arti-ficial intelligence and its elements into justice is trust on the part of the disputing parties and the court. Such trust is provided with a real possibility of verifying the actions and de-cisions made with artificial intelligence by psychologically acceptable and legally formalized methods (external factors). The use of artificial intelligence in law enforcement in general and justice in particular is possible in two directions: (1) solving problems related to the approximation of specialized artificial intelligence systems in legal proceedings to human capabilities and their integration to enhance intelligence; (2) creating artificial intelligence, which is the integration of already created elements of artificial intelligence into a single system capable of participating in justice, but does not have the properties of free will and does not acquire legal personality. Law enforcement using artificial intelligence should com-ply with the principles enshrined in the European Ethical Charter on the Use of Artificial Intelligence in Judicial Systems and their environment, the provisions of which should be implemented in domestic legislation, having previously been revised in accordance with the national legal tradition.","2023","2024-11-03 18:37:17","2024-11-03 18:37:17","","116-124","","2","7","","","","","","","","","","English","","","","WOS:001027805400012","","","","","","","Artificial intelligence (AI); concept; law enforcement; corporate governance; efficiency; justice; labor activity; legal psychology; remote work; SYSTEM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LWT752A3","journalArticle","2021","Wachter, S; Mittelstadt, B; Russell, C","Why fairness cannot be automated: Bridging the gap between EU non-discrimination law and AI","COMPUTER LAW & SECURITY REVIEW","","0267-3649","10.1016/j.clsr.2021.105567","","In recent years a substantial literature has emerged concerning bias, discrimination, and fairness in artificial intelligence (AI) and machine learning. Connecting this work to existing legal non-discrimination frameworks is essential to create tools and methods that are practically useful across divergent legal regimes. While much work has been undertaken from an American legal perspective, comparatively little has mapped the effects and requirements of EU law. This Article addresses this critical gap between legal, technical, and organisational notions of algorithmic fairness. Through analysis of EU non-discrimination law and jurisprudence of the European Court of Justice (ECJ) and national courts, we identify a critical incompatibility between European notions of discrimination and existing work on algorithmic and automated fairness. A clear gap exists between statistical measures of fairness as embedded in myriad fairness toolkits and governance mechanisms and the context-sensitive, often intuitive and ambiguous discrimination metrics and evidential requirements used by the ECJ; we refer to this approach as ""contextual equality."" This Article makes three contributions. First, we review the evidential requirements to bring a claim under EU non-discrimination law. Due to the disparate nature of algorithmic and human discrimination, the EU's current requirements are too contextual, reliant on intuition, and open to judicial interpretation to be automated. Many of the concepts fundamental to bringing a claim, such as the composition of the disadvantaged and advantaged group, the severity and type of harm suffered, and requirements for the relevance and admissibility of evidence, require normative or political choices to be made by the judiciary on a caseby-case basis. We show that automating fairness or non-discrimination in Europe may be impossible because the law, by design, does not provide a static or homogenous framework suited to testing for discrimination in AI systems. Second, we show how the legal protection offered by non-discrimination law is challenged when AI, not humans, discriminate. Humans discriminate due to negative attitudes (e.g. stereotypes, prejudice) and unintentional biases (e.g. organisational practices or internalised stereotypes) which can act as a signal to victims that discrimination has occurred. Equivalent signalling mechanisms and agency do not exist in algorithmic systems. Compared to traditional forms of discrimination, automated discrimination is more abstract and unintuitive, subtle, intangible, and difficult to detect. The increasing use of algorithms disrupts traditional legal remedies and procedures for detection, investigation, prevention, and correction of discrimination which have predominantly relied upon intuition. Consistent assessment procedures that define a common standard for statistical evidence to detect and assess prima facie automated discrimination are urgently needed to support judges, regulators, system controllers and developers, and claimants. Finally, we examine how existing work on fairness in machine learning lines up with procedures for assessing cases under EU non-discrimination law. A 'gold standard' for assessment of prima facie discrimination has been advanced by the European Court of Justice but not yet translated into standard assessment procedures for automated discrimination. We propose 'conditional demographic disparity' (CDD) as a standard baseline statistical measurement that aligns with the Court's 'gold standard'. Establishing a standard set of statistical evidence for automated discrimination cases can help ensure consistent procedures for assessment, but not judicial interpretation, of cases involving AI and automated systems. Through this proposal for procedural regularity in the identification and assessment of automated discrimination, we clarify how to build considerations of fairness into automated systems as far as possible while still respecting and enabling the contextual approach to judicial interpretation practiced under EU non-discrimination law.","2021-07","2024-11-03 18:37:17","2024-11-03 18:37:17","","","","","41","","","","","","","","","","English","","","","WOS:000685463100019","","","","","","","Machine learning; Law; BIG DATA; Artificial intelligence; ETHICS; DISCRIMINATION; BIAS; Fairness; IMPACT; Discrimination; Algorithm; Bias; Demographic; European union; Non-discrimination; parity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""