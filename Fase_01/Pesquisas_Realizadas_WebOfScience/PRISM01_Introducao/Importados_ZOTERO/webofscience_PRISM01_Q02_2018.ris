TY  - CPAPER
AU  - Verma, S
AU  - Rubin, J
A1  - IEEE
TI  - Fairness Definitions Explained
T2  - 2018 IEEE/ACM INTERNATIONAL WORKSHOP ON SOFTWARE FAIRNESS (FAIRWARE 2018)
LA  - English
CP  - IEEE/ACM International Workshop on Software Fairness (FairWare)
AB  - Algorithm fairness has started to attract the attention of researchers in AI, Software Engineering and Law communities, with more than twenty different notions of fairness proposed in the last few years. Yet, there is no clear agreement on which definition to apply in each situation. Moreover, the detailed differences between multiple definitions are difficult to grasp. To address this issue, this paper collects the most prominent definitions of fairness for the algorithmic classification problem, explains the rationale behind these definitions, and demonstrates each of them on a single unifying case-study. Our analysis intuitively explains why the same case can be considered fair according to some definitions and unfair according to others.
AD  - Indian Inst Technol Kanpur, Kanpur, Uttar Pradesh, IndiaAD  - Univ British Columbia, Vancouver, BC, CanadaC3  - Indian Institute of Technology System (IIT System)C3  - Indian Institute of Technology (IIT) - KanpurC3  - University of British ColumbiaPU  - IEEE
PI  - NEW YORK
PA  - 345 E 47TH ST, NEW YORK, NY 10017 USA
SN  - 978-1-4503-5746-3
PY  - 2018
SP  - 1
EP  - 7
DO  - 10.1145/3194770.3194776
WE  - Conference Proceedings Citation Index - Science (CPCI-S)AN  - WOS:000447014100001
N1  - Times Cited in Web of Science Core Collection:  571
Total Times Cited:  643
Cited Reference Count:  24
ER  -

TY  - JOUR
AU  - Pesapane, F
AU  - Volonté, C
AU  - Codari, M
AU  - Sardanelli, F
TI  - Artificial intelligence as a medical device in radiology: ethical and regulatory issues in Europe and the United States
T2  - INSIGHTS INTO IMAGING
LA  - English
KW  - Artificial intelligence
KW  - Legislation
KW  - Policy
KW  - Privacy
KW  - Radiology
KW  - BIG DATA
KW  - FUTURE
KW  - DIAGNOSIS
AB  - Worldwide interest in artificial intelligence (AI) applications is growing rapidly. In medicine, devices based on machine/deep learning have proliferated, especially for image analysis, presaging new significant challenges for the utility of AI in healthcare. This inevitably raises numerous legal and ethical questions. In this paper we analyse the state of AI regulation in the context of medical device development, and strategies to make AI applications safe and useful in the future. We analyse the legal framework regulating medical devices and data protection in Europe and in the United States, assessing developments that are currently taking place. The European Union (EU) is reforming these fields with new legislation (General Data Protection Regulation [GDPR], Cybersecurity Directive, Medical Devices Regulation, In Vitro Diagnostic Medical Device Regulation). This reform is gradual, but it has now made its first impact, with the GDPR and the Cybersecurity Directive having taken effect in May, 2018. As regards the United States (U.S.), the regulatory scene is predominantly controlled by the Food and Drug Administration. This paper considers issues of accountability, both legal and ethical. The processes of medical device decision-making are largely unpredictable, therefore holding the creators accountable for it clearly raises concerns. There is a lot that can be done in order to regulate AI applications. If this is done properly and timely, the potentiality of AI based technology, in radiology as well as in other fields, will be invaluable.Teaching Points center dot AI applications are medical devices supporting detection/diagnosis, work-flow, cost-effectiveness.center dot Regulations for safety, privacy protection, and ethical use of sensitive information are needed.center dot EU and U.S. have different approaches for approving and regulating new medical devices.center dot EU laws consider cyberattacks, incidents (notification and minimisation), and service continuity.center dot U.S. laws ask for opt-in data processing and use as well as for clear consumer consent.
AD  - Univ Milan, Postgrad Sch Radiodiagnost, Via Festa Perdono 7, I-20122 Milan, ItalyAD  - 3 Greenwich Court,Cavell St, London E1 2BS, EnglandAD  - IRCCS Policlin San Donato, Unit Radiol, Via Morandi 30, I-20097 Milan, ItalyAD  - Univ Milan, Dept Biomed Sci Hlth, Via Morandi 30, I-20097 Milan, ItalyC3  - University of MilanC3  - IRCCS Policlinico San DonatoC3  - University of MilanPU  - SPRINGER
PI  - NEW YORK
PA  - ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES
SN  - 1869-4101
J9  - INSIGHTS IMAGING
JI  - Insights Imaging
DA  - OCT
PY  - 2018
VL  - 9
IS  - 5
SP  - 745
EP  - 753
DO  - 10.1007/s13244-018-0645-y
WE  - Science Citation Index Expanded (SCI-EXPANDED)AN  - WOS:000448802900011
N1  - Times Cited in Web of Science Core Collection:  242
Total Times Cited:  252
Cited Reference Count:  58
ER  -

TY  - JOUR
AU  - Cath, C
TI  - Governing artificial intelligence: ethical, legal and technical opportunities and challenges Introduction
T2  - PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY A-MATHEMATICAL PHYSICAL AND ENGINEERING SCIENCES
LA  - English
KW  - artificial intelligence
KW  - law
KW  - ethics
KW  - technology
KW  - governance
KW  - culture
KW  - EXPLANATION
KW  - AI
AB  - This paper is the introduction to the special issue entitled: 'Governing artificial intelligence: ethical, legal and technical opportunities and challenges. Artificial intelligence (AI) increasingly permeates every aspect of our society, from the critical, like urban infrastructure, law enforcement, banking, healthcare and humanitarian aid, to the mundane like dating. AI, including embodied AI in robotics and techniques like machine learning, can improve economic, social welfare and the exercise of human rights. Owing to the proliferation of AI in high-risk areas, the pressure is mounting to design and govern AI to be accountable, fair and transparent. How can this be achieved and through which frameworks? This is one of the central questions addressed in this special issue, in which eight authors present in-depth analyses of the ethical, legal-regulatory and technical challenges posed by developing governance regimes for AI systems. It also gives a brief overview of recent developments in AI governance, how much of the agenda for defining AI regulation, ethical frameworks and technical approaches is set, as well as providing some concrete suggestions to further the debate on AI governance.
   This article is part of the theme issue 'Governing artificial intelligence: ethical, legal, and technical opportunities and challenges'.
AD  - Univ Oxford, Oxford Internet Inst, 1 St Giles, Oxford OX1 3JS, EnglandAD  - Alan Turing Inst, 96 Euston Rd, London NW1 2DB, EnglandC3  - University of OxfordFU  - Privacy and Trust Stream-Social lead of the PETRAS Internet of Things research hub; Engineering and Physical Sciences Research Council (EPSRC) [EP/N023013/1]; EPSRC [EP/N023013/1] Funding Source: UKRI
FX  - Cath's and Floridi's contributions to the editing of this theme issue have been funded as part of the Privacy and Trust Stream-Social lead of the PETRAS Internet of Things research hub. PETRAS is funded by the Engineering and Physical Sciences Research Council (EPSRC), grant agreement no. EP/N023013/1.
PU  - ROYAL SOC
PI  - LONDON
PA  - 6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND
SN  - 1364-503X
SN  - 1471-2962
J9  - PHILOS T R SOC A
JI  - Philos. Trans. R. Soc. A-Math. Phys. Eng. Sci.
DA  - NOV 28
PY  - 2018
VL  - 376
IS  - 2133
C7  - 20180080
DO  - 10.1098/rsta.2018.0080
WE  - Science Citation Index Expanded (SCI-EXPANDED)AN  - WOS:000447313000001
N1  - Times Cited in Web of Science Core Collection:  187
Total Times Cited:  193
Cited Reference Count:  41
ER  -

TY  - JOUR
AU  - Nemitz, P
TI  - Constitutional democracy and technology in the age of artificial intelligence
T2  - PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY A-MATHEMATICAL PHYSICAL AND ENGINEERING SCIENCES
LA  - English
KW  - artificial intelligence
KW  - GDPR
KW  - democracy
KW  - rule of law
KW  - ethics
KW  - law
KW  - digital power
AB  - Given the foreseeable pervasiveness of artificial intelligence (AI) in modern societies, it is legitimate and necessary to ask the question how this new technology must be shaped to support the maintenance and strengthening of constitutional democracy. This paper first describes the four core elements of today's digital power concentration, which need to be seen in cumulation and which, seen together, are both a threat to democracy and to functioning markets. It then recalls the experience with the lawless Internet and the relationship between technology and the law as it has developed in the Internet economy and the experience with GDPR before it moves on to the key question for AI in democracy, namely which of the challenges of AI can be safely and with good conscience left to ethics, and which challenges of AI need to be addressed by rules which are enforceable and encompass the legitimacy of democratic process, thus laws. The paper closes with a call for a new culture of incorporating the principles of democracy, rule of law and human rights by design in AI and a three-level technological impact assessment for new technologies like AI as a practical way forward for this purpose.
   This article is part of a theme issue 'Governing artificial intelligence: ethical, legal, and technical opportunities and challenges'.
AD  - European Commiss, Directorate Gen Justice & Consumers, 59 Rue Montoyer, B-1049 Brussels, BelgiumPU  - ROYAL SOC
PI  - LONDON
PA  - 6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND
SN  - 1364-503X
SN  - 1471-2962
J9  - PHILOS T R SOC A
JI  - Philos. Trans. R. Soc. A-Math. Phys. Eng. Sci.
DA  - NOV 28
PY  - 2018
VL  - 376
IS  - 2133
C7  - 20180089
DO  - 10.1098/rsta.2018.0089
WE  - Science Citation Index Expanded (SCI-EXPANDED)AN  - WOS:000447313000008
N1  - Times Cited in Web of Science Core Collection:  112
Total Times Cited:  115
Cited Reference Count:  11
ER  -

TY  - JOUR
AU  - Mantelero, A
TI  - AI and Big Data: A blueprint for a human rights, social and ethical impact assessment
T2  - COMPUTER LAW & SECURITY REVIEW
LA  - English
KW  - Data protection
KW  - Impact assessment
KW  - Data protection impact assessment
KW  - Human rights
KW  - Human rights impact assessment
KW  - Ethical impact assessment
KW  - Social impact assessment
KW  - General Data Protection Regulation
KW  - PRIVACY
KW  - LAW
AB  - The use of algorithms in modern data processing techniques, as well as data-intensive technological trends, suggests the adoption of a broader view of the data protection impact assessment. This will force data controllers to go beyond the traditional focus on data quality and security, and consider the impact of data processing on fundamental rights and collective social and ethical values.
   Building on studies of the collective dimension of data protection, this article sets out to embed this new perspective in an assessment model centred on human rights (Human Rights, Ethical and Social Impact Assessment-HRESIA). This self-assessment model intends to overcome the limitations of the existing assessment models, which are either too closely focused on data processing or have an extent and granularity that make them too complicated to evaluate the consequences of a given use of data.
   In terms of architecture, the HRESIA has two main elements: a self-assessment questionnaire and an ad hoc expert committee. As a blueprint, this contribution focuses mainly on the nature of the proposed model, its architecture and its challenges; a more detailed description of the model and the content of the questionnaire will be discussed in a future publication drawing on the ongoing research. (C) 2018 Alessandro Mantelero. Published by Elsevier Ltd.
AD  - Polytech Univ Turin, Dept Management & Prod Engn, Turin, ItalyC3  - Polytechnic University of TurinFU  - European Union's Horizon 2020 research and innovation programme [732027]; H2020 - Industrial Leadership [732027] Funding Source: H2020 - Industrial Leadership
FX  - This article presents the first results of an ongoing research programme on "Legal and regulatory issues of data processing and related social impacts" (Polytechnic University of Thrin, 2017-2022, PI: Prof. Alessandro Mantelero). The results of this project, regarding the HRESIA model outlined here, are expected at the begin of 2019 and will be published in A. Mantelero (ed.), Addressing social and ethical issues in data processing, Springer (forthcoming 2019). I am grateful to Joe Cannataci for the comments he provided during the first presentation of my thoughts on this topic at the Expert workshop on the right to privacy in the digital age organised by the Office of the United Nations High Commissioner for Human Rights (Geneva, February 19-20, 2018). I am also grateful to Samantha Esposito for the analysis of DPAs' jurisprudence; her research has been partially supported by the European Union's Horizon 2020 research and innovation programme under grant agreement No. 732027 (Virt-EU project).
PU  - ELSEVIER ADVANCED TECHNOLOGY
PI  - OXFORD
PA  - OXFORD FULFILLMENT CENTRE THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN  - 0267-3649
J9  - COMPUT LAW SECUR REV
JI  - Comput. Law Secur. Rev.
DA  - AUG
PY  - 2018
VL  - 34
IS  - 4
SP  - 754
EP  - 772
DO  - 10.1016/j.clsr.2018.05.017
WE  - Social Science Citation Index (SSCI)AN  - WOS:000441655000010
N1  - Times Cited in Web of Science Core Collection:  97
Total Times Cited:  101
Cited Reference Count:  107
ER  -

TY  - JOUR
AU  - Villaronga, EF
AU  - Kieseberg, P
AU  - Li, T
TI  - Humans forget, machines remember: Artificial intelligence and the Right to Be Forgotten
T2  - COMPUTER LAW & SECURITY REVIEW
LA  - English
KW  - Right to Be Forgotten
KW  - Artificial intelligence (AI)
KW  - Privacy
KW  - Data deletion
KW  - Memory
AB  - This article examines the problem of AI memory and the Right to Be Forgotten. First, this article analyzes the legal background behind the Right to Be Forgotten, in order to understand its potential applicability to AI, including a discussion on the antagonism between the values of privacy and transparency under current E.U. privacy law. Next, the authors explore whether the Right to Be Forgotten is practicable or beneficial in an AI/machine learning context, in order to understand whether and how the law should address the Right to Be Forgotten in a post-AI world. The authors discuss the technical problems faced when adhering to strict interpretation of data deletion requirements under the Right to Be Forgotten, ultimately concluding that it may be impossible to fulfill the legal aims of the Right to Be Forgotten in artificial intelligence environments. Finally, this article addresses the core issue at the heart of the AI and Right to Be Forgotten problem: the unfortunate dearth of interdisciplinary scholarship supporting privacy law and regulation. (C) 2017 Eduard Fosch Villaronga, Peter Kieseberg, Tiffany Li. Published by Elsevier Ltd. All rights reserved.
AD  - Univ Twente, Drienerlolaan 5, NL-7522 NB Enschede, NetherlandsAD  - SBA Res, Vienna, AustriaAD  - WikimediaYale Law Sch Initiat Intermediaries & In, Yale Law Sch Informat Soc Project, New Haven, CT USAAD  - Princeton Ctr Informat Technol Policy, Princeton, NJ USAC3  - University of TwentePU  - ELSEVIER ADVANCED TECHNOLOGY
PI  - OXFORD
PA  - OXFORD FULFILLMENT CENTRE THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND
SN  - 0267-3649
J9  - COMPUT LAW SECUR REV
JI  - Comput. Law Secur. Rev.
DA  - APR
PY  - 2018
VL  - 34
IS  - 2
SP  - 304
EP  - 313
DO  - 10.1016/j.clsr.2017.08.007
WE  - Social Science Citation Index (SSCI)AN  - WOS:000430903700011
N1  - Times Cited in Web of Science Core Collection:  75
Total Times Cited:  81
Cited Reference Count:  18
ER  -

TY  - JOUR
AU  - Levendowski, A
TI  - HOW COPYRIGHT LAW CAN FIX ARTIFICIAL INTELLIGENCE'S IMPLICIT BIAS PROBLEM
T2  - WASHINGTON LAW REVIEW
LA  - English
KW  - FAIR
KW  - POWER
KW  - COPY
AB  - As the use of artificial intelligence (AI) continues to spread, we have seen an increase in examples of AI systems reflecting or exacerbating societal bias, from racist facial recognition to sexist natural language processing. These biases threaten to overshadow AI's technological gains and potential benefits. While legal and computer science scholars have analyzed many sources of bias, including the unexamined assumptions of its often homogenous creators, flawed algorithms, and incomplete datasets, the role of the law itself has been largely ignored. Yet just as code and culture play significant roles in how AI agents learn about and act in the world, so too do the laws that govern them. This Article is the first to examine perhaps the most powerful law impacting AI bias: copyright.
   Artificial intelligence often learns to "think" by reading, viewing, and listening to copies of human works. This Article first explores the problem of bias through the lens of copyright doctrine, looking at how the law's exclusion of access to certain copyrighted source materials may create or promote biased Al systems. Copyright law limits bias mitigation techniques, such as testing AI through reverse engineering, algorithmic accountability processes, and competing to convert customers. The rules of copyright law also privilege access to certain works over others, encouraging AI creators to use easily available, legally low-risk sources of data for teaching AI, even when those data are demonstrably biased. Second, it examines how a different part of copyright law the fair use doctrine has traditionally been used to address similar concerns in other technological fields, and asks whether it is equally capable of addressing them in the field of AI bias. The Article ultimately concludes that it is, in large part because the normative values embedded within traditional fair use ultimately align with the goals of mitigating Al bias and, quite literally, creating fairer AI systems.
AD  - NYU, Sch Law, New York, NY 10003 USAAD  - NYU, Informat Law Inst, New York, NY 10003 USAC3  - New York UniversityC3  - New York UniversityFU  - NYU Lawyering Scholarship Colloquium
FX  - Technology Law and Policy Clinical Teaching Fellow, New York University School of Law and Research Fellow, NYU Information Law Institute. Thanks to Solon Barocas, Barton Beebe, Ilya Beylin, Kiel Brennan-Marquez, Miles Brundage, Ryan Calo, Rochelle Dreyfuss, Seth Endo, Jeanne Fromer, Gautam Hans, Anne Hassett, H. Brian Holland, Sonia Katyal, Craig Konnoth, Karen Levy, Tiffany Li, Richard Loren Jolly, Laurel Reik, Zvi Rosen, Jason Schultz, Scott Skinner-Thompson, Naomi Sunshine, Chris Sprig-man, Eva Subotnik, Ari Waldman, Clinton Wallace, Rebecca Wexler, Felix Wu, and Cameron Tepski for their thoughtful observations and suggestions. Rachel Brooke provided stellar research assistance. Thanks also to the editors of the Washington Law Review for their insightful recommendations. I am also grateful to the organizers and participants of the 2017 Works-in-Progress in Intellectual Property Colloquium, the NYU Lawyering Scholarship Colloquium, We Robot 2017, the NYU Law Engelberg Center Faculty Workshop, the Intellectual Property Scholars Conference, and the Shefelman Faculty Workshop at the University of Washington, where I presented drafts of this paper. The NYU Technology Law and Policy Clinic filed amicus briefs in several cases discussed in this Article, and I previously worked for firms involved with other cases. Any discussion is based on public information and all views expressed are my own.
PU  - UNIV WASHINGTON SCHOOL OF LAW
PI  - SEATTLE
PA  - WASHINGTON LAW REVIEW 1100 NE CAMPUS PARKWAY 410 CONDON HALL, SEATTLE, WA 98105 USA
SN  - 0043-0617
J9  - WASH LAW REV
JI  - Wash. Law Rev.
DA  - JUN
PY  - 2018
VL  - 93
IS  - 2
SP  - 579
EP  - 630
WE  - Social Science Citation Index (SSCI)AN  - WOS:000445990600001
N1  - Times Cited in Web of Science Core Collection:  51
Total Times Cited:  56
Cited Reference Count:  206
ER  -

TY  - CPAPER
AU  - Erdélyi, OJ
AU  - Goldsmith, J
A1  - ACM
TI  - Regulating Artificial Intelligence Proposal for a Global Solution
T2  - PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18)
LA  - English
CP  - AAAI/ACM Conference on AI, Ethics, and Society (AIES)
KW  - Transnational legal ordering
KW  - international organizations
KW  - hard/soft law
KW  - international governance
AB  - Given the ubiquity of artificial intelligence (AI) in modern societies, it is clear that individuals, corporations, and countries will be grappling with the legal and ethical issues of its use. As global problems require global solutions, we propose the establishment of an international AI regulatory agency that - drawing on interdisciplinary expertise - could create a unified framework for the regulation of AI technologies and inform the development of AI policies around the world. We urge that such an organization be developed with all deliberate haste, as issues such as cryptocurrencies, personalized political ad hacking, autonomous vehicles and autonomous weaponized agents are already a reality, affecting international trade, politics, and war.
AD  - Univ Canterbury, Sch Law, Christchurch, New ZealandAD  - Univ Kentucky, Dept Comp Sci, Lexington, KY USAC3  - University of CanterburyC3  - University of KentuckyFU  - NSF [1646887]; Direct For Computer & Info Scie & Enginr [1646887] Funding Source: National Science Foundation; Div Of Information & Intelligent Systems [1646887] Funding Source: National Science Foundation
FX  - Part of the work was done while the first author was affiliated with the School of Economic Disciplines at University of Siegen. The second author was partially supported by NSF grant 1646887.
PU  - ASSOC COMPUTING MACHINERY
PI  - NEW YORK
PA  - 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
SN  - 978-1-4503-6012-8
PY  - 2018
SP  - 95
EP  - 101
DO  - 10.1145/3278721.3278731
WE  - Conference Proceedings Citation Index - Science (CPCI-S)WE  - Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)AN  - WOS:000510018100015
N1  - Times Cited in Web of Science Core Collection:  50
Total Times Cited:  54
Cited Reference Count:  19
ER  -

TY  - JOUR
AU  - Fowler, KA
AU  - Jack, SPD
AU  - Lyons, BH
AU  - Betz, CJ
AU  - Petrosky, E
TI  - Surveillance for Violent Deaths - National Violent Death Reporting System, 18 States, 2014
T2  - MMWR SURVEILLANCE SUMMARIES
LA  - English
KW  - PROGRAM
AB  - Problem/Condition: In 2014, approximately 59,000 persons died in the United States as a result of violence-related injuries. This report summarizes data from CDC's National Violent Death Reporting System (NVDRS) regarding violent deaths from 18 U.S. states for 2014. Results are reported by sex, age group, race/ethnicity, marital status, location of injury, method of injury, circumstances of injury, and other selected characteristics.
   Reporting Period Covered: 2014.
   Description of System: NVDRS collects data from participating states regarding violent deaths. Data are obtained from death certificates, coroner/medical examiner reports, law enforcement reports, and secondary sources (e.g., child fatality review team data, supplemental homicide reports, hospital data, and crime laboratory data). This report includes data from 18 states that collected statewide data for 2014 (Alaska, Colorado, Georgia, Kentucky, Maryland, Massachusetts, Michigan, New Jersey, New Mexico, North Carolina, Ohio, Oklahoma, Oregon, Rhode Island, South Carolina, Utah, Virginia, and Wisconsin). NVDRS collates documents for each death and links deaths that are related (e.g., multiple homicides, a homicide followed by a suicide, or multiple suicides) into a single incident.
   Results: For 2014, a total of 22,098 fatal incidents involving 22,618 deaths were captured by NVDRS in the 18 states included in this report. The majority of deaths were suicides (65.6%), followed by homicides (22.5%), deaths of undetermined intent (10.0%), deaths involving legal intervention (1.3%) (i.e., deaths caused by law enforcement and other persons with legal authority to use deadly force, excluding legal executions), and unintentional firearm deaths (< 1%). The term "legal intervention" is a classification incorporated into the International Classification of Diseases, Tenth Revision (ICD-10) and does not denote the lawfulness or legality of the circumstances surrounding a death caused by law enforcement. Suicides occurred at higher rates among males, non-Hispanic American Indian/Alaska Natives (AI/AN), non-Hispanic whites, persons aged 45-54 years, and males aged = 75 years. Suicides were preceded primarily by a mental health, intimate partner, substance abuse, or physical health problem or a crisis during the previous or upcoming 2 weeks. Homicide rates were higher among males and persons aged < 1 year and 15-44 years; rates were highest among non-Hispanic black and AI/AN males. Homicides primarily were precipitated by arguments and interpersonal conflicts, occurrence in conjunction with another crime, or related to intimate partner violence (particularly for females). When the relationship between a homicide victim and a suspected perpetrator was known, it was most often either an acquaintance/ friend or an intimate partner. Legal intervention death rates were highest among males and persons aged 20-44 years; rates were highest among non-Hispanic black males and Hispanic males. Precipitating factors for the majority of legal intervention deaths were alleged criminal activity in progress, the victim reportedly using a weapon in the incident, a mental health or substance abuse problem, an argument or conflict, or a recent crisis. Deaths of undetermined intent occurred more frequently among males, particularly non-Hispanic black and AI/AN males, and persons aged 30-54 years. Substance abuse, mental health problems, physical health problems, and a recent crisis were the most common circumstances preceding deaths of undetermined intent. Unintentional firearm deaths were more frequent among males, non-Hispanic whites, and persons aged 10-24 years; these deaths most often occurred while the shooter was playing with a firearm and were most often precipitated by a person unintentionally pulling the trigger or mistakenly thinking the firearm was unloaded.
   Interpretation: This report provides a detailed summary of data from NVDRS for 2014. The results indicate that violent deaths resulting from self-inflicted or interpersonal violence disproportionately affected persons aged < 65 years, males, and certain minority populations. The primary precipitating factors for homicides and suicides were intimate partner problems, interpersonal conflicts, mental health and substance abuse problems, and recent crises.
   Public Health Action: NVDRS data are used to monitor the occurrence of violence-related fatal injuries and assist public health authorities in the development, implementation, and evaluation of programs and policies to reduce and prevent violent deaths. For example, North Carolina VDRS data were used to improve case ascertainment of pregnancy-associated suicides, Wisconsin VDRS data were used to develop the statewide suicide prevention strategy, and Colorado VDRS data were used to develop programs and prevention strategies for suicide among veterans. The continued development and expansion of NVDRS to include all U.S. states, territories, and the District of Columbia are essential to public health efforts to reduce the impact of violence.
AD  - CDC, Natl Ctr Injury Prevent & Control, Div Violence Prevent, Atlanta, GA 30333 USAC3  - Centers for Disease Control & Prevention - USAPU  - CENTERS  DISEASE CONTROL & PREVENTION
PI  - ATLANTA
PA  - 1600 CLIFTON RD, ATLANTA, GA 30333 USA
SN  - 1545-8636
J9  - MMWR SURVEILL SUMM
JI  - MMWR Surv. Summ.
DA  - FEB 2
PY  - 2018
VL  - 67
IS  - 2
SP  - 1
EP  - 31
WE  - Science Citation Index Expanded (SCI-EXPANDED)WE  - Social Science Citation Index (SSCI)AN  - WOS:000429961600001
N1  - Times Cited in Web of Science Core Collection:  39
Total Times Cited:  42
Cited Reference Count:  30
ER  -

TY  - JOUR
AU  - Reed, C
TI  - How should we regulate artificial intelligence?
T2  - PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY A-MATHEMATICAL PHYSICAL AND ENGINEERING SCIENCES
LA  - English
KW  - artificial intelligence
KW  - machine learning
KW  - law
KW  - regulation
KW  - transparency
AB  - Using artificial intelligence (AI) technology to replace human decision-making will inevitably create new risks whose consequences are unforeseeable. This naturally leads to calls for regulation, but I argue that it is too early to attempt a general system of AI regulation. Instead, we should work incrementally within the existing legal and regulatory schemes which allocate responsibility, and therefore liability, to persons. Where AI clearly creates risks which current law and regulation cannot deal with adequately, then new regulation will be needed. But in most cases, the current system can work effectively if the producers of AI technology can provide sufficient transparency in explaining how AI decisions are made. Transparency ex post can often be achieved through retrospective analysis of the technology's operations, and will be sufficient if the main goal is to compensate victims of incorrect decisions. Ex ante transparency is more challenging, and can limit the use of some AI technologies such as neural networks. It should only be demanded by regulation where the AI presents risks to fundamental rights, or where society needs reassuring that the technology can safely be used. Masterly inactivity in regulation is likely to achieve a better long-term solution than a rush to regulate in ignorance.
   This article is part of a discussion meeting issue 'The growing ubiquity of algorithms in society: implications, impacts and innovations'.
AD  - Queen Mary Univ London, Ctr Commercial Law Studies, Sch Law, London, EnglandC3  - University of LondonC3  - Queen Mary University LondonFU  - Microsoft research
FX  - This work emanates from the Microsoft Cloud Computing Research Centre, a collaboration between the Cloud Legal Project, Centre for Commercial Law Studies, Queen Mary University of London and the Department of Computer Science and Technology, University of Cambridge, which is generously supported by a Microsoft research donation.
PU  - ROYAL SOC
PI  - LONDON
PA  - 6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND
SN  - 1364-503X
SN  - 1471-2962
J9  - PHILOS T R SOC A
JI  - Philos. Trans. R. Soc. A-Math. Phys. Eng. Sci.
DA  - SEP 13
PY  - 2018
VL  - 376
IS  - 2128
C7  - 20170360
DO  - 10.1098/rsta.2017.0360
WE  - Science Citation Index Expanded (SCI-EXPANDED)AN  - WOS:000440870000009
N1  - Times Cited in Web of Science Core Collection:  34
Total Times Cited:  35
Cited Reference Count:  28
ER  -

