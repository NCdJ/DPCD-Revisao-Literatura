TY  - JOUR
AU  - Nagy, N.
TI  - "Humanity's new frontier": Human rights implications of artificial intelligence and new technologies
PY  - 2024
T2  - Hungarian Journal of Legal Studies
VL  - 64
IS  - 2
SP  - 236
EP  - 267
DO  - 10.1556/2052.2023.00481
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189909172&doi=10.1556%2f2052.2023.00481&partnerID=40&md5=7c98467be3e74bb7da1c3e9521f3bc10
AD  - Ludovika University of Public Service, Budapest, Hungary
AB  - New technologies based on digitalization, automation, and artificial intelligence have fundamentally transformed our lives and society as a whole, in just a few decades. These technologies support human well-being and prosperity by enhancing progress and innovation, however, they also have the potential to negatively impact human rights, democracy, and the rule of law. Discrimination, the violation of privacy, increasing surveillance, the weakening of personal autonomy, disinformation and electoral interference are but a few of the many concerns. This paper examines the specific human rights implications of AI-driven systems through the lens of the most important international instruments adopted by the UN and regional human rights mechanisms. The paper shows how AI can affect the exercise of all human rights, not only a most obvious few. In line with major international organizations, the author calls on decision-makers to take a precautionary approach by adopting AI regulations that are consistent with the standards of fundamental human rights, and that balance the realization of the opportunities with the potential risks which AI presents.  © 2023 The Author(s).
KW  - AI and human rights
KW  - civil
KW  - discrimination
KW  - economic
KW  - political
KW  - social and cultural rights
PB  - Akademiai Kiado ZRt.
SN  - 24985473 (ISSN)
LA  - English
J2  - Hung. J. Leg. Stud.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 3; Correspondence Address: N. Nagy; Ludovika University of Public Service, Budapest, Hungary; email: nagynoemi@uni-nke.hu
ER  -

TY  - JOUR
AU  - Bouderhem, R.
TI  - Shaping the future of AI in healthcare through ethics and governance
PY  - 2024
T2  - Humanities and Social Sciences Communications
VL  - 11
IS  - 1
C7  - 416
DO  - 10.1057/s41599-024-02894-w
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187899065&doi=10.1057%2fs41599-024-02894-w&partnerID=40&md5=2cfd64bcbe42bd9622049d9e06475b4e
AD  - College of Law, Prince Mohammad Bin Fahd University, Al Khobar, Saudi Arabia
AD  - Research Associate CREDIMI (FRE 2003) CNRS - University of Burgundy, Dijon, France
AB  - The purpose of this research is to identify and evaluate the technical, ethical and regulatory challenges related to the use of Artificial Intelligence (AI) in healthcare. The potential applications of AI in healthcare seem limitless and vary in their nature and scope, ranging from privacy, research, informed consent, patient autonomy, accountability, health equity, fairness, AI-based diagnostic algorithms to care management through automation for specific manual activities to reduce paperwork and human error. The main challenges faced by states in regulating the use of AI in healthcare were identified, especially the legal voids and complexities for adequate regulation and better transparency. A few recommendations were made to protect health data, mitigate risks and regulate more efficiently the use of AI in healthcare through international cooperation and the adoption of harmonized standards under the World Health Organization (WHO) in line with its constitutional mandate to regulate digital and public health. European Union (EU) law can serve as a model and guidance for the WHO for a reform of the International Health Regulations (IHR). © The Author(s) 2024.
PB  - Springer Nature
SN  - 26629992 (ISSN)
LA  - English
J2  - Hum. Soc. Sci. Comm
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 7; Correspondence Address: R. Bouderhem; College of Law, Prince Mohammad Bin Fahd University, Al Khobar, Saudi Arabia; email: rbouderhem@pmu.edu.sa
ER  -

TY  - JOUR
AU  - Sanchez-Graells, A.
TI  - Resh(AI)ping Good Administration: Addressing the Mass Effects of Public Sector Digitalisation
PY  - 2024
T2  - Laws
VL  - 13
IS  - 1
C7  - 9
DO  - 10.3390/laws13010009
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187256502&doi=10.3390%2flaws13010009&partnerID=40&md5=268dc99ee46b15cd15e029269fadad15
AD  - Law School, Faculty of Arts, Law and Social Sciences, University of Bristol, Clifton Campus, Bristol, BS8 1RJ, United Kingdom
AB  - Public sector digitalisation is transforming public governance at an accelerating rate. Digitalisation is outpacing the evolution of the legal framework. Despite several strands of international efforts to adjust good administration guarantees to new modes of digital public governance, progress has so far been slow and tepid. The increasing automation of decision-making processes puts significant pressure on traditional good administration guarantees, jeopardises individual due process rights, and risks eroding public trust. Automated decision-making has, so far, attracted the bulk of scholarly attention, especially in the European context. However, most analyses seek to reconcile existing duties towards individuals under the right to good administration with the challenges arising from digitalisation. Taking a critical and technology-centred doctrinal approach to developments under the law of the European Union and the Council of Europe, this paper goes beyond current debates to challenge the sufficiency of existing good administration duties. By stressing the mass effects that can derive from automated decision-making by the public sector, the paper advances the need to adapt good administration guarantees to a collective dimension through an extension and a broadening of the public sector’s good administration duties: that is, through an extended ex ante control of organisational risk-taking, and a broader ex post duty of automated redress. These legal modifications should be urgently implemented. © 2024 by the author.
KW  - automated decision-making
KW  - automated redress
KW  - collective interests
KW  - digitalisation
KW  - good administration
KW  - mass effects
KW  - organisational risk-taking
KW  - public sector
KW  - public trust
PB  - Multidisciplinary Digital Publishing Institute (MDPI)
SN  - 2075471X (ISSN)
LA  - English
J2  - Law.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 4; Correspondence Address: A. Sanchez-Graells; Law School, Faculty of Arts, Law and Social Sciences, University of Bristol, Bristol, Clifton Campus, BS8 1RJ, United Kingdom; email: a.sanchez-graells@bristol.ac.uk
ER  -

TY  - JOUR
AU  - Gray, M.A.
AU  - Savelka, J.
AU  - Oliver, W.M.
AU  - Ashley, K.D.
TI  - Empirical legal analysis simplified: reducing complexity through automatic identification and evaluation of legally relevant factors
PY  - 2024
T2  - Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences
VL  - 382
IS  - 2270
C7  - 20230155
DO  - 10.1098/rsta.2023.0155
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186139883&doi=10.1098%2frsta.2023.0155&partnerID=40&md5=ac373bcb3cdf2be22e22eb39267e6951
AD  - Intelligent Systems Program, University of Pittsburgh, Pittsburgh, PA, United States
AD  - School of Law, University of Pittsburgh, Pittsburgh, PA, United States
AD  - School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, United States
AD  - Thomas R. Kline School of Law, Duquesne University, Pittsburgh, PA, United States
AB  - This paper investigates the potential for reducing the complexity of AI and Law and empirical legal studies projects through a novel annotation methodology that relies on GPT Family Models to assist human annotators. Improving the speed, cost and quality of annotation could greatly benefit such projects. In modelling types of legal claims, researchers in the fields of empirical legal studies and AI and Law have long relied on manually annotating factors in case texts. To demonstrate our methodology, we employ cases and factors regarding whether a police officer has constitutional authority to detain a motorist on the basis of the officer's suspicion that the motorist is trafficking drugs. Our results demonstrate how recent advances in text analytics can reduce the burden of identifying factors in large numbers of cases and improve machine learning models' predictions of case outcomes. This article is part of the theme issue 'A complexity science approach to law and governance'.  © 2024 The Author(s).
KW  - annotation
KW  - generative classification
KW  - interpretability
KW  - large language models
KW  - machine learning
KW  - Humans
KW  - Machine Learning
KW  - Automation
KW  - Crime
KW  - AI and law
KW  - Annotation
KW  - Automatic evaluation
KW  - Automatic identification
KW  - Generative classifications
KW  - Identification and evaluation
KW  - Interpretability
KW  - Language model
KW  - Large language model
KW  - Machine-learning
KW  - human
KW  - machine learning
KW  - Machine learning
PB  - Royal Society Publishing
SN  - 1364503X (ISSN)
C2  - 38403058
LA  - English
J2  - Philos. Trans. R. Soc. A Math. Phys. Eng. Sci.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 4; Correspondence Address: M.A. Gray; Intelligent Systems Program, University of Pittsburgh, Pittsburgh, United States; email: mag454@pitt.edu
ER  -

TY  - JOUR
AU  - Houghtaling, M.A.
AU  - Rama Fiorini, S.
AU  - Fabiano, N.
AU  - Gonçalves, P.J.S.
AU  - Ulgen, O.
AU  - Haidegger, T.
AU  - Luís Carbonera, J.
AU  - Isabelle Olszewska, J.
AU  - Page, B.
AU  - Murahwi, Z.
AU  - Prestes, E.
TI  - Standardizing an Ontology for Ethically Aligned Robotic and Autonomous Systems
PY  - 2024
T2  - IEEE Transactions on Systems, Man, and Cybernetics: Systems
VL  - 54
IS  - 3
SP  - 1791
EP  - 1804
DO  - 10.1109/TSMC.2023.3330981
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184795445&doi=10.1109%2fTSMC.2023.3330981&partnerID=40&md5=1e68d1a3dbee83fa123b907205a850e3
AD  - was with IBM Systems and Technology Group, USA., Tucson, 85750, AZ, United States
AD  - with IBM Research, Rio de Janeiro, 20031-170, Brazil
AD  - the Studio Legale Fabiano, University of Ostrava, Rome, 00183, Italy
AD  - IDMEC, Instituto Politécnico de Castelo Branco, Castelo Branco, 6000-084, Portugal
AD  - the School of Law, University of Nottingham, Nottingham, NG7 2RD, United Kingdom
AD  - the University Research and Innovation Center, Óbuda University, Budapest, 1034, Hungary
AD  - the Informatics Institute, Federal University of Rio Grande do Sul, Porto Alegre, 90010-150, Brazil
AD  - the School of Computing and Engineering, University of the West of Scotland, Glasgow, G72 0LH, United Kingdom
AD  - with Visiontech Communications, Spokane Valley, 99216, WA, United States
AD  - the Department of Research and Development, Gratia ICT Projects Advisory, Johannesburg, 2196, South Africa
AB  - —Domain-specific ontologies support system design and can establish a framework for fulfilling user-level, safety, or ethical requirements. The IEEE 7007-2021 Ontological Standard for ethically driven robotics and automation systems is the first industry standard to introduce a structure of ontologies concerning robot ethics and related fields, such as data privacy, transparency, responsibility, and accountability, offering a systems science approach to support the ethically aligned design of complex cyber–physical systems (CPSs) and robots particularly. This article provides a comprehensive overview of the main ontological commitments composing the foundation of the standard, the rationale behind their development, together with use cases of applications. Future directions for ethically aligned robotics and artificial intelligence (AI)-based systems along IEEE 7007-2021 are outlined, taking into account the exponentially growing fields of service and medical robotics. © 2024 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.
KW  - Accountability
KW  - automation
KW  - ethics
KW  - ontology
KW  - privacy
KW  - responsibility
KW  - robotics
KW  - standards
KW  - transparency
KW  - Data privacy
KW  - Laws and legislation
KW  - Machine design
KW  - Ontology
KW  - Philosophical aspects
KW  - Robots
KW  - Semantics
KW  - Transparency
KW  - Accountability
KW  - Domain-specific ontologies
KW  - Ontology's
KW  - Privacy
KW  - Responsibility
KW  - Robotic systems
KW  - Support systems
KW  - User levels
KW  - Vocabulary
KW  - Unified Modeling Language
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 21682216 (ISSN)
LA  - English
J2  - IEEE Trans. Syst. Man Cybern. Syst.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 8; Correspondence Address: T. Haidegger; the University Research and Innovation Center, Óbuda University, Budapest, 1034, Hungary; email: haidegger@ieee.org
ER  -

TY  - JOUR
AU  - Hirvonen, H.
TI  - Just accountability structures – a way to promote the safe use of automated decision-making in the public sector
PY  - 2024
T2  - AI and Society
VL  - 39
IS  - 1
SP  - 155
EP  - 167
DO  - 10.1007/s00146-023-01731-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167817084&doi=10.1007%2fs00146-023-01731-z&partnerID=40&md5=b81c36a421f5c42f7f2acb90153fca74
AD  - Doctoral Programme in Law, University of Helsinki and Legal Counsel at Turre Legal LLC, Helsinki, Finland
AB  - The growing use of automated decision-making (ADM) systems in the public sector and the need to control these has raised many legal questions in academic research and in policymaking. One of the timely means of legal control is accountability, which traditionally includes the ability to impose sanctions on the violator as one dimension. Even though many risks regarding the use of ADM have been noted and there is a common will to promote the safety of these systems, the relevance of the safety research has been discussed little in this context. In this article, I evaluate regulating accountability over the use of ADM in the public sector in relation to the findings of safety research. I conducted the study by focusing on ongoing regulatory projects regarding ADM, the Finnish ADM legislation draft and the EU proposal for the AI Act. The critical question raised in the article is what the role of sanctions is. I ask if official accountability could mean more of an opportunity to learn from mistakes, share knowledge and compensate for harm instead of control via sanctions. © The Author(s) 2023.
KW  - Accountability structures
KW  - Artificial intelligence
KW  - Automated decision-making
KW  - Official accountability
KW  - Public accountability
KW  - Safety research
KW  - Sanctions
KW  - Automation
KW  - Decision making
KW  - Academic research
KW  - Accountability structure
KW  - Automated decision making
KW  - Automated decision making systems
KW  - Legal questions
KW  - Official accountability
KW  - Public accountability
KW  - Public sector
KW  - Safety research
KW  - Sanction
KW  - Laws and legislation
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 09515666 (ISSN)
LA  - English
J2  - AI Soc.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 5; Correspondence Address: H. Hirvonen; Doctoral Programme in Law, University of Helsinki and Legal Counsel at Turre Legal LLC, Helsinki, Finland; email: hanne.hirvonen@helsinki.fi
ER  -

TY  - JOUR
AU  - Abimbola, B.
AU  - de La Cal Marin, E.
AU  - Tan, Q.
TI  - Enhancing Legal Sentiment Analysis: A Convolutional Neural Network–Long Short-Term Memory Document-Level Model
PY  - 2024
T2  - Machine Learning and Knowledge Extraction
VL  - 6
IS  - 2
SP  - 877
EP  - 897
DO  - 10.3390/make6020041
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196799693&doi=10.3390%2fmake6020041&partnerID=40&md5=a2957372c0489232c9bed4b12e7ffe89
AD  - Department of Computer Science, University of Oviedo, Oviedo, 33003, Spain
AD  - Faculty of Science and Technology, Athabasca University, 1 University Drive, Athabasca, T9S 3A3, AB, Canada
AB  - This research investigates the application of deep learning in sentiment analysis of Canadian maritime case law. It offers a framework for improving maritime law and legal analytic policy-making procedures. The automation of legal document extraction takes center stage, underscoring the vital role sentiment analysis plays at the document level. Therefore, this study introduces a novel strategy for sentiment analysis in Canadian maritime case law, combining sentiment case law approaches with state-of-the-art deep learning techniques. The overarching goal is to systematically unearth hidden biases within case law and investigate their impact on legal outcomes. Employing Convolutional Neural Network (CNN)- and long short-term memory (LSTM)-based models, this research achieves a remarkable accuracy of 98.05% for categorizing instances. In contrast, conventional machine learning techniques such as support vector machine (SVM) yield an accuracy rate of 52.57%, naïve Bayes at 57.44%, and logistic regression at 61.86%. The superior accuracy of the CNN and LSTM model combination underscores its usefulness in legal sentiment analysis, offering promising future applications in diverse fields like legal analytics and policy design. These findings mark a significant choice for AI-powered legal tools, presenting more sophisticated and sentiment-aware options for the legal profession. © 2024 by the authors.
KW  - convolutional neural networks
KW  - deep neural networks
KW  - long short-term memory
KW  - recurrent neural networks
KW  - sentimental analysis
PB  - Multidisciplinary Digital Publishing Institute (MDPI)
SN  - 25044990 (ISSN)
LA  - English
J2  - Mach. Learn. Knowl. Extr.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 3; Correspondence Address: B. Abimbola; Department of Computer Science, University of Oviedo, Oviedo, 33003, Spain; email: uo285018@uniovi.es
ER  -

TY  - JOUR
AU  - Parycek, P.
AU  - Schmid, V.
AU  - Novak, A.-S.
TI  - Artificial Intelligence (AI) and Automation in Administrative Procedures: Potentials, Limitations, and Framework Conditions
PY  - 2024
T2  - Journal of the Knowledge Economy
VL  - 15
IS  - 2
SP  - 8390
EP  - 8415
DO  - 10.1007/s13132-023-01433-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162224524&doi=10.1007%2fs13132-023-01433-3&partnerID=40&md5=30aa8fcb01928e9b0a14c832f57afc62
AD  - Vice Rector - Vice Rectorate for Teaching/Scientific Education and Digital Transformation (CDO), University for Continuing Education Krems, Krems an Der Donau, Austria
AD  - Research Associate, University for Continuing Education Krems, Krems an Der Donau, Austria
AB  - Integrating artificial intelligence (AI) systems into administrative procedures can revolutionize the way processes are conducted and fundamentally change established forms of action and organization in administrative law. However, implementing AI in administrative procedures requires a comprehensive evaluation of the capabilities and limitations of different systems, including considerations of transparency and data availability. Data are a crucial factor in the operation of AI systems and the validity of their predictions. It is essential to ensure that the data used to train AI algorithms are extensive, representative, and free of bias. Transparency is also an important aspect establishing trust and reliability in AI systems, particularly regarding the potential for transparent representation in rule-based and machine-learning AI systems. This paper examines the potential and challenges that arise from integrating AI into administrative procedures. In addition, the paper offers a nuanced perspective on current developments in artificial intelligence and provides a conceptual framework for its potential applications in administrative procedures. Beyond this, the paper highlights essential framework conditions that require continuous monitoring to ensure optimal results in practice. © The Author(s) 2023.
KW  - AI
KW  - Artificial intelligence
KW  - Automation
KW  - Bias
KW  - Digital Government
KW  - Digital law
KW  - E-Government
KW  - Law
KW  - Legal Tech
KW  - Transparency
PB  - Springer
SN  - 18687865 (ISSN)
LA  - English
J2  - J. Knowl. Econ.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 14; Correspondence Address: A.-S. Novak; Research Associate, University for Continuing Education Krems, Krems an Der Donau, Austria; email: anna-sophie.novak@donau-uni.ac.at
ER  -

TY  - JOUR
AU  - Ni, B.
AU  - Buehler, M.J.
TI  - MechAgents: Large language model multi-agent collaborations can solve mechanics problems, generate new data, and integrate knowledge
PY  - 2024
T2  - Extreme Mechanics Letters
VL  - 67
C7  - 102131
DO  - 10.1016/j.eml.2024.102131
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185307555&doi=10.1016%2fj.eml.2024.102131&partnerID=40&md5=8d8520113f0544792728b07b79d75fc5
AD  - Laboratory for Atomistic and Molecular Mechanics (LAMM), Massachusetts Institute of Technology, 77 Massachusetts Ave, Cambridge, 02139, MA, United States
AD  - Center for Computational Science and Engineering, Schwarzman College of Computing, Massachusetts Institute of Technology, 77 Massachusetts Ave, Cambridge, 02139, MA, United States
AB  - Solving mechanics problems using numerical methods requires comprehensive intelligent capability of retrieving relevant knowledge and theory, constructing and executing codes, analyzing the results, a task that has thus far mainly been reserved for humans. While emerging AI methods can provide effective approaches to solve end-to-end problems, for instance via the use of deep surrogate models or various data analytics strategies, they often lack physical intuition since knowledge is baked into the parametric complement through training, offering less flexibility when it comes to incorporating mathematical or physical insights. By leveraging diverse capabilities of multiple dynamically interacting large language models (LLMs), we can overcome the limitations of conventional approaches and develop a new class of physics-inspired generative machine learning platform, here referred to as MechAgents. A set of AI agents can solve mechanics tasks, here demonstrated for elasticity problems, via autonomous collaborations. A two-agent team can effectively write, execute and self-correct code, in order to apply finite element methods to solve classical elasticity problems in various flavors (different boundary conditions, domain geometries, meshes, small/finite deformation and linear/hyper-elastic constitutive laws, and others). For more complex tasks, we construct a larger group of agents with enhanced division of labor among planning, formulating, coding, executing and criticizing the process and results. The agents mutually correct each other to improve the overall team-work performance in understanding, formulating and validating the solution. Our framework shows the potential of synergizing the intelligence of language models, the reliability of physics-based modeling, and the dynamic collaborations among diverse agents, opening novel avenues for automation of solving engineering problems. © 2024 Elsevier Ltd
KW  - Elasticity
KW  - Finite element method
KW  - GPT-4
KW  - Hyper-elasticity
KW  - Large language model (LLM)
KW  - Multi-agent modeling
KW  - Physics-inspired machine learning
KW  - Autonomous agents
KW  - Computational linguistics
KW  - Computational methods
KW  - Data Analytics
KW  - Finite element method
KW  - Machine learning
KW  - Modeling languages
KW  - Numerical methods
KW  - Agent collaboration
KW  - Elasticity problems
KW  - GPT-4
KW  - Hyper-elasticity
KW  - Language model
KW  - Large language model
KW  - Machine-learning
KW  - Multi agent
KW  - Multi-Agent Model
KW  - Physic-inspired machine learning
KW  - Elasticity
PB  - Elsevier Ltd
SN  - 23524316 (ISSN)
LA  - English
J2  - Extrem. Mech. Lett.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 9; Correspondence Address: M.J. Buehler; Laboratory for Atomistic and Molecular Mechanics (LAMM), Massachusetts Institute of Technology, Cambridge, 77 Massachusetts Ave, 02139, United States; email: mbuehler@MIT.EDU
ER  -

TY  - JOUR
AU  - Wulf, A.J.
AU  - Seizov, O.
TI  - “Please understand we cannot provide further information”: evaluating content and transparency of GDPR-mandated AI disclosures
PY  - 2024
T2  - AI and Society
VL  - 39
IS  - 1
SP  - 235
EP  - 256
DO  - 10.1007/s00146-022-01424-z
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129848315&doi=10.1007%2fs00146-022-01424-z&partnerID=40&md5=cfb71983c01c1926c27f15a26947f52a
AD  - Berlin School of Management, SRH Berlin University of Applied Sciences, Ernst-Reuter-Platz 10, Berlin, 10587, Germany
AB  - The General Data Protection Regulation (GDPR) of the EU confirms the protection of personal data as a fundamental human right and affords data subjects more control over the way their personal information is processed, shared, and analyzed. However, where data are processed by artificial intelligence (AI) algorithms, asserting control and providing adequate explanations is a challenge. Due to massive increases in computing power and big data processing, modern AI algorithms are too complex and opaque to be understood by most data subjects. Articles 15 and 22 of the GDPR provide a modest regulatory framework for automated data processing by, among other things, mandating that data controllers inform data subjects about when it is being used, and its logic and ramifications. Nevertheless, due to the phrasing of the articles and the numerous exceptions they allow, doubts have arisen about their effectiveness. In this paper, we empirically evaluate the quality and effectiveness of AI disclosures as mandated by the GDPR. By means of an online survey (N = 835), we investigated how data subjects expect to be informed about the automated processing of their data. We then conducted a content analysis of the AI disclosures of N = 100 companies and organizations. The combined findings reveal that current GDPR-mandated disclosures do not meet the expectations and needs of data subjects. Explanations drawn up following the guidelines of the generic formulations of the GDPR differ widely and are often vague, incomplete and lack transparency. In our conclusions we identify a path towards standardizing and optimizing AI information notices. © The Author(s) 2022.
KW  - Artificial intelligence
KW  - Automated data processing
KW  - Empirical legal studies
KW  - Explainable AI
KW  - GDPR
KW  - Information disclosures
KW  - Artificial intelligence
KW  - Automation
KW  - Computation theory
KW  - Laws and legislation
KW  - Quality control
KW  - Artificial intelligence algorithms
KW  - Automated data processing
KW  - Computing power
KW  - Data subjects
KW  - Empirical legal study
KW  - Explainable artificial intelligence
KW  - General data protection regulations
KW  - Human rights
KW  - Information disclosure
KW  - Personal information
KW  - Transparency
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 09515666 (ISSN)
LA  - English
J2  - AI Soc.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 13; Correspondence Address: A.J. Wulf; Berlin School of Management, SRH Berlin University of Applied Sciences, Berlin, Ernst-Reuter-Platz 10, 10587, Germany; email: alexander.wulf@srh.de
ER  -

