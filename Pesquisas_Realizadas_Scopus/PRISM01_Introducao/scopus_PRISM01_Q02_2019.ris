TY  - JOUR
AU  - Gunning, D.
AU  - Stefik, M.
AU  - Choi, J.
AU  - Miller, T.
AU  - Stumpf, S.
AU  - Yang, G.-Z.
TI  - XAI-Explainable artificial intelligence
PY  - 2019
T2  - Science Robotics
VL  - 4
IS  - 37
C7  - eaay7120
DO  - 10.1126/scirobotics.aay7120
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077809710&doi=10.1126%2fscirobotics.aay7120&partnerID=40&md5=b25a8aab746ae4d7ee21f6629b3dc7ea
AD  - Defense Advanced Research Projects Agency (DARPA), 675 North Randolph Street, Arlington, 22201, VA, United States
AD  - Palo Alto Research Center, 3333 Coyote Hill Road, Palo Alto, 94304, CA, United States
AD  - Graduate School of Artificial Intelligence, Korea Advanced Institute of Science and Technology, 291 Daehak-ro, Yuseong-gu, Daejeon, 34141, South Korea
AD  - School of Computing and Information Systems, University of Melbourne, 3010, VIC, Australia
AD  - Centre for HCI Design, School of Mathematics, Computer Science and Engineering, City, University of London, London, EC1V 0HB, United Kingdom
AD  - Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, China
AD  - Facebook AI Research, 770 Broadway, New York, 10003, NY, United States
AB  - Recent successes in machine learning (ML) have led to a new wave of artificial intelligence (AI) applications that offer extensive benefits to a diverse range of fields. However, many of these systems are not able to explain their autonomous decisions and actions to human users. Explanations may not be essential for certain AI applications, and some AI researchers argue that the emphasis on explanation is misplaced, too difficult to achieve, and perhaps unnecessary. However, for many critical applications in defense, medicine, finance, and law, explanations are essential for users to understand, trust, and effectively manage these new, artificially intelligent partners [see recent reviews (1-3)]. Copyright © 2019 The Authors, some rights reserved; exclusive licensee American Association for the Advancement of Science. No claim to original U.S. Government Works
KW  - AI applications
KW  - Autonomous decision
KW  - Critical applications
KW  - Diverse range
KW  - Human users
KW  - artificial intelligence
KW  - review
KW  - trust
KW  - Artificial intelligence
PB  - American Association for the Advancement of Science
SN  - 24709476 (ISSN)
C2  - 33137719
LA  - English
J2  - Sci. Robotics
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 1149; Correspondence Address: D. Gunning; Defense Advanced Research Projects Agency (DARPA), Arlington, 675 North Randolph Street, 22201, United States; email: dgunning@fb.com
ER  -

TY  - JOUR
AU  - O'Sullivan, S.
AU  - Nevejans, N.
AU  - Allen, C.
AU  - Blyth, A.
AU  - Leonard, S.
AU  - Pagallo, U.
AU  - Holzinger, K.
AU  - Holzinger, A.
AU  - Sajid, M.I.
AU  - Ashrafian, H.
TI  - Legal, regulatory, and ethical frameworks for development of standards in artificial intelligence (AI) and autonomous robotic surgery
PY  - 2019
T2  - International Journal of Medical Robotics and Computer Assisted Surgery
VL  - 15
IS  - 1
C7  - e1968
DO  - 10.1002/rcs.1968
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059739836&doi=10.1002%2frcs.1968&partnerID=40&md5=cbbb62d767531d8bfa21576a49ef1535
AD  - Department of Pathology, Faculdade de Medicina, Universidade de São Paulo, São Paulo, Brazil
AD  - Research Center in Law, Ethics and Procedures, Faculty of Law of Douai, University of Artois, France
AD  - Department of History and Philosophy of Science, University of Pittsburgh, United States
AD  - Department of Computing and Mathematics, Faculty of Computing, Engineering and Science, University of South Wales, United Kingdom
AD  - Department of Computer Science, Johns Hopkins University, Baltimore, United States
AD  - Department of Jurisprudence, University of Turin, Italy
AD  - Secure Business Austria, SBA Research gGmbH, Vienna, Austria
AD  - Holzinger Group, HCI-KDD, Institute for Medical Informatics/Statistics. Medical University of Graz, Austria
AD  - Department of Upper GI Surgery, Wirral University Teaching Hospital, United Kingdom
AD  - Department of Surgery and Cancer and Institute of Global Health Innovation Imperial College London, United Kingdom
AB  - Background: This paper aims to move the debate forward regarding the potential for artificial intelligence (AI) and autonomous robotic surgery with a particular focus on ethics, regulation and legal aspects (such as civil law, international law, tort law, liability, medical malpractice, privacy and product/device legislation, among other aspects). Methods: We conducted an intensive literature search on current or emerging AI and autonomous technologies (eg, vehicles), military and medical technologies (eg, surgical robots), relevant frameworks and standards, cyber security/safety- and legal-systems worldwide. We provide a discussion on unique challenges for robotic surgery faced by proposals made for AI more generally (eg, Explainable AI) and machine learning more specifically (eg, black box), as well as recommendations for developing and improving relevant frameworks or standards. Conclusion: We classify responsibility into the following: (1) Accountability; (2) Liability; and (3) Culpability. All three aspects were addressed when discussing responsibility for AI and autonomous surgical robots, be these civil or military patients (however, these aspects may require revision in cases where robots become citizens). The component which produces the least clarity is Culpability, since it is unthinkable in the current state of technology. We envision that in the near future a surgical robot can learn and perform routine operative tasks that can then be supervised by a human surgeon. This represents a surgical parallel to autonomously driven vehicles. Here a human remains in the ‘driving seat’ as a ‘doctor-in-the-loop’ thereby safeguarding patients undergoing operations that are supported by surgical machines with autonomous capabilities. © 2018 John Wiley & Sons, Ltd.
KW  - Algorithms
KW  - Artificial Intelligence
KW  - Computer Security
KW  - Ethics, Medical
KW  - Europe
KW  - Humans
KW  - Medical Errors
KW  - Robotic Surgical Procedures
KW  - United States
KW  - Ethical technology
KW  - Intelligent robots
KW  - Surgical equipment
KW  - Artificial intelligence technologies
KW  - Autonomous robotics
KW  - Autonomous technology
KW  - Civil laws
KW  - Legal aspects
KW  - Literature search
KW  - On currents
KW  - On-currents
KW  - Robotics surgery
KW  - Vehicle technology
KW  - adult
KW  - army
KW  - artificial intelligence
KW  - ethics
KW  - human
KW  - international law
KW  - machine learning
KW  - malpractice
KW  - medical technology
KW  - privacy
KW  - responsibility
KW  - review
KW  - robot assisted surgery
KW  - surgeon
KW  - surgery
KW  - algorithm
KW  - computer security
KW  - ethics
KW  - Europe
KW  - legislation and jurisprudence
KW  - medical error
KW  - medical ethics
KW  - robotic surgical procedure
KW  - United States
KW  - Robotic surgery
PB  - John Wiley and Sons Ltd
SN  - 14785951 (ISSN)
C2  - 30397993
LA  - English
J2  - Int. J. Med. Rob. Comput. Assisted Surg.
M3  - Review
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 252; Correspondence Address: S. O'Sullivan; Department of Pathology, Faculdade de Medicina, Universidade de São Paulo, São Paulo, Brazil; email: doctorshaneosullivan@gmail.com
ER  -

TY  - JOUR
AU  - Upadhyay, N.K.
AU  - Jiang, H.
AU  - Wang, Z.
AU  - Asapu, S.
AU  - Xia, Q.
AU  - Joshua Yang, J.
TI  - Emerging Memory Devices for Neuromorphic Computing
PY  - 2019
T2  - Advanced Materials Technologies
VL  - 4
IS  - 4
C7  - 1800589
DO  - 10.1002/admt.201800589
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059662820&doi=10.1002%2fadmt.201800589&partnerID=40&md5=201925d71bb22f76f67ff1316703053a
AD  - Department of Electrical and Computer Engineering, University of Massachusetts, Amherst, 01003, MA, United States
AB  - A neuromorphic computing system may be able to learn and perform a task on its own by interacting with its surroundings. Combining such a chip with complementary metal–oxide–semiconductor (CMOS)-based processors can potentially solve a variety of problems being faced by today's artificial intelligence (AI) systems. Although various architectures purely based on CMOS are designed to maximize the computing efficiency of AI-based applications, the most fundamental operations including matrix multiplication and convolution heavily rely on the CMOS-based multiply–accumulate units which are ultimately limited by the von Neumann bottleneck. Fortunately, many emerging memory devices can naturally perform vector matrix multiplication directly utilizing Ohm's law and Kirchhoff's law when an array of such devices is employed in a cross-bar architecture. With certain dynamics, these devices can also be used either as synapses or neurons in a neuromorphic computing system. This paper discusses various emerging nanoscale electronic devices that can potentially reshape the computing paradigm in the near future. © 2019 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim
KW  - artificial synapses
KW  - emerging memory technologies
KW  - memristors
KW  - neuromorphic systems
KW  - synaptic transistors
KW  - CMOS integrated circuits
KW  - Electron devices
KW  - Memory architecture
KW  - Memristors
KW  - artificial synapses
KW  - Emerging memory technologies
KW  - Fundamental operations
KW  - MAtrix multiplication
KW  - Nanoscale electronic devices
KW  - Neuromorphic computing
KW  - Neuromorphic systems
KW  - Vector-matrix multiplications
KW  - Matrix algebra
PB  - Wiley-Blackwell
SN  - 2365709X (ISSN)
LA  - English
J2  - Adv.  Mater. Technol.
M3  - Review
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 354; Correspondence Address: J. Joshua Yang; Department of Electrical and Computer Engineering, University of Massachusetts, Amherst, 01003, United States; email: jjyang@umass.edu
ER  -

TY  - CONF
AU  - Gade, K.
AU  - Geyik, S.C.
AU  - Kenthapadi, K.
AU  - Mithal, V.
AU  - Taly, A.
TI  - Explainable AI in industry
PY  - 2019
T2  - Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining
SP  - 3203
EP  - 3204
DO  - 10.1145/3292500.3332281
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071169118&doi=10.1145%2f3292500.3332281&partnerID=40&md5=5d18b8ba6c38975577344b992a4bae14
AD  - Fiddler Labs
AD  - LinkedIn
AB  - Artificial Intelligence is increasingly playing an integral role in determining our day-to-day experiences. Moreover, with proliferation of AI based solutions in areas such as hiring, lending, criminal justice, healthcare, and education, the resulting personal and professional implications of AI are far-reaching. The dominant role played by AI models in these domains has led to a growing concern regarding potential bias in these models, and a demand for model transparency and interpretability [6]. In addition, model explainability is a prerequisite for building trust and adoption of AI systems in high stakes domains requiring reliability and safety such as healthcare [1] and automated transportation, and critical industrial applications with significant economic implications such as predictive maintenance, exploration of natural resources, and climate change modeling. As a consequence, AI researchers and practitioners have focused their attention on explainable AI to help them better trust and understand models at scale [8, 9, 19]. The challenges for the research community include (i) defining model explainability, (ii) formulating explainability tasks for understanding model behavior and developing solutions for these tasks, and finally (iii) designing measures for evaluating the performance of models in explainability tasks. In this tutorial, we will present an overview of model interpretability and explainability in AI [4], key regulations/laws, and techniques/tools for providing explainability as part of AI/ML systems [7]. Then, we will focus on the application of explainability techniques in industry, wherein we present practical challenges/ guidelines for using explainability techniques effectively and lessons learned from deploying explainable models for several web-scale machine learning and data mining applications. We will present case studies across different companies, spanning application domains such as search and recommendation systems, sales, lending, and fraud detection. Finally, based on our experiences in industry, we will identify open problems and research directions for the data mining/machine learning community. © 2019 Copyright held by the owner/author(s).
KW  - Accident prevention
KW  - Artificial intelligence
KW  - Climate change
KW  - Climate models
KW  - Crime
KW  - Health care
KW  - Natural resources exploration
KW  - Climate change modeling
KW  - Data mining applications
KW  - Developing solutions
KW  - Economic implications
KW  - Model transparency
KW  - Predictive maintenance
KW  - Reliability and safeties
KW  - Research communities
KW  - Data mining
PB  - Association for Computing Machinery
SN  - 978-145036201-6 (ISBN)
LA  - English
J2  - Proc. ACM SIGKDD Int. Conf. Knowl. Discov. Data Min.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 119; Conference name: 25th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD 2019; Conference date: 4 August 2019 through 8 August 2019; Conference code: 149966
ER  -

TY  - JOUR
AU  - Schönberger, D.
TI  - Artificial intelligence in healthcare: A critical analysis of the legal and ethical implications
PY  - 2019
T2  - International Journal of Law and Information Technology
VL  - 27
IS  - 2
C7  - eaz004
SP  - 171
EP  - 203
DO  - 10.1093/ijlit/eaz004
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070278372&doi=10.1093%2fijlit%2feaz004&partnerID=40&md5=826499daedb9a931326256f6920b8dfc
AD  - Department of Law, Department of Medical Law and Ethics, Edinburgh, United Kingdom
AB  - Artificial intelligence (AI) is perceived as the most transformative technology of the 21st century. Healthcare has been identified as an early candidate to be revolutionized by AI technologies. Various clinical and patient-facing applications have already reached healthcare practice with the potential to ease the pressure on healthcare staff, bring down costs and ultimately improve the lives of patients. However, various concerns have been raised as regards the unique properties and risks inherent to AI technologies. This article aims at providing an early stage contribution with a holistic view on the 'decision-making' capacities of AI technologies. The possible ethical and legal ramifications will be discussed against the backdrop of the existing frameworks. I will conclude that the present structures are largely fit to deal with the challenges AI technologies are posing. In some areas, sector-specific revisions of the law may be advisable, particularly concerning non-discrimination and product liability. © 2019 The Author(s). Published by Oxford University Press. All rights reserved.
KW  - accountability
KW  - Artificial intelligence
KW  - autonomy
KW  - data protection
KW  - fairness
KW  - liability
KW  - medical law and ethics
KW  - negligence
KW  - product liability
PB  - Oxford University Press
SN  - 09670769 (ISSN)
LA  - English
J2  - Int. J. Law Inf. Technol.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 151; Correspondence Address: D. Schönberger; Department of Law, Department of Medical Law and Ethics, Edinburgh, United Kingdom; email: daniel.m.schoenberger@gmail.com
ER  -

TY  - JOUR
AU  - Winfield, A.F.
AU  - Michael, K.
AU  - Pitt, J.
AU  - Evers, V.
TI  - Machine ethics: The design and governance of ethical ai and autonomous systems
PY  - 2019
T2  - Proceedings of the IEEE
VL  - 107
IS  - 3
C7  - 8662743
SP  - 509
EP  - 517
DO  - 10.1109/JPROC.2019.2900622
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062611190&doi=10.1109%2fJPROC.2019.2900622&partnerID=40&md5=ca8044fa9e5d6271874db596700afc73
AB  - The so-called fourth industrial revolution and its economic and societal implications are no longer solely an academic concern, but a matter for political as well as public debate. Characterized as the convergence of robotics, AI, autonomous systems and information technology - or cyberphysical systems - the fourth industrial revolution was the focus of the World Economic Forum, at Davos, in 2016 [1]. Also in 2016 the US White House initiated a series of public workshops on artificial intelligence (AI) and the creation of an interagency working group, and the European Parliament Committee for Legal Affairs published a draft report with recommendations to the Commission on Civil Law Rules on Robotics. © 1963-2012 IEEE.
KW  - Embedded systems
KW  - Industry 4.0
KW  - Philosophical aspects
KW  - Robotics
KW  - Autonomous systems
KW  - Cyber physical systems (CPSs)
KW  - European Parliament
KW  - Industrial revolutions
KW  - Public debate
KW  - Societal implications
KW  - White House
KW  - Working groups
KW  - Industrial economics
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 00189219 (ISSN)
LA  - English
J2  - Proc. IEEE
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 132; CODEN: IEEPA
ER  -

TY  - JOUR
AU  - Kitto, K.
AU  - Knight, S.
TI  - Practical ethics for building learning analytics
PY  - 2019
T2  - British Journal of Educational Technology
VL  - 50
IS  - 6
SP  - 2855
EP  - 2870
DO  - 10.1111/bjet.12868
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068639691&doi=10.1111%2fbjet.12868&partnerID=40&md5=f40125bc14540c19516ccc44b898b498
AD  - Connected Intelligence Centre, Australia
AD  - Faculty of Transdisciplinary Innovation, Australia
AB  - Artificial intelligence and data analysis (AIDA) are increasingly entering the field of education. Within this context, the subfield of learning analytics (LA) has, since its inception, had a strong emphasis upon ethics, with numerous checklists and frameworks proposed to ensure that student privacy is respected and potential harms avoided. Here, we draw attention to some of the assumptions that underlie previous work in ethics for LA, which we frame as three tensions. These assumptions have the potential of leading to both the overcautious underuse of AIDA as administrators seek to avoid risk, or the unbridled misuse of AIDA as practitioners fail to adhere to frameworks that provide them with little guidance upon the problems that they face in building LA for institutional adoption. We use three edge cases to draw attention to these tensions, highlighting places where existing ethical frameworks fail to inform those building LA solutions. We propose a pilot open database that lists edge cases faced by LA system builders as a method for guiding ethicists working in the field towards places where support is needed to inform their practice. This would provide a middle space where technical builders of systems could more deeply interface with those concerned with policy, law and ethics and so work towards building LA that encourages human flourishing across a lifetime of learning. Practitioner Notes What is already known about this topic Applied ethics has a number of well-established theoretical groundings that we can use to frame the actions of ethical agents, including, deontology, consequentialism and virtue ethics. Learning analytics has developed a number of checklists, frameworks and evaluation methodologies for supporting trusted and ethical development, but these are often not adhered to by practitioners. Laws like the General Data Protection Regulation (GDPR) apply to fields like education, but the complexity of this field can make them difficult to apply. What this paper adds Evidence of tensions and gaps in existing ethical frameworks and checklists to support the ethical development and implementation of learning analytics. A set of three edge cases that demonstrate places where existing work on the ethics of AI in education has failed to provide guidance. A “practical ethics” conceptualisation that draws on virtue ethics to support practitioners in building learning analytics systems. Implications for practice and/or policy Those using AIDA in education should collect and share example edge cases to support development of practical ethics in the field. A multiplicity of ethical approaches are likely to be useful in understanding how to develop and implement learning analytics ethically in practical contexts. © 2019 British Educational Research Association
KW  - Buildings
KW  - Learning systems
KW  - Risk perception
KW  - Analytics systems
KW  - Evaluation methodologies
KW  - General data protection regulations
KW  - In-buildings
KW  - Potential harm
KW  - Provide guidances
KW  - System builders
KW  - Virtue ethics
KW  - Philosophical aspects
PB  - Blackwell Publishing Ltd
SN  - 00071013 (ISSN)
LA  - English
J2  - Br J Educ Technol
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 90; Correspondence Address: K. Kitto; Connected Intelligence Centre, Australia; email: kirsty.kitto@uts.edu.au; CODEN: BJETD
ER  -

TY  - JOUR
AU  - Deeks, A.
TI  - The judicial demand for explainable artificial intelligence
PY  - 2019
T2  - Columbia Law Review
VL  - 119
IS  - 7
SP  - 1829
EP  - 1850
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076224290&partnerID=40&md5=1dc77e2f2b6bdacf279198dce2e4b8b7
AB  - A recurrent concern about machine learning algorithms is that they operate as “black boxes,” making it difficult to identify how and why the algorithms reach particular decisions, recommendations, or predictions. Yet judges are confronting machine learning algorithms with increasing frequency, including in criminal, administrative, and civil cases. This Essay argues that judges should demand explanations for these algorithmic outcomes. One way to address the “black box” problem is to design systems that explain how the algorithms reach their conclusions or predictions. If and as judges demand these explanations, they will play a seminal role in shaping the nature and form of “explainable AI” (xAI). Using the tools of the common law, courts can develop what xAI should mean in different legal contexts. There are advantages to having courts to play this role: Judicial reasoning that builds from the bottom up, using case-by-case consideration of the facts to produce nuanced decisions, is a pragmatic way to develop rules for xAI. Further, courts are likely to stimulate the production of different forms of xAI that are responsive to distinct legal settings and audiences. More generally, we should favor the greater involvement of public actors in shaping xAI, which to date has largely been left in private hands. © 2019, Columbia Law Review Association. All rights reserved.
KW  - Administrative law
KW  - Artificial intelligence
KW  - Common law
KW  - Criminal justice
KW  - Machine learning
KW  - Predictive algorithms
PB  - Columbia Law Review Association
SN  - 00101958 (ISSN)
LA  - English
J2  - Columbia Law Rev.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 126
ER  -

TY  - JOUR
AU  - Engin, Z.
AU  - Treleaven, P.
TI  - Algorithmic Government: Automating Public Services and Supporting Civil Servants in using Data Science Technologies
PY  - 2019
T2  - Computer Journal
VL  - 62
IS  - 3
SP  - 448
EP  - 460
DO  - 10.1093/comjnl/bxy082
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062667080&doi=10.1093%2fcomjnl%2fbxy082&partnerID=40&md5=c3cec170e72259dae229830a44820749
AD  - Department of Computer Science, University College London, London, United Kingdom
AB  - The data science technologies of artificial intelligence (AI), Internet of Things (IoT), big data and behavioral/predictive analytics, and blockchain are poised to revolutionize government and create a new generation of GovTech start-ups. The impact from the â€ smartification' of public services and the national infrastructure will be much more significant in comparison to any other sector given government's function and importance to every institution and individual. Potential GovTech systems include Chatbots and intelligent assistants for public engagement, Robo-advisors to support civil servants, real-time management of the national infrastructure using IoT and blockchain, automated compliance/regulation, public records securely stored in blockchain distributed ledgers, online judicial and dispute resolution systems, and laws/statutes encoded as blockchain smart contracts. Government is potentially the major â€ client' and also â€ public champion' for these new data technologies. This review paper uses our simple taxonomy of government services to provide an overview of data science automation being deployed by governments world-wide. The goal of this review paper is to encourage the Computer Science community to engage with government to develop these new systems to transform public services and support the work of civil servants. © 2017 The British Computer Society. All rights reserved.
KW  - artificial intelligence
KW  - big data
KW  - blockchain
KW  - data science
KW  - government
KW  - Internet of Things
KW  - Artificial intelligence
KW  - Big data
KW  - Blockchain
KW  - Data Science
KW  - Online systems
KW  - Real time systems
KW  - Regulatory compliance
KW  - Dispute resolution
KW  - government
KW  - Government services
KW  - Intelligent assistants
KW  - Internet of Things (IOT)
KW  - National infrastructure
KW  - Real-time management
KW  - Science technologies
KW  - Internet of things
PB  - Oxford University Press
SN  - 00104620 (ISSN)
LA  - English
J2  - Comput J
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 154; Correspondence Address: Z. Engin; Department of Computer Science, University College London, London, United Kingdom; email: z.engin@ucl.ac.uk; CODEN: CMPJA
ER  -

TY  - CONF
AU  - Buiten, M.C.
TI  - Towards intelligent regulation of artificial intelligence
PY  - 2019
T2  - European Journal of Risk Regulation
VL  - 10
IS  - 1
SP  - 41
EP  - 59
DO  - 10.1017/err.2019.8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066085211&doi=10.1017%2ferr.2019.8&partnerID=40&md5=6fc3c1ad33cd04fabebf37a9df738cbc
AD  - McGill Faculty of Law Cipp, Germany
AB  - Artificial intelligence (AI) is becoming a part of our daily lives at a fast pace, offering myriad benefits for society. At the same time, there is concern about the unpredictability and uncontrollability of AI. In response, legislators and scholars call for more transparency and explainability of AI. This article considers what it would mean to require transparency of AI. It advocates looking beyond the opaque concept of AI, focusing on the concrete risks and biases of its underlying technology: Machine-learning algorithms. The article discusses the biases that algorithms may produce through the input data, the testing of the algorithm and the decision model. Any transparency requirement for algorithms should result in explanations of these biases that are both understandable for the prospective recipients, and technically feasible for producers. Before asking how much transparency the law should require from algorithms, we should therefore consider if the explanation that programmers could offer is useful in specific legal contexts. © 2019 Cambridge University Press.
PB  - Cambridge University Press
SN  - 1867299X (ISSN)
LA  - English
J2  - Eur. J. Risk Regul.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 122; Correspondence Address: M.C. Buiten; McGill Faculty of Law Cipp, Germany; email: buiten@uni-mannheim.de
ER  -

