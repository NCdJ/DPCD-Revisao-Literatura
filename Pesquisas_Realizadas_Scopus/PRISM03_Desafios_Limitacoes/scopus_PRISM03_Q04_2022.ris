TY  - JOUR
AU  - Liu, Y.
AU  - Liu, Y.
AU  - Liu, Z.
AU  - Liang, Y.
AU  - Meng, C.
AU  - Zhang, J.
AU  - Zheng, Y.
TI  - Federated Forest
PY  - 2022
T2  - IEEE Transactions on Big Data
VL  - 8
IS  - 3
SP  - 843
EP  - 854
DO  - 10.1109/TBDATA.2020.2992755
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089758492&doi=10.1109%2fTBDATA.2020.2992755&partnerID=40&md5=ddc3c22b7618ceb921035c9ef44706fd
AD  - Jd Intelligent Cities Business Unit, Jd Digits, Beijing, China
AD  - Jd Intelligent Cities Research, Beijing, 100176, China
AD  - Institute of Artificial Intelligence, Southwest Jiaotong University, Chengdu, Sichuan, 610031, China
AD  - Xidian University, Shaanxi, Xi'an, 710071, China
AD  - University of Science and Technology of China, Anhui, Hefei, 230027, China
AD  - Beijing Normal University, Beijing, 100875, China
AD  - School of Computing, National University of Singapore, Singapore, 119077, Singapore
AB  - Most real-world data are scattered across different companies or government organizations, and cannot be easily integrated under data privacy and related regulations such as the European Union's General Data Protection Regulation (GDPR) and China' Cyber Security Law. Such data islands situation and data privacy & security are two major challenges for applications of artificial intelligence. In this article, we tackle these challenges and propose a privacy-preserving machine learning model, called Federated Forest, which is a lossless learning model of the traditional random forest method, i.e., achieving the same level of accuracy as the non-privacy-preserving approach. Based on it, we developed a secure cross-regional machine learning system that allows a learning process to be jointly trained over different regions' clients with the same user samples but different attribute sets, processing the data stored in each of them without exchanging their raw data. A novel prediction algorithm was also proposed which could largely reduce the communication overhead. Experiments on both real-world and UCI data sets demonstrate the performance of the Federated Forest is as accurate as of the non-federated version. The efficiency and robustness of our proposed system had been verified. Overall, our model is practical, scalable and extensible for real-life tasks.  © 2015 IEEE.
KW  - data mining
KW  - Machine learning
KW  - Cybersecurity
KW  - Data structures
KW  - Decision trees
KW  - Laws and legislation
KW  - Privacy-preserving techniques
KW  - Cyber security
KW  - European union
KW  - General data protection regulations
KW  - Government organizations
KW  - Learning models
KW  - Lossless
KW  - Machine learning models
KW  - Machine-learning
KW  - Privacy preserving
KW  - Real-world
KW  - Machine learning
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 23327790 (ISSN)
LA  - English
J2  - IEEE Trans. Big Data
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 61
ER  -

TY  - JOUR
AU  - Liu, J.
AU  - Wang, H.
TI  - Machine learning assisted modeling of mixing timescale for LES/PDF of high-Karlovitz turbulent premixed combustion
PY  - 2022
T2  - Combustion and Flame
VL  - 238
C7  - 111895
DO  - 10.1016/j.combustflame.2021.111895
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120851771&doi=10.1016%2fj.combustflame.2021.111895&partnerID=40&md5=7812f8460b5898b681b2a11ddd6a12da
AD  - School of Aeronautics and Astronautics, Purdue University, West Lafayette, 47907, IN, United States
AB  - Accurate modeling of mixing in the transported probability density function (PDF) method remains a great challenge, especially for turbulent premixed combustion under extreme conditions such as high Karlovitz number Ka. Recently, a power-law based mixing timescale model was developed (Zhang et al., Proceedings of the Combustion Institute, 2021, 38(2): 2917–2927) for the large-eddy simulations (LES)/PDF modeling of high-Ka number turbulent premixed flames. It is found in this work that the power-law mixing timescale model is highly sensitive to the model parameters. It is thus critically needed to develop accurate calibration of these model parameters. The empirical specification of the model parameters developed in Zhang et al. is found to be inadequate for accurate modeling of the mixing timescale. Machine learning is introduced as an attractive alternative in this work for the specification of the model parameters. A high-Ka number DNS jet flame is used as the training and validation of the machine learning models. The choices of the input parameters are discussed and compared for the machine learning models. The effect of differential molecular diffusion on mixing is examined by including the effect of the Lewis number in the training of the machine learning models. The performance of different machine learning algorithms is compared for the specification of the mixing model parameters. Overall, excellent performance of the machine learning models is observed for assisting the mixing modeling. The feasibility, interpretability, applicability, generality, and portability of using machine learning are discussed in general to provide a perspective on applying data-driven machine learning for turbulent combustion modeling studies. © 2021 The Combustion Institute
KW  - Large-eddy simulations
KW  - Machine learning
KW  - Mixing process
KW  - Power-law mixing timescale model
KW  - Transported PDF method
KW  - Combustion
KW  - Learning algorithms
KW  - Machine learning
KW  - Mixing
KW  - Probability density function
KW  - Specifications
KW  - Large-eddy simulations
KW  - Machine learning models
KW  - Machine-learning
KW  - Mixing process
KW  - Modeling parameters
KW  - Power-law
KW  - Power-law mixing timescale model
KW  - Probability density function method
KW  - Time-scales
KW  - Transported probability density function method
KW  - article
KW  - calibration
KW  - combustion
KW  - controlled study
KW  - density
KW  - diffusion
KW  - flame
KW  - learning algorithm
KW  - machine learning
KW  - pharmaceutics
KW  - probability
KW  - simulation
KW  - Large eddy simulation
PB  - Elsevier Inc.
SN  - 00102180 (ISSN)
LA  - English
J2  - Combust. Flame
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 62; Correspondence Address: H. Wang; School of Aeronautics and Astronautics, Purdue University, West Lafayette, 47907, United States; email: haifeng@purdue.edu; CODEN: CBFMA
ER  -

TY  - JOUR
AU  - Chu, C.H.
AU  - Nyrup, R.
AU  - Leslie, K.
AU  - Shi, J.
AU  - Bianchi, A.
AU  - Lyn, A.
AU  - McNicholl, M.
AU  - Khan, S.
AU  - Rahimi, S.
AU  - Grenier, A.
TI  - Digital Ageism: Challenges and Opportunities in Artificial Intelligence for Older Adults
PY  - 2022
T2  - Gerontologist
VL  - 62
IS  - 7
SP  - 947
EP  - 955
DO  - 10.1093/geront/gnab167
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129235014&doi=10.1093%2fgeront%2fgnab167&partnerID=40&md5=0425f26cc7529ab3de8a4a10c5ae82d2
AD  - Lawrence S. Bloomberg Faculty of Nursing, University of Toronto, Toronto, ON, Canada
AD  - Kite - Toronto Rehabilitation Institute, University Health Network, Toronto, ON, Canada
AD  - Leverhulme Centre for the Future of Intelligence, University of Cambridge, Cambridge, United Kingdom
AD  - Faculty of Health Disciplines, Athabasca University, Athabasca, AB, Canada
AD  - Dalla Lana School of Public Health, University of Toronto, Toronto, ON, Canada
AD  - University Health Network, Toronto, ON, Canada
AD  - University of Cambridge, Cambridge, United Kingdom
AD  - London School of Hygiene and Tropical Medicine, University of London, London, United Kingdom
AD  - Institute of Biomedical Engineering, University of Toronto, Toronto, ON, Canada
AD  - Department of Family Medicine, McGill University, Montreal, QC, Canada
AD  - Mila - Quebec Ai Institute, Montréal, QC, Canada
AD  - Factor-Inwentash Faculty of Social Work, University of Toronto, Toronto, ON, Canada
AD  - Baycrest Hospital, Toronto, ON, Canada
AB  - Artificial intelligence (AI) and machine learning are changing our world through their impact on sectors including health care, education, employment, finance, and law. AI systems are developed using data that reflect the implicit and explicit biases of society, and there are significant concerns about how the predictive models in AI systems amplify inequity, privilege, and power in society. The widespread applications of AI have led to mainstream discourse about how AI systems are perpetuating racism, sexism, and classism; yet, concerns about ageism have been largely absent in the AI bias literature. Given the globally aging population and proliferation of AI, there is a need to critically examine the presence of age-related bias in AI systems. This forum article discusses ageism in AI systems and introduces a conceptual model that outlines intersecting pathways of technology development that can produce and reinforce digital ageism in AI systems. We also describe the broader ethical and legal implications and considerations for future directions in digital ageism research to advance knowledge in the field and deepen our understanding of how ageism in AI is fostered by broader cycles of injustice. © 2022 The Author(s). Published by Oxford University Press on behalf of The Gerontological Society of America.
KW  - Bias
KW  - Gerontology
KW  - Machine learning
KW  - Technology
KW  - Aged
KW  - Ageism
KW  - Artificial Intelligence
KW  - Delivery of Health Care
KW  - Humans
KW  - Machine Learning
KW  - Racism
KW  - aged
KW  - ageism
KW  - aging
KW  - artificial intelligence
KW  - cell proliferation
KW  - conceptual model
KW  - female
KW  - gerontology
KW  - human
KW  - human experiment
KW  - machine learning
KW  - male
KW  - review
KW  - artificial intelligence
KW  - health care delivery
KW  - machine learning
KW  - racism
PB  - Gerontological Society of America
SN  - 00169013 (ISSN)
C2  - 35048111
LA  - English
J2  - Gerontologist
M3  - Review
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 80; Correspondence Address: C.H. Chu; Lawrence S. Bloomberg Faculty of Nursing, University of Toronto, Health Sciences Building, Toronto, 155 College Street, M5T 1P8, Canada; email: Charlene.chu@utoronto.ca; CODEN: GRNTA
ER  -

TY  - JOUR
AU  - Guo, S.
AU  - Agarwal, M.
AU  - Cooper, C.
AU  - Tian, Q.
AU  - Gao, R.X.
AU  - Guo, W.G.
AU  - Guo, Y.B.
TI  - Machine learning for metal additive manufacturing: Towards a physics-informed data-driven paradigm
PY  - 2022
T2  - Journal of Manufacturing Systems
VL  - 62
SP  - 145
EP  - 163
DO  - 10.1016/j.jmsy.2021.11.003
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120355687&doi=10.1016%2fj.jmsy.2021.11.003&partnerID=40&md5=4d6e6eec3cc983619fc02ab090040861
AD  - The School of Manufacturing Systems and Networks, Arizona State University, Mesa, 85212, AZ, United States
AD  - Department of Mechanical and Aerospace Engineering, Rutgers University-New Brunswick, Piscataway, 08854, NJ, United States
AD  - Department of Mechanical and Aerospace Engineering, Case Western Reserve University, Cleveland, 44106, OH, United States
AD  - The State Key Laboratory of Coastal and Offshore Engineering, Dalian University of Technology, Dalian, 116024, China
AD  - Department of Industrial and Systems Engineering, Rutgers University-New Brunswick, Piscataway, 08854, NJ, United States
AD  - New Jersey Advanced Manufacturing Institute, Rutgers University-New Brunswick, Piscataway, 08854, NJ, United States
AB  - Machine learning (ML) has shown to be an effective alternative to physical models for quality prediction and process optimization of metal additive manufacturing (AM). However, the inherent “black box” nature of ML techniques such as those represented by artificial neural networks has often presented a challenge to interpret ML outcomes in the framework of the complex thermodynamics that govern AM. While the practical benefits of ML provide an adequate justification, its utility as a reliable modeling tool is ultimately reliant on assured consistency with physical principles and model transparency. To facilitate the fundamental needs, physics-informed machine learning (PIML) has emerged as a hybrid machine learning paradigm that imbues ML models with physical domain knowledge such as thermomechanical laws and constraints. The distinguishing feature of PIML is the synergistic integration of data-driven methods that reflect system dynamics in real-time with the governing physics underlying AM. In this paper, the current state-of-the-art in metal AM is reviewed and opportunities for a paradigm shift to PIML are discussed, thereby identifying relevant future research directions. © 2021 The Society of Manufacturing Engineers
KW  - Additive manufacturing
KW  - Deep learning
KW  - Machine learning
KW  - Physics of manufacturing processes
KW  - Additives
KW  - Deep learning
KW  - Domain Knowledge
KW  - Neural networks
KW  - Optimization
KW  - Thermodynamics
KW  - Black boxes
KW  - Data driven
KW  - Deep learning
KW  - Machine learning techniques
KW  - Manufacturing process
KW  - Physic of manufacturing process
KW  - Physical modelling
KW  - Process optimisation
KW  - Quality prediction
KW  - Quality process
KW  - 3D printers
PB  - Elsevier B.V.
SN  - 02786125 (ISSN)
LA  - English
J2  - J Manuf Syst
M3  - Review
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 136; Correspondence Address: W.G. Guo; Department of Industrial and Systems Engineering, Rutgers University-New Brunswick, Piscataway, 08854, United States; email: wg152@soe.rutgers.edu; CODEN: JMSYE
ER  -

TY  - JOUR
AU  - Patel, R.G.
AU  - Manickam, I.
AU  - Trask, N.A.
AU  - Wood, M.A.
AU  - Lee, M.
AU  - Tomas, I.
AU  - Cyr, E.C.
TI  - Thermodynamically consistent physics-informed neural networks for hyperbolic systems
PY  - 2022
T2  - Journal of Computational Physics
VL  - 449
C7  - 110754
DO  - 10.1016/j.jcp.2021.110754
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118745634&doi=10.1016%2fj.jcp.2021.110754&partnerID=40&md5=1401af9a5b8d80c9909308b29362ac5f
AD  - Sandia National Laboratories, Computational Mathematics Department, United States
AD  - Sandia National Laboratories, Computational Multiscale Department, United States
AD  - Sandia National Laboratories, Combustion Research Facility, United States
AD  - Sandia National Laboratories, Mission Algorithms Research & Solutions, United States
AB  - Physics-informed neural network architectures have emerged as a powerful tool for developing flexible PDE solvers that easily assimilate data. When applied to problems in shock physics however, these approaches face challenges related to the collocation-based PDE discretization underpinning them. By instead adopting a least squares space-time control volume scheme, we obtain a scheme which more naturally handles: regularity requirements, imposition of boundary conditions, entropy compatibility, and conservation, substantially reducing requisite hyperparameters in the process. Additionally, connections to classical finite volume methods allows application of inductive biases toward entropy solutions and total variation diminishing properties. For inverse problems in shock hydrodynamics, we propose inductive biases for discovering thermodynamically consistent equations of state that guarantee hyperbolicity. This framework therefore provides a means of discovering continuum shock models from molecular simulations of rarefied gases and metals. The output of the learning process provides a data-driven equation of state which may be incorporated into traditional shock hydrodynamics codes. © 2021
KW  - Conservation laws
KW  - Equation of state
KW  - Inverse problems
KW  - Machine learning
KW  - Physics-informed neural networks
KW  - Shock hydrodynamics
KW  - Differential equations
KW  - Entropy
KW  - Equations of state
KW  - Finite volume method
KW  - Hydrodynamics
KW  - Machine learning
KW  - Network architecture
KW  - Neural networks
KW  - Conservation law
KW  - Equation-of-state
KW  - Hyperbolic system
KW  - Inductive bias
KW  - Machine-learning
KW  - Neural network architecture
KW  - Neural-networks
KW  - PDE solvers
KW  - Physic-informed neural network
KW  - Shock hydrodynamic
KW  - Inverse problems
PB  - Academic Press Inc.
SN  - 00219991 (ISSN)
LA  - English
J2  - J. Comput. Phys.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 78; Correspondence Address: N.A. Trask; Sandia National Laboratories, Computational Mathematics Department, United States; email: natrask@sandia.gov; CODEN: JCTPA
ER  -

TY  - JOUR
AU  - Guo, C.
AU  - Duan, X.
AU  - Fang, Z.
AU  - Zhao, Y.
AU  - Yang, T.
AU  - Wang, E.
AU  - Hou, X.
TI  - A new strategy for long-term complex oxidation of MAX phases: Database generation and oxidation kinetic model establishment with aid of machine learning
PY  - 2022
T2  - Acta Materialia
VL  - 241
C7  - 118378
DO  - 10.1016/j.actamat.2022.118378
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138818329&doi=10.1016%2fj.actamat.2022.118378&partnerID=40&md5=a26a34ec6dab72c813f00f8a1c630639
AD  - Beijing Advanced Innovation Center for Materials Genome Engineering, Collaborative Innovation Center of Steel Technology, University of Science and Technology Beijing, Beijing, 100083, China
AD  - AECC Beijing Institute of Aeronautical Materials, Beijing, 100095, China
AB  - Owing to competitive behavior between oxidation products, complex oxidation commonly exists for MAX phases applied at high temperatures. Two major challenges remain to explain the oxidation law, i.e., acquirement of comprehensive oxidation data and establishment of reliable kinetic model. In this work, the long short-term memory recurrent neural network (LSTM-RNN) model is adopted combining the thermogravimetric (TG) experiment to generate the comprehensive oxidation database of MAX phases. By exploring the working principles of machine learning (ML) algorithms, a novel approach of combining real physical picture (RPP) model and sure independence screening and sparsifying operator (SISSO) method is proposed. The obtained machine learning-based real physical picture (ML-RPP) model can accurately deal with the long-term complex oxidation of various MAX phases. This work will provide a useful guideline for the cognition of complex oxidation of other ceramics and alloys. © 2022 Acta Materialia Inc.
KW  - Complex oxidation
KW  - Machine learning
KW  - MAX phases
KW  - ML-RPP model
KW  - Complex networks
KW  - Kinetic parameters
KW  - Kinetic theory
KW  - Long short-term memory
KW  - Competitive behavior
KW  - Complex oxidation
KW  - Database generation
KW  - Machine learning-real physical picture model
KW  - Machine-learning
KW  - MAX-phase
KW  - Oxidation kinetics modelling
KW  - Oxidation products
KW  - Physical pictures
KW  - Oxidation
PB  - Acta Materialia Inc
SN  - 13596454 (ISSN)
LA  - English
J2  - Acta Mater
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 51; Correspondence Address: E. Wang; Beijing Advanced Innovation Center for Materials Genome Engineering, Collaborative Innovation Center of Steel Technology, University of Science and Technology Beijing, Beijing, 100083, China; email: wangenhui@ustb.edu.cn
ER  -

TY  - JOUR
AU  - Kraft, B.
AU  - Jung, M.
AU  - Körner, M.
AU  - Koirala, S.
AU  - Reichstein, M.
TI  - Towards hybrid modeling of the global hydrological cycle
PY  - 2022
T2  - Hydrology and Earth System Sciences
VL  - 26
IS  - 6
SP  - 1579
EP  - 1614
DO  - 10.5194/hess-26-1579-2022
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127418173&doi=10.5194%2fhess-26-1579-2022&partnerID=40&md5=c17d6d5048c9d8d4d08ad1f2886724e5
AD  - Department Of Biogeochemical Integration, Max Planck Institute For Biogeochemistry, Germany
AD  - Department Of Aerospace And Geodesy, Technical University Of Munich, Germany
AB  - State-of-the-art global hydrological models (GHMs) exhibit large uncertainties in hydrological simulations due to the complexity, diversity, and heterogeneity of the land surface and subsurface processes, as well as the scale dependency of these processes and associated parameters. Recent progress in machine learning, fueled by relevant Earth observation data streams, may help overcome these challenges. But machine learning methods are not bound by physical laws, and their interpretability is limited by design. In this study, we exemplify a hybrid approach to global hydrological modeling that exploits the data adaptivity of neural networks for representing uncertain processes within a model structure based on physical principles (e.g., mass conservation) that form the basis of GHMs. This combination of machine learning and physical knowledge can potentially lead to data-driven, yet physically consistent and partially interpretable hybrid models. The hybrid hydrological model (H2M), extended from , simulates the dynamics of snow, soil moisture, and groundwater storage globally at 1g spatial resolution and daily time step. Water fluxes are simulated by an embedded recurrent neural network. We trained the model simultaneously against observational products of terrestrial water storage variations (TWS), grid cell runoff (Q), evapotranspiration (ET), and snow water equivalent (SWE) with a multi-task learning approach. We find that the H2M is capable of reproducing key patterns of global water cycle components, with model performances being at least on par with four state-of-the-art GHMs which provide a necessary benchmark for H2M. The neural-network-learned hydrological responses of evapotranspiration and grid cell runoff to antecedent soil moisture states are qualitatively consistent with our understanding and theory. The simulated contributions of groundwater, soil moisture, and snowpack variability to TWS variations are plausible and within the ranges of traditional GHMs. H2M identifies a somewhat stronger role of soil moisture for TWS variations in transitional and tropical regions compared to GHMs. With the findings and analysis, we conclude that H2M provides a new data-driven perspective on modeling the global hydrological cycle and physical responses with machine-learned parameters that is consistent with and complementary to existing global modeling frameworks. The hybrid modeling approaches have a large potential to better leverage ever-increasing Earth observation data streams to advance our understandings of the Earth system and capabilities to monitor and model it. © 2022 Copernicus GmbH. All rights reserved.
KW  - Climate models
KW  - Digital storage
KW  - Evapotranspiration
KW  - Groundwater
KW  - Recurrent neural networks
KW  - Runoff
KW  - Snow
KW  - Water supply
KW  - Watersheds
KW  - Data driven
KW  - Data stream
KW  - Earth observation data
KW  - Grid cells
KW  - Hybrid model
KW  - Hydrological cycles
KW  - Neural-networks
KW  - State of the art
KW  - Terrestrial water storage
KW  - Water storage variation
KW  - artificial neural network
KW  - benchmarking
KW  - complexity
KW  - data interpretation
KW  - evapotranspiration
KW  - heterogeneity
KW  - hydrological cycle
KW  - hydrological modeling
KW  - parameterization
KW  - snow water equivalent
KW  - soil moisture
KW  - water storage
KW  - Soil moisture
PB  - Copernicus GmbH
SN  - 10275606 (ISSN)
LA  - English
J2  - Hydrol. Earth Syst. Sci.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 66; Correspondence Address: B. Kraft; Department Of Biogeochemical Integration, Max Planck Institute For Biogeochemistry, Germany; email: bkraft@bgc-jena.mpg.de
ER  -

TY  - JOUR
AU  - Devagiri, J.S.
AU  - Paheding, S.
AU  - Niyaz, Q.
AU  - Yang, X.
AU  - Smith, S.
TI  - Augmented Reality and Artificial Intelligence in industry: Trends, tools, and future challenges
PY  - 2022
T2  - Expert Systems with Applications
VL  - 207
C7  - 118002
DO  - 10.1016/j.eswa.2022.118002
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133939651&doi=10.1016%2fj.eswa.2022.118002&partnerID=40&md5=09822ad9b075050dd57e6e59de25fbc3
AD  - Department of Applied Computing, Michigan Technological University, 1400 Townsend Dr, Houghton, 49931, MI, United States
AD  - Department of Electrical and Computer Engineering, Purdue University Northwest, 2200 169th Street Hammond, Hammond, 46323, IN, United States
AD  - Department of Computer Science and Engineering, Fairfield University, 1073 North Benson Road, Fairfield, 06824, CT, United States
AD  - Department of Cognitive and Learning Sciences, Michigan Technological University, 1400 Townsend Dr, Houghton, 49931, MI, United States
AB  - Augmented Reality (AR) is an augmented depiction of reality formed by overlaying digital information on an image of objects being seen through a device. Artificial Intelligence (AI) techniques have experienced unprecedented growth and are being applied in various industries. The combination of AR and AI is the next prominent direction in upcoming years with many industries and academia recognizing the importance of their adoption. With the advancements in the silicone industry that push the boundaries of Moore's law, processors will be less expensive, more efficient, and power-optimized in the forthcoming years. This is a tremendous support and necessity for an AR boom, and with the help of AI, there is an excellent potential for smart industries to increase the production speed and workforce training along with improved manufacturing, error handling, assembly, and packaging. In this work, we provide a systematic review of recent advances, tools, techniques, and platforms of AI-empowered AR along with the challenges of using AI in AR applications. This paper will serve as a guideline for future research in the domain of AI-assisted AR in industrial applications. © 2022 Elsevier Ltd
KW  - Artificial Intelligence
KW  - Augmented Reality
KW  - Deep learning
KW  - Industrial applications
KW  - Machine learning
KW  - Deep learning
KW  - Industrial research
KW  - Learning systems
KW  - Silicones
KW  - Artificial intelligence techniques
KW  - Deep learning
KW  - Digital information
KW  - Future challenges
KW  - Industry trends
KW  - Machine-learning
KW  - Moore Law
KW  - Power
KW  - Production speed
KW  - Workforce training
KW  - Augmented reality
PB  - Elsevier Ltd
SN  - 09574174 (ISSN)
LA  - English
J2  - Expert Sys Appl
M3  - Review
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 89; Correspondence Address: S. Paheding; Department of Applied Computing, Michigan Technological University, Houghton, 1400 Townsend Dr, 49931, United States; email: spahedin@mtu.edu; CODEN: ESAPE
ER  -

TY  - JOUR
AU  - Fuhg, J.N.
AU  - Bouklas, N.
TI  - On physics-informed data-driven isotropic and anisotropic constitutive models through probabilistic machine learning and space-filling sampling
PY  - 2022
T2  - Computer Methods in Applied Mechanics and Engineering
VL  - 394
C7  - 114915
DO  - 10.1016/j.cma.2022.114915
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127824112&doi=10.1016%2fj.cma.2022.114915&partnerID=40&md5=7e9f2fa683fb0259e1fd1171dee611de
AD  - Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, 14853, NY, United States
AD  - Center for Applied Mathematics, Cornell University, Ithaca, 14853, NY, United States
AB  - Data-driven constitutive modeling is an emerging field in computational solid mechanics with the prospect of significantly relieving the computational costs of hierarchical computational methods. Additionally, this data-driven paradigm could enable a seamless connection of experimental data probing material responses with numerical simulations at the structural level. Traditionally, these surrogates have just been trained using datasets which map strain inputs to stress outputs for elastic and inelastic materials directly. Recently, artificial neural networks (ANNs) have instead been trained to additionally incorporate the underlying physical laws in the construction of these models. However, ANNs do not offer convergence guarantees from an engineering point of view and are majorly reliant on user-specified parameters. In contrast to ANNs, Gaussian process regression (GPR) is based on nonparametric modeling principles as well as on fundamental statistical knowledge and hence allows for strict convergence guarantees. Motivated by the recent work by Frankel et al. (2021) which is based on rewriting the stress output as a linear combination of an irreducible integrity basis, in this work we present a physics-informed and data-driven constitutive modeling approach for isotropic and anisotropic hyperelastic materials at finite strain. The trained surrogates are able to respect physical principles such as material frame indifference, material symmetry, thermodynamic consistency, stress-free undeformed configuration, and the local balance of angular momentum. Our approach is based on probabilistic machine learning and uniquely can be used in the big data context while maintaining the benefits of GPR. As sampling in the mixed invariant space poses a unique challenge, we additionally present the first sampling approach that directly generates space-filling points in the invariant space corresponding to a bounded domain of the deformation gradient tensor. The sampling technique is based on simulated annealing and provides more efficient and reliable physics-informed constitutive models. Overall, the presented approach is tested on synthetic data from isotropic and anisotropic constitutive laws and shows surprising accuracy even far beyond the limits of the training domain, indicating that the resulting surrogates can efficiently generalize as they incorporate knowledge about the underlying physics. © 2022 Elsevier B.V.
KW  - Data-driven constitutive models
KW  - Finite strain
KW  - Hyperelasticity
KW  - Physics-informed machine learning
KW  - Solid mechanics
KW  - Anisotropy
KW  - Elasticity
KW  - Machine learning
KW  - Neural networks
KW  - Simulated annealing
KW  - Data driven
KW  - Data-driven constitutive model
KW  - Finite strain
KW  - Gaussian process regression
KW  - Hyper-elasticity
KW  - Isotropics
KW  - Physic-informed machine learning
KW  - Probabilistics
KW  - Solid mechanics
KW  - Space filling
KW  - Constitutive models
PB  - Elsevier B.V.
SN  - 00457825 (ISSN)
LA  - English
J2  - Comput. Methods Appl. Mech. Eng.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 63; Correspondence Address: N. Bouklas; 153 Hoy Rd., Ithaca, 14853, United States; email: nbouklas@cornell.edu; CODEN: CMMEC
ER  -

TY  - JOUR
AU  - Gosselin, R.
AU  - Vieu, L.
AU  - Loukil, F.
AU  - Benoit, A.
TI  - Privacy and Security in Federated Learning: A Survey
PY  - 2022
T2  - Applied Sciences (Switzerland)
VL  - 12
IS  - 19
C7  - 9901
DO  - 10.3390/app12199901
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140000285&doi=10.3390%2fapp12199901&partnerID=40&md5=77977f52924b6a765e234e78ceb622cd
AD  - Polytech Annecy-Chambéry, Savoie Mont Blanc University, Annecy, F-74944, France
AD  - LISTIC, Savoie Mont Blanc University, Annecy, F-74944, France
AB  - In recent years, privacy concerns have become a serious issue for companies wishing to protect economic models and comply with end-user expectations. In the same vein, some countries now impose, by law, constraints on data use and protection. Such context thus encourages machine learning to evolve from a centralized data and computation approach to decentralized approaches. Specifically, Federated Learning (FL) has been recently developed as a solution to improve privacy, relying on local data to train local models, which collaborate to update a global model that improves generalization behaviors. However, by definition, no computer system is entirely safe. Security issues, such as data poisoning and adversarial attack, can introduce bias in the model predictions. In addition, it has recently been shown that the reconstruction of private raw data is still possible. This paper presents a comprehensive study concerning various privacy and security issues related to federated learning. Then, we identify the state-of-the-art approaches that aim to counteract these problems. Findings from our study confirm that the current major security threats are poisoning, backdoor, and Generative Adversarial Network (GAN)-based attacks, while inference-based attacks are the most critical to the privacy of FL. Finally, we identify ongoing research directions on the topic. This paper could be used as a reference to promote cybersecurity-related research on designing FL-based solutions for alleviating future challenges. © 2022 by the authors.
KW  - blockchain
KW  - deep learning
KW  - deep learning security and privacy threats
KW  - distributed learning
KW  - federated learning
KW  - machine learning
KW  - privacy
KW  - security
KW  - survey
PB  - MDPI
SN  - 20763417 (ISSN)
LA  - English
J2  - Appl. Sci.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 59; Correspondence Address: F. Loukil; LISTIC, Savoie Mont Blanc University, Annecy, F-74944, France; email: faiza.loukil@univ-smb.fr; A. Benoit; LISTIC, Savoie Mont Blanc University, Annecy, F-74944, France; email: alexandre.benoit@univ-smb.fr
ER  -

