TY  - JOUR
AU  - Gallifant, J.
AU  - Fiske, A.
AU  - Levites Strekalova, Y.A.
AU  - Osorio-Valencia, J.S.
AU  - Parke, R.
AU  - Mwavu, R.
AU  - Martinez, N.
AU  - Gichoya, J.W.
AU  - Ghassemi, M.
AU  - Demner-Fushman, D.
AU  - McCoy, L.G.
AU  - Celi, L.A.
AU  - Pierce, R.
TI  - Peer review of GPT-4 technical report and systems card
PY  - 2024
T2  - PLOS Digital Health
VL  - 3
IS  - 1 January
C7  - e0000417
DO  - 10.1371/journal.pdig.0000417
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187799539&doi=10.1371%2fjournal.pdig.0000417&partnerID=40&md5=dc82d204ebe70cc697274ceee3528e64
AD  - Department of Critical Care, Guy’s & St Thomas’ NHS Trust, London, United Kingdom
AD  - Massachusetts Institute of Technology, Laboratory for Computational Physiology, Cambridge, MA, United States
AD  - Institute of History and Ethics in Medicine, Department of Clinical Medicine, TUM School of Medicine and Health, Technical University of Munich, Munich, Germany
AD  - Department of Health Services Research, Management, and Policy, College of Public Health and Health Professions, University of Florida, Gainesville, FL, United States
AD  - A.I. and Innovation Committee, Colombian Radiology Association, Medellin, Colombia
AD  - ScienteLab, Bogota, Colombia
AD  - Be4tech, Medellin, Colombia
AD  - Cardiothoracic and Vascular Intensive Care Unit, Auckland City Hospital, Auckland, New Zealand
AD  - School of Nursing, The University of Auckland, Auckland, New Zealand
AD  - Faculty of Computing and Informatics, Mbarara University of Science and Technology, Mbarara, Uganda
AD  - Center for Biomedical Ethics, Stanford University, Stanford, CA, United States
AD  - Department of Radiology, Emory University School of Medicine, Atlanta, GA, United States
AD  - Massachusetts Institute of Technology, Electrical Engineering and Computer Science (EECS), Cambridge, MA, United States
AD  - National Library of Medicine, NIH, HHS, Bethesda, MD, United States
AD  - Faculty of Medicine and Dentistry, University of Alberta, Edmonton, AB, Canada
AD  - Division of Pulmonary, Critical Care, and Sleep Medicine, Beth Israel Deaconess Medical Center, Boston, MA, United States
AD  - Department of Biostatistics, Harvard T.H. Chan School of Public Health, Boston, MA, United States
AD  - The Law School, Faculty of Humanities, Arts, and Social Sciences, University of Exeter, Exeter, United Kingdom
AB  - The study provides a comprehensive review of OpenAI’s Generative Pre-trained Transformer 4 (GPT-4) technical report, with an emphasis on applications in high-risk settings like healthcare. A diverse team, including experts in artificial intelligence (AI), natural language processing, public health, law, policy, social science, healthcare research, and bioethics, analyzed the report against established peer review guidelines. The GPT-4 report shows a significant commitment to transparent AI research, particularly in creating a systems card for risk assessment and mitigation. However, it reveals limitations such as restricted access to training data, inadequate confidence and uncertainty estimations, and concerns over privacy and intellectual property rights. Key strengths identified include the considerable time and economic investment in transparent AI research and the creation of a comprehensive systems card. On the other hand, the lack of clarity in training processes and data raises concerns about encoded biases and interests in GPT-4. The report also lacks confidence and uncertainty estimations, crucial in high-risk areas like healthcare, and fails to address potential privacy and intellectual property issues. Furthermore, this study emphasizes the need for diverse, global involvement in developing and evaluating large language models (LLMs) to ensure broad societal benefits and mitigate risks. The paper presents recommendations such as improving data transparency, developing accountability frameworks, establishing confidence standards for LLM outputs in high-risk settings, and enhancing industry research review processes. It concludes that while GPT-4’s report is a step towards open discussions on LLMs, more extensive interdisciplinary reviews are essential for addressing bias, harm, and risk concerns, especially in high-risk domains. The review aims to expand the understanding of LLMs in general and highlights the need for new reflection forms on how LLMs are reviewed, the data required for effective evaluation, and addressing critical issues like bias and risk. © 2024 Gallifant et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.
PB  - Public Library of Science
SN  - 27673170 (ISSN)
LA  - English
J2  - PLOS Digit. Health
M3  - Review
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 18; Correspondence Address: J. Gallifant; Department of Critical Care, Guy’s & St Thomas’ NHS Trust, London, United Kingdom; email: jgally@mit.edu
ER  -

TY  - JOUR
AU  - Moneus, A.M.
AU  - Sahari, Y.
TI  - Artificial intelligence and human translation: A contrastive study based on legal texts
PY  - 2024
T2  - Heliyon
VL  - 10
IS  - 6
C7  - e28106
DO  - 10.1016/j.heliyon.2024.e28106
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188067362&doi=10.1016%2fj.heliyon.2024.e28106&partnerID=40&md5=cb8a1cb6d725198e618ba25389438478
AD  - Sana'a University, Yemen
AD  - University of Bisha, Saudi Arabia
AB  - Artificial intelligence has advanced significantly in recent years, affecting multiple aspects of life. In particular, this has had an impact on the machine translation of texts, reducing or removing human interaction. Artificial intelligence (AI)-based translation software models have thus become widely available, and these now include Google Translate, Bing, Microsoft Translator, DeepL, Reverso, Systran Translate, and Amazon Translate. Several computer-aided translation (CAT) tools such as Memoq, Trados, Smartcat, Lokalise, Smartling, Crowdin, TextUnited, and Memsource are also available. More recently, artificial intelligence has been applied in the development of applications such as ChatGPT, ChatSonic, GPT-3 Playground, Chat GPT 4 and YouChat, which simulate conversational responses to researchers' inquiries, mimicking human interactions more directly. This study thus aimed to examine any remaining contrasts between human and AI translation in the legal field to investigate the potential hypothesis that there is now no difference between human and AI translation. The paper thus also examined concerns about whether the need for human translators will decline in the face of AI development, as well as beginning to assess whether it will ever be possible for those in the legal field to depend only on machine translation. To achieve this, a collection of legal texts from various contracts was chosen, and these pieces were both allocated to legal translators and subjected to AI translation systems. Using a contrastive methodology, the study thus examined the differences between AI and human translation, examining the strengths and weaknesses of both approaches and discussing the situations in which each approach might be most effective. © 2024 The Authors
KW  - Artificial intelligence
KW  - Human translation
KW  - Legal translation
KW  - Machine translation
KW  - Translation software
PB  - Elsevier Ltd
SN  - 24058440 (ISSN)
LA  - English
J2  - Heliyon
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 8; Correspondence Address: A.M. Moneus; Sana'a University, Yemen; email: moneus55@gmail.com
ER  -

TY  - JOUR
AU  - Bozkurt, A.
TI  - GenAI et al.: Cocreation, Authorship, Ownership, Academic Ethics and Integrity in a Time of Generative AI
PY  - 2024
T2  - Open Praxis
VL  - 16
IS  - 1
SP  - 1
EP  - 10
DO  - 10.55982/openpraxis.16.1.654
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188900975&doi=10.55982%2fopenpraxis.16.1.654&partnerID=40&md5=a9ea382cb38b1563b25aa0e0dc8cdc8e
AD  - Anadolu University, Turkey
AB  - This paper investigates the complex interplay between generative artificial intelligence (AI) and human intellect in academic writing and publishing. It examines the ‘organic versus synthetic’ paradox, emphasizing the implications of using generative AI tools in educational and academic integrity contexts. The paper critiques the prevalent ‘publish or perish’ culture in academia, highlighting the need for systemic reevaluation due to generative AI’s emerging role in academic writing and reporting. It delves into the legal and ethical challenges of authorship and ownership, especially in relation to copyright laws and AI-generated content. The paper discusses generative AI’s diverse roles and advocates for transparent reporting to uphold academic integrity. Additionally, it calls for a broader examination of generative AI tools and stresses the need for new mechanisms to identify generative AI use and ensure adherence to academic integrity and ethics. The implications of generative AI are also explored, suggesting the need for innovative AI-inclusive strategies in academia. The paper concludes by emphasizing the significance of generative AI in various information-processing domains, highlighting the urgency to adapt and transform academic practices in an era of rapid generative AI-driven change. © 2024 The Author(s).
KW  - academic integrity
KW  - academic writing
KW  - AI
KW  - AIEd
KW  - artificial intelligence
KW  - authorship
KW  - chatbots
KW  - ChatGPT
KW  - cocreating
KW  - collaboration
KW  - conversational agents
KW  - education
KW  - educational technology
KW  - ethics
KW  - GenAI
KW  - Generative AI
KW  - generative pre-trained transformer
KW  - GPT
KW  - higher education
KW  - large language models
KW  - learning
KW  - LLMs
KW  - natural language processing
KW  - ownership
KW  - teaching
KW  - transparency in research
PB  - International Council for Open and Distance Education
SN  - 13699997 (ISSN)
LA  - English
J2  - Open. Prax.
M3  - Editorial
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 17; Correspondence Address: A. Bozkurt; Anadolu University, Turkey; email: arasbozkurt@gmail.com
ER  -

TY  - JOUR
AU  - Wang, Z.
AU  - Chen, A.
AU  - Tao, K.
AU  - Han, Y.
AU  - Li, J.
TI  - MatGPT: A Vane of Materials Informatics from Past, Present, to Future
PY  - 2024
T2  - Advanced Materials
VL  - 36
IS  - 6
C7  - 2306733
DO  - 10.1002/adma.202306733
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178203067&doi=10.1002%2fadma.202306733&partnerID=40&md5=496aa6ff8f35a8d27c127750a652da32
AD  - National Key Laboratory of Science and Technology on Micro/Nano Fabrication, Shanghai Jiao Tong University, Shanghai, 200240, China
AD  - Key Laboratory of Thin Film and Microfabrication of Ministry of Education, Department of Micro/Nano Electronics, Shanghai Jiao Tong University, Shanghai, 200240, China
AB  - Combining materials science, artificial intelligence (AI), physical chemistry, and other disciplines, materials informatics is continuously accelerating the vigorous development of new materials. The emergence of “GPT (Generative Pre-trained Transformer) AI” shows that the scientific research field has entered the era of intelligent civilization with “data” as the basic factor and “algorithm + computing power” as the core productivity. The continuous innovation of AI will impact the cognitive laws and scientific methods, and reconstruct the knowledge and wisdom system. This leads to think more about materials informatics. Here, a comprehensive discussion of AI models and materials infrastructures is provided, and the advances in the discovery and design of new materials are reviewed. With the rise of new research paradigms triggered by “AI for Science”, the vane of materials informatics: “MatGPT”, is proposed and the technical path planning from the aspects of data, descriptors, generative models, pretraining models, directed design models, collaborative training, experimental robots, as well as the efforts and preparations needed to develop a new generation of materials informatics, is carried out. Finally, the challenges and constraints faced by materials informatics are discussed, in order to achieve a more digital, intelligent, and automated construction of materials informatics with the joint efforts of more interdisciplinary scientists. © 2023 Wiley-VCH GmbH.
KW  - AI for Science
KW  - artificial intelligence
KW  - materials informatics
KW  - materials science
KW  - Physical chemistry
KW  - Robot programming
KW  - Algorithm computing
KW  - Artificial intelligence for science
KW  - Cognitive law
KW  - Computing power
KW  - Continuous innovation
KW  - Material Informatics
KW  - Material science
KW  - Research fields
KW  - Scientific method
KW  - Scientific researches
KW  - Machine design
PB  - John Wiley and Sons Inc
SN  - 09359648 (ISSN)
C2  - 37813548
LA  - English
J2  - Adv Mater
M3  - Review
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 15; Correspondence Address: J. Li; National Key Laboratory of Science and Technology on Micro/Nano Fabrication, Shanghai Jiao Tong University, Shanghai, 200240, China; email: lijinjin@sjtu.edu.cn; CODEN: ADVME
ER  -

TY  - JOUR
AU  - Talyshinskii, A.
AU  - Naik, N.
AU  - Hameed, B.M.Z.
AU  - Juliebø-Jones, P.
AU  - Somani, B.K.
TI  - Potential of AI-Driven Chatbots in Urology: Revolutionizing Patient Care Through Artificial Intelligence
PY  - 2024
T2  - Current Urology Reports
VL  - 25
IS  - 1
SP  - 9
EP  - 18
DO  - 10.1007/s11934-023-01184-3
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171432053&doi=10.1007%2fs11934-023-01184-3&partnerID=40&md5=800d9fc4add0957dab0c0fe5bafdd32e
AD  - Department of Urology, Astana Medical University, Astana, Kazakhstan
AD  - Department of Mechanical and Industrial Engineering, Manipal Institute of Technology, Manipal Academy of Higher Education, Karnataka, Manipal, 576104, India
AD  - Department of Urology, Father Muller Medical College, Karnataka, Mangalore, India
AD  - Department of Urology, Haukeland University Hospital, Bergen, Norway
AD  - Department of Clinical Medicine, University of Bergen, Bergen, Norway
AD  - Department of Urology, University Hospital Southampton, Southampton, United Kingdom
AB  - Purpose of Review: Artificial intelligence (AI) chatbots have emerged as a potential tool to transform urology by improving patient care and physician efficiency. With an emphasis on their potential advantages and drawbacks, this literature review offers a thorough assessment of the state of AI-driven chatbots in urology today. Recent Findings: The capacity of AI-driven chatbots in urology to give patients individualized and timely medical advice is one of its key advantages. Chatbots can help patients prioritize their symptoms and give advice on the best course of treatment. By automating administrative duties and offering clinical decision support, chatbots can also help healthcare providers. Before chatbots are widely used in urology, there are a few issues that need to be resolved. The precision of chatbot diagnoses and recommendations might be impacted by technical constraints like system errors and flaws. Additionally, issues regarding the security and privacy of patient data must be resolved, and chatbots must adhere to all applicable laws. Important issues that must be addressed include accuracy and dependability because any mistakes or inaccuracies could seriously harm patients. The final obstacle is resistance from patients and healthcare professionals who are hesitant to use new technology or who value in-person encounters. Summary: AI-driven chatbots have the potential to significantly improve urology care and efficiency. However, it is essential to thoroughly test and ensure the accuracy of chatbots, address privacy and security concerns, and design user-friendly chatbots that can integrate into existing workflows. By exploring various scenarios and examining the current literature, this review provides an analysis of the prospects and limitations of implementing chatbots in urology. © 2023, The Author(s).
KW  - Artificial intelligence
KW  - Chatbot
KW  - GPT
KW  - Healthcare
KW  - Urology
KW  - Artificial Intelligence
KW  - Humans
KW  - Patient Care
KW  - Physicians
KW  - Urology
KW  - adult
KW  - artificial intelligence chatbot
KW  - decision support system
KW  - health care personnel
KW  - human
KW  - patient care
KW  - patient coding
KW  - physician
KW  - privacy
KW  - review
KW  - security
KW  - urology
KW  - workflow
KW  - artificial intelligence
KW  - patient care
KW  - physician
PB  - Springer
SN  - 15272737 (ISSN)
C2  - 37723300
LA  - English
J2  - Curr. Urol. Rep.
M3  - Review
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 13; Correspondence Address: P. Juliebø-Jones; Department of Urology, Haukeland University Hospital, Bergen, Norway; email: jonesurology@gmail.com
ER  -

TY  - JOUR
AU  - Nay, J.J.
AU  - Karamardian, D.
AU  - Lawsky, S.B.
AU  - Tao, W.
AU  - Bhat, M.
AU  - Jain, R.
AU  - Lee, A.T.
AU  - Choi, J.H.
AU  - Kasai, J.
TI  - Large language models as tax attorneys: a case study in legal capabilities emergence
PY  - 2024
T2  - Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences
VL  - 382
IS  - 2270
C7  - 20230159
DO  - 10.1098/rsta.2023.0159
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186140789&doi=10.1098%2frsta.2023.0159&partnerID=40&md5=e43de89be2d93775cb39d4a6e45b3dbc
AD  - CodeX, Center for Legal Informatics, Stanford University, Stanford, CA, United States
AD  - Stanford University, Stanford, CA, United States
AD  - Northwestern Pritzker School of Law, Chicago, IL, United States
AD  - University of Michigan, Ann Arbor, MI, United States
AD  - SimPPL, India
AD  - Northern Ireland, United Kingdom
AD  - School of Law, University of Southern California, Los Angeles, CA, United States
AD  - Department of Computer Science, University of Washington, Seattle, WA, United States
AB  - Better understanding of Large Language Models' (LLMs) legal analysis abilities can contribute to improving the efficiency of legal services, governing artificial intelligence and leveraging LLMs to identify inconsistencies in law. This paper explores LLM capabilities in applying tax law. We choose this area of law because it has a structure that allows us to set up automated validation pipelines across thousands of examples, requires logical reasoning and maths skills, and enables us to test LLM capabilities in a manner relevant to real-world economic lives of citizens and companies. Our experiments demonstrate emerging legal understanding capabilities, with improved performance in each subsequent OpenAI model release. We experiment with retrieving and using the relevant legal authority to assess the impact of providing additional legal context to LLMs. Few-shot prompting, presenting examples of question-answer pairs, is also found to significantly enhance the performance of the most advanced model, GPT-4. The findings indicate that LLMs, particularly when combined with prompting enhancements and the correct legal texts, can perform at high levels of accuracy but not yet at expert tax lawyer levels. As LLMs continue to advance, their ability to reason about law autonomously could have significant implications for the legal profession and AI governance. This article is part of the theme issue 'A complexity science approach to law and governance'.  © 2024 The Authors.
KW  - artificial intelligence
KW  - computational law
KW  - large language models
KW  - law informs code
KW  - law-informed AI
KW  - machine learning
KW  - Artificial Intelligence
KW  - Humans
KW  - Language
KW  - Lawyers
KW  - Codes (symbols)
KW  - Computational linguistics
KW  - Laws and legislation
KW  - Learning systems
KW  - Machine learning
KW  - Case-studies
KW  - Computational law
KW  - Language model
KW  - Large language model
KW  - Law inform code
KW  - Law-informed AI
KW  - Legal services
KW  - Machine-learning
KW  - Performance
KW  - Tax attorneys
KW  - artificial intelligence
KW  - human
KW  - language
KW  - lawyer
KW  - Taxation
PB  - Royal Society Publishing
SN  - 1364503X (ISSN)
C2  - 38403061
LA  - English
J2  - Philos. Trans. R. Soc. A Math. Phys. Eng. Sci.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 9; Correspondence Address: J.J. Nay; CodeX, Center for Legal Informatics, Stanford University, Stanford, United States; email: john.j.nay@gmail.com
ER  -

TY  - JOUR
AU  - Katz, D.M.
AU  - Bommarito, M.J.
AU  - Gao, S.
AU  - Arredondo, P.
TI  - GPT-4 passes the bar exam
PY  - 2024
T2  - Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences
VL  - 382
IS  - 2270
C7  - 20230254
DO  - 10.1098/rsta.2023.0254
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186143430&doi=10.1098%2frsta.2023.0254&partnerID=40&md5=0b39f0303457f7345f006969b8bfd5de
AD  - Illinois Tech, Chicago Kent College of Law, Chicago, IL, United States
AD  - CodeX, The Stanford Center for Legal Informatics, Stanford, CA, United States
AD  - Bucerius Law School, Hamburg, Germany
AD  - 273 Ventures, Llc, United States
AD  - Casetext, Inc., United States
AB  - In this paper, we experimentally evaluate the zero-shot performance of GPT-4 against prior generations of GPT on the entire uniform bar examination (UBE), including not only the multiple-choice multistate bar examination (MBE), but also the open-ended multistate essay exam (MEE) and multistate performance test (MPT) components. On the MBE, GPT-4 significantly outperforms both human test-takers and prior models, demonstrating a 26% increase over ChatGPT and beating humans in five of seven subject areas. On the MEE and MPT, which have not previously been evaluated by scholars, GPT-4 scores an average of 4.2/6.0 when compared with much lower scores for ChatGPT. Graded across the UBE components, in the manner in which a human test-taker would be, GPT-4 scores approximately 297 points, significantly in excess of the passing threshold for all UBE jurisdictions. These findings document not just the rapid and remarkable advance of large language model performance generally, but also the potential for such models to support the delivery of legal services in society. This article is part of the theme issue 'A complexity science approach to law and governance'.  © 2024 The Authors.
KW  - Bar Exam
KW  - GPT-4
KW  - large language models
KW  - legal complexity
KW  - legal language
KW  - legal services
KW  - Computational linguistics
KW  - alanine aminotransferase
KW  - Bar exam
KW  - GPT-4
KW  - Language model
KW  - Large language model
KW  - Legal complexity
KW  - Legal language
KW  - Legal services
KW  - Multi-state
KW  - Performance tests
KW  - Uniform bar
KW  - article
KW  - ChatGPT
KW  - diagnosis
KW  - human
KW  - large language model
KW  - multiple choice test
KW  - Zero-shot learning
PB  - Royal Society Publishing
SN  - 1364503X (ISSN)
C2  - 38403056
LA  - English
J2  - Philos. Trans. R. Soc. A Math. Phys. Eng. Sci.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 41; Correspondence Address: D.M. Katz; Illinois Tech, Chicago Kent College of Law, Chicago, United States; email: dkatz3@kentlaw.iit.edu
ER  -

TY  - JOUR
AU  - Zaretsky, J.
AU  - Min Kim, J.
AU  - Baskharoun, S.
AU  - Zhao, Y.
AU  - Austrian, J.
AU  - Aphinyanaphongs, Y.
AU  - Gupta, R.
AU  - Blecker, S.B.
AU  - Feldman, J.
TI  - Generative Artificial Intelligence to Transform Inpatient Discharge Summaries to Patient-Friendly Language and Format
PY  - 2024
T2  - JAMA Network Open
SP  - E240357
DO  - 10.1001/jamanetworkopen.2024.0357
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187472990&doi=10.1001%2fjamanetworkopen.2024.0357&partnerID=40&md5=f69bdc78efc778e78319f1f817bc41fb
AD  - Division of Hospital Medicine, Department of Medicine, NYU (New York University) Langone Health, New York, NY, United States
AD  - Department of Medicine, NYU Long Island School of Medicine, Mineola, United States
AD  - Department of Population Health, NYU Langone Health, New York, United States
AD  - Department of Health Informatics, NYU Langone Medical Center Information Technology, New York, United States
AD  - Predictive Analytics Unit, NYU Langone Health, New York, United States
AD  - Department of Internal Medicine, Long Island Community Hospital, NYU Langone Health, New York, United States
AB  - IMPORTANCE By law, patients have immediate access to discharge notes in their medical records. Technical language and abbreviations make notes difficult to read and understand for a typical patient. Large language models (LLMs [eg, GPT-4]) have the potential to transform these notes into patient-friendly language and format. OBJECTIVE To determine whether an LLM can transform discharge summaries into a format that is more readable and understandable. DESIGN, SETTING, AND PARTICIPANTS This cross-sectional study evaluated a sample of the discharge summaries of adult patients discharged from the General Internal Medicine service at NYU (New York University) Langone Health from June 1 to 30, 2023. Patients discharged as deceased were excluded. All discharge summaries were processed by the LLM between July 26 and August 5, 2023. INTERVENTIONS A secure Health Insurance Portability and Accountability Act–compliant platform, Microsoft Azure OpenAI, was used to transform these discharge summaries into a patient-friendly format between July 26 and August 5, 2023. MAIN OUTCOMES AND MEASURES Outcomes included readability as measured by Flesch-Kincaid Grade Level and understandability using Patient Education Materials Assessment Tool (PEMAT) scores. Readability and understandability of the original discharge summaries were compared with the transformed, patient-friendly discharge summaries created through the LLM. As balancing metrics, accuracy and completeness of the patient-friendly version were measured. RESULTS Discharge summaries of 50 patients (31 female [62.0%] and 19 male [38.0%]) were included. The median patient age was 65.5 (IQR, 59.0-77.5) years. Mean (SD) Flesch-Kincaid Grade Level was significantly lower in the patient-friendly discharge summaries (6.2 [0.5] vs 11.0 [1.5]; P < .001). PEMAT understandability scores were significantly higher for patient-friendly discharge summaries (81% vs 13%; P < .001). Two physicians reviewed each patient-friendly discharge summary for accuracy on a 6-point scale, with 54 of 100 reviews (54.0%) giving the best possible rating of 6. Summaries were rated entirely complete in 56 reviews (56.0%). Eighteen reviews noted safety concerns, mostly involving omissions, but also several inaccurate statements (termed hallucinations). CONCLUSIONS AND RELEVANCE The findings of this cross-sectional study of 50 discharge summaries suggest that LLMs can be used to translate discharge summaries into patient-friendly language and formats that are significantly more readable and understandable than discharge summaries as they appear in electronic health records. However, implementation will require improvements in accuracy, completeness, and safety. Given the safety concerns, initial implementation will require physician review. © 2024 American Medical Association. All rights reserved.
KW  - Adult
KW  - Aged
KW  - Artificial Intelligence
KW  - Cross-Sectional Studies
KW  - Electronic Health Records
KW  - Female
KW  - Humans
KW  - Inpatients
KW  - Language
KW  - Male
KW  - Middle Aged
KW  - Patient Discharge
KW  - United States
KW  - adult
KW  - aged
KW  - artificial intelligence
KW  - cross-sectional study
KW  - electronic health record
KW  - female
KW  - hospital discharge
KW  - hospital patient
KW  - human
KW  - language
KW  - male
KW  - middle aged
KW  - United States
PB  - American Medical Association
SN  - 25743805 (ISSN)
C2  - 38466307
LA  - English
J2  - JAMA Netw. Open
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 25; Correspondence Address: J. Zaretsky; NYU Langone Health, New York, 550 First Ave, 10016, United States; email: jonah.zaretsky@nyulangone.org
ER  -

TY  - JOUR
AU  - Ni, B.
AU  - Buehler, M.J.
TI  - MechAgents: Large language model multi-agent collaborations can solve mechanics problems, generate new data, and integrate knowledge
PY  - 2024
T2  - Extreme Mechanics Letters
VL  - 67
C7  - 102131
DO  - 10.1016/j.eml.2024.102131
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185307555&doi=10.1016%2fj.eml.2024.102131&partnerID=40&md5=8d8520113f0544792728b07b79d75fc5
AD  - Laboratory for Atomistic and Molecular Mechanics (LAMM), Massachusetts Institute of Technology, 77 Massachusetts Ave, Cambridge, 02139, MA, United States
AD  - Center for Computational Science and Engineering, Schwarzman College of Computing, Massachusetts Institute of Technology, 77 Massachusetts Ave, Cambridge, 02139, MA, United States
AB  - Solving mechanics problems using numerical methods requires comprehensive intelligent capability of retrieving relevant knowledge and theory, constructing and executing codes, analyzing the results, a task that has thus far mainly been reserved for humans. While emerging AI methods can provide effective approaches to solve end-to-end problems, for instance via the use of deep surrogate models or various data analytics strategies, they often lack physical intuition since knowledge is baked into the parametric complement through training, offering less flexibility when it comes to incorporating mathematical or physical insights. By leveraging diverse capabilities of multiple dynamically interacting large language models (LLMs), we can overcome the limitations of conventional approaches and develop a new class of physics-inspired generative machine learning platform, here referred to as MechAgents. A set of AI agents can solve mechanics tasks, here demonstrated for elasticity problems, via autonomous collaborations. A two-agent team can effectively write, execute and self-correct code, in order to apply finite element methods to solve classical elasticity problems in various flavors (different boundary conditions, domain geometries, meshes, small/finite deformation and linear/hyper-elastic constitutive laws, and others). For more complex tasks, we construct a larger group of agents with enhanced division of labor among planning, formulating, coding, executing and criticizing the process and results. The agents mutually correct each other to improve the overall team-work performance in understanding, formulating and validating the solution. Our framework shows the potential of synergizing the intelligence of language models, the reliability of physics-based modeling, and the dynamic collaborations among diverse agents, opening novel avenues for automation of solving engineering problems. © 2024 Elsevier Ltd
KW  - Elasticity
KW  - Finite element method
KW  - GPT-4
KW  - Hyper-elasticity
KW  - Large language model (LLM)
KW  - Multi-agent modeling
KW  - Physics-inspired machine learning
KW  - Autonomous agents
KW  - Computational linguistics
KW  - Computational methods
KW  - Data Analytics
KW  - Finite element method
KW  - Machine learning
KW  - Modeling languages
KW  - Numerical methods
KW  - Agent collaboration
KW  - Elasticity problems
KW  - GPT-4
KW  - Hyper-elasticity
KW  - Language model
KW  - Large language model
KW  - Machine-learning
KW  - Multi agent
KW  - Multi-Agent Model
KW  - Physic-inspired machine learning
KW  - Elasticity
PB  - Elsevier Ltd
SN  - 23524316 (ISSN)
LA  - English
J2  - Extrem. Mech. Lett.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 9; Correspondence Address: M.J. Buehler; Laboratory for Atomistic and Molecular Mechanics (LAMM), Massachusetts Institute of Technology, Cambridge, 77 Massachusetts Ave, 02139, United States; email: mbuehler@MIT.EDU
ER  -

TY  - JOUR
AU  - Munn, L.
AU  - Magee, L.
AU  - Arora, V.
TI  - Truth machines: synthesizing veracity in AI language models
PY  - 2024
T2  - AI and Society
VL  - 39
IS  - 6
C7  - e11510
SP  - 2759
EP  - 2773
DO  - 10.1007/s00146-023-01756-4
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168887254&doi=10.1007%2fs00146-023-01756-4&partnerID=40&md5=b8862d84a40c54ca88126cffec89259e
AD  - Digital Cultures and Societies, University of Queensland, Saint Lucia, Australia
AD  - Institute for Culture and Society, Western Sydney University, Sydney, Australia
AD  - University of Stirling, Stirling, United Kingdom
AB  - As AI technologies are rolled out into healthcare, academia, human resources, law, and a multitude of other domains, they become de-facto arbiters of truth. But truth is highly contested, with many different definitions and approaches. This article discusses the struggle for truth in AI systems and the general responses to date. It then investigates the production of truth in InstructGPT, a large language model, highlighting how data harvesting, model architectures, and social feedback mechanisms weave together disparate understandings of veracity. It conceptualizes this performance as an operationalization of truth, where distinct, often-conflicting claims are smoothly synthesized and confidently presented into truth-statements. We argue that these same logics and inconsistencies play out in Instruct’s successor, ChatGPT, reiterating truth as a non-trivial problem. We suggest that enriching sociality and thickening “reality” are two promising vectors for enhancing the truth-evaluating capacities of future language models. We conclude, however, by stepping back to consider AI truth-telling as a social practice: what kind of “truth” do we as listeners desire? © The Author(s) 2023.
KW  - AI
KW  - ChatGPT
KW  - GPT-3
KW  - InstructGPT
KW  - Large language model
KW  - Truthfulness
KW  - Veracity
KW  - AI systems
KW  - AI Technologies
KW  - ChatGPT
KW  - Data harvesting
KW  - GPT-3
KW  - Instructgpt
KW  - Language model
KW  - Large language model
KW  - Truthfulness
KW  - Veracity
KW  - Computational linguistics
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 09515666 (ISSN)
LA  - English
J2  - AI Soc.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 10; Correspondence Address: L. Munn; Digital Cultures and Societies, University of Queensland, Saint Lucia, Australia; email: l.munn@uq.edu.au
ER  -

