TY  - CONF
AU  - Hadzi, A.
TI  - Algorithms, Ethics and Justice
PY  - 2022
T2  - Lecture Notes in Networks and Systems
VL  - 382
SP  - 121
EP  - 138
DO  - 10.1007/978-3-030-93780-5_9
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126199090&doi=10.1007%2f978-3-030-93780-5_9&partnerID=40&md5=ffd3075692dbf2a1df0aa8fe1a5bff1d
AD  - University of Malta, Msida, MSD-2080, Malta
AB  - This paper discusses the argument that the adoption of artificial intelligence (AI) technologies benefits the powerful few, focussing on their own existential concerns. The paper will narrow down the analysis of the argument to jurisprudence (i.e. the philosophy of law), considering also the historical context. The paper will discuss the construction of the legal system through the lens of political involvement of what one may want to consider to be powerful elites. Before discussing these aspects the paper will clarify the notion of “powerful elites”. In doing so the paper will be demonstrating that it is difficult to prove that the adoption of AI technologies is undertaken in a way which mainly serves a powerful class in society. Nevertheless, analysing the culture around AI technologies with regard to the nature of law with a philosophical and sociological focus demonstrates a utilitarian and authoritarian trend in the adoption of AI technologies. The paper will conclude by proposing an alternative, some might say practically unattainable, approach to the current legal system by looking into restorative justice for AI crimes, and how the ethics of care could be applied to AI technologies. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Artificial intelligence
KW  - Cyborg
KW  - Disciplinary power
KW  - Ethics of care
KW  - Legal positivism
KW  - Natural law
KW  - Power elites
KW  - Privacy
KW  - Restorative justice
A2  - Dingli A.
A2  - Pfeiffer A.
A2  - Serada A.
A2  - Bugeja M.
A2  - Bezzina S.
PB  - Springer Science and Business Media Deutschland GmbH
SN  - 23673370 (ISSN); 978-303093779-9 (ISBN)
LA  - English
J2  - Lect. Notes Networks Syst.
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 2; Correspondence Address: A. Hadzi; University of Malta, Msida, MSD-2080, Malta; email: ahadz01@um.edu.mt; Conference name: Media, Arts, and Design Artificial Intelligence conference, MADAI 2020; Conference date: 19 June 2020 through 19 June 2020; Conference code: 274259
ER  -

TY  - JOUR
AU  - Matsuo, T.
AU  - Iwamitsu, S.
TI  - Sustainable city planning and public administration assisted by green AI: attendant legal challenges under Japanese law
PY  - 2022
T2  - Transforming Government: People, Process and Policy
VL  - 16
IS  - 3
SP  - 334
EP  - 346
DO  - 10.1108/TG-06-2021-0109
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132864271&doi=10.1108%2fTG-06-2021-0109&partnerID=40&md5=238a58391ebe81fb85b0907193905ce2
AD  - Momo-o, Matsuo and Namba, Tokyo, Japan
AD  - Law School, Columbia University, New York City, NY, United States
AB  - Purpose: The purpose of this paper is to present the legal conditions under which governments may use green artificial intelligence (AI) in city planning. Although Japan was one of the early countries to release its general AI principles, it has been relatively slow in establishing conditions where administrative agencies may use AI. Granted, there have been some recent scholarship that discusses the usage of AI in general under Japanese administrative law, but the use of green AI in city planning under Japanese law has not yet been discussed. Hence, this paper intends to focus on green AI in city planning and discuss the conditions for usage based on different categories of AI. Design/methodology/approach: This paper conducts a legal analysis on the utilization of AI for the purpose of sustainable city planning and administration in Japan. The approach of this paper is to summarize the existing scholarship in Japanese administrative law and analyse the new elements in the new field of green AI in city planning. This paper is not a natural science paper. The social science method of jurisprudence is used. This paper cites only public sources, and no informal literature has been referenced. Findings: This paper establishes the conditions where Japanese central and local government may use green AI in city planning from a legal viewpoint based on three categories. The categories are green AI usage in city planning concerning things, green AI usage in city planning concerning people and green AI usage in city planning concerning automated decision-making. Research limitations: This research is limited to an analysis of Japanese law, which means that issues other than law are not included in this paper. Further, although general legal issues are discussed, this paper is intended to discuss Japanese law issues only, and foreign laws are not discussed. Therefore, this paper mostly cites Japanese language papers published in domestic journals. Practical implications: The intended practical implication of this paper is to allow central and local governments to determine – based on the proposed categories – whether green AI can be used for city planning purposes and under which conditions. The authors hope that this will assist the Japanese government in establishing rules on the usage of AI by governmental agencies and allow for the greater actual usage by Japanese central and local governments of green AI in future city planning. Social implications: As the theme of this paper deals with governmental use (and the function of a government is to serve society), the social implications at issue can be said to be equivalent to the practical implication. Originality/value: There have been articles discussing Japanese administrative law restrictions on AI in general. However, as of now, to the best of the authors’ knowledge, there have been no articles published focusing on green AI used for city planning. The authors note that the green AI used for city planning would have different legal implications from AI’s usage by the government in general, such as the chatbot used by the agencies or lethal autonomous weapons by the military force. Therefore, this paper is original in focusing on green AI used for city planning. © 2022, Emerald Publishing Limited.
KW  - Administrative Law
KW  - Green AI
KW  - Law
PB  - Emerald Group Holdings Ltd.
SN  - 17506166 (ISSN)
LA  - English
J2  - Trans. Gov. People Process Policy
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 7; Correspondence Address: T. Matsuo; Momo-o, Matsuo and Namba, Tokyo, Japan; email: tmatsuo@llm13.law.harvard.edu
ER  -

TY  - JOUR
AU  - Lang, M.
AU  - Bernier, A.
AU  - Knoppers, B.M.
TI  - Artificial Intelligence in Cardiovascular Imaging: “Unexplainable” Legal and Ethical Challenges?
PY  - 2022
T2  - Canadian Journal of Cardiology
VL  - 38
IS  - 2
SP  - 225
EP  - 233
DO  - 10.1016/j.cjca.2021.10.009
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121773438&doi=10.1016%2fj.cjca.2021.10.009&partnerID=40&md5=61c8d3056fe3cbd1332635240c41ee12
AD  - Centre of Genomics and Policy, McGill University, Faculty of Medicine and Health Sciences, Montreal, Quebec, Canada
AB  - Nowhere is the influence of artificial intelligence (AI) likely to be more profoundly felt than in health care, from patient triage and diagnosis to surgery and follow-up. Over the medium-term, these effects will be more acute in the cardiovascular imaging context, in which AI models are already successfully performing at approximately human levels of accuracy and efficiency in certain applications. Yet, the adoption of unexplainable AI systems for cardiovascular imaging still raises significant legal and ethical challenges. We focus in particular on challenges posed by the unexplainable character of deep learning and other forms of sophisticated AI modelling used for cardiovascular imaging by briefly outlining the systems being developed in this space, describing how they work, and considering how they might generate outputs that are not reviewable by physicians or system programmers. We suggest that an unexplainable tendency presents 2 specific ethico-legal concerns: (1) difficulty for health regulators; and (2) confusion about the assignment of liability for error or fault in the use of AI systems. We suggest that addressing these concerns is critical for ensuring AI's successful implementation in cardiovascular imaging. © 2021 Canadian Cardiovascular Society
KW  - Artificial Intelligence
KW  - Cardiology
KW  - Cardiovascular Diseases
KW  - Deep Learning
KW  - Delivery of Health Care
KW  - Diagnostic Techniques, Cardiovascular
KW  - Humans
KW  - adoption
KW  - adult
KW  - artificial intelligence
KW  - deep learning
KW  - emergency health service
KW  - follow up
KW  - human
KW  - physician
KW  - review
KW  - cardiology
KW  - cardiovascular disease
KW  - cardiovascular system examination
KW  - ethics
KW  - health care delivery
KW  - legislation and jurisprudence
PB  - Elsevier Inc.
SN  - 0828282X (ISSN)
C2  - 34737036
LA  - English
J2  - Can. J. Cardiol.
M3  - Review
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 19; Correspondence Address: M. Lang; Michael Lang, McGill University, 740 Avenue Dr, Penfield, Suite 5200, Montreal, Montreal, H3A 0G1, Canada; email: michael.lang@mcgill.ca; B.M. Knoppers; McGill University, 740, Avenue Dr Penfield, Suite 5200, Montreal, Montreal, H3A 0G1, Canada; email: bartha.knoppers@mcgill.ca; CODEN: CJCAE
ER  -

TY  - JOUR
AU  - Garvey, J.B.
TI  - LET’S GET REAL: WEAK ARTIFICIAL INTELLIGENCE HAS FREE SPEECH RIGHTS
PY  - 2022
T2  - Fordham Law Review
VL  - 91
IS  - 3
SP  - 953
EP  - 991
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153774591&partnerID=40&md5=04580aaac28718d80ed70c384368f4f4
AD  - Fordham University School of Law, United States
AB  - The right to free speech is a strongly protected constitutional right under the First Amendment to the U.S. Constitution. In 2010, the U.S. Supreme Court significantly expanded free speech protections for corporations in Citizens United v. FEC. This case prompted the question: could other nonhuman actors also be eligible for free speech protection under the First Amendment? This inquiry is no longer a mere intellectual exercise: sophisticated artificial intelligence (AI) may soon be capable of producing speech. As such, there are novel and complex questions surrounding the application of the First Amendment to AI. Some commentators argue that AI should be granted free speech rights because AI speech may soon be sufficiently comparable to human speech. Others disagree and argue that First Amendment rights should not be extended to AI because there are traits in human speech that AI speech could not replicate. This Note explores the application of First Amendment jurisprudence to AI. Introducing relevant philosophical literature, this Note examines theories of human intelligence and decision-making in order to better understand the process that humans use to produce speech, and whether AI produces speech in a similar manner. In light of the legal and philosophical literature, as well as the Supreme Court’s current First Amendment jurisprudence, this Note proposes that some types of AI are eligible for free speech protection under the First Amendment. © 2022 Fordham University School of Law. All rights reserved.
PB  - Fordham University School of Law
SN  - 0015704X (ISSN)
LA  - English
J2  - Fordham Law Rev.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 2
ER  -

TY  - CHAP
AU  - Levy, I.
TI  - Hercules on a Diet
PY  - 2022
T2  - Economic Analysis of Law in European Legal Scholarship
VL  - 14
SP  - 159
EP  - 177
DO  - 10.1007/978-3-031-11744-2_8
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167518007&doi=10.1007%2f978-3-031-11744-2_8&partnerID=40&md5=a5ef5f36570b12c0c11d40c2d7488da0
AD  - Melbourne Law School, Carlton, VIC, Australia
AB  - This paper argues that Ronald Dworkin’s ‘Judge Hercules’ jurisprudence is inapplicable in light of the psychological analysis of judicial decision-making. Dworkin adopts the assumption that the law is structured by a coherent set of principles about justice and fairness and procedural due process. In his view, the law asks judges to enforce this coherent set of principles in any new cases that come before them, so that each person’s situation is judged fairly and justly according to the same principles. To explain how this complex task is performed, Dworkin creates his metaphor of a ‘Judge Hercules’. Hercules is an ideal judge who is required to consider the law as a whole when deciding a particular case and to always ascertain the one right answer. According to Dworkin, Hercules must check the various combinations of principles and determine which of them is ‘best’ as compared to all other possible combinations. Dworkin’s metaphor of Judge Hercules is inconsistent with the cognitive findings regarding information overload. While Dworkin supports taking a wide range of principles into account to reach a specific decision, the phenomenon of information overload suggests that excessive information would confuse the judge and damage the decision-making process. Dworkin recognises that Hercules is more reflective and self-conscious than any real judge needs to be or could be given the pressure of work. But, even though no judge can behave just like Hercules, Dworkin asserts it remains a useful aspiration. He proceeds to say that Hercules shows us the ‘hidden structure’ of real judges’ judgments. However, psychological findings imply that the Judge Hercules metaphor is not as useful as Dworkin suggests. Dworkin’s approach values the integration of as many principles as possible to reach a decision. But, in line with cognitive findings, Dworkin’s suggested decision-making process is more likely to confuse a human judge than to help her reach the right decision. The Judge Hercules model may, however, be suitable for AI rather than for a human judge since algorithms are able to process a vast amount of information. Therefore, the discussion will be concluded by reference to the debate about machine learning algorithmic legal decision-making, which has the potential of resolving some of the issues with Judge Hercules. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.
KW  - Cognitive overload
KW  - Dworkin
KW  - Judges
PB  - Springer Nature
SN  - 25121294 (ISSN)
LA  - English
J2  - Econ. Anal. Law. Eur. Leg. Scholarsh.
M3  - Book chapter
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 0; Correspondence Address: I. Levy; Melbourne Law School, Carlton, Australia; email: inbar.levy@unimelb.edu.au
ER  -

TY  - JOUR
AU  - Jobson, D.
AU  - Mar, V.
AU  - Freckelton, I.
TI  - Legal and ethical considerations of artificial intelligence in skin cancer diagnosis
PY  - 2022
T2  - Australasian Journal of Dermatology
VL  - 63
IS  - 1
SP  - e1
EP  - e5
DO  - 10.1111/ajd.13690
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112760556&doi=10.1111%2fajd.13690&partnerID=40&md5=3dfb1a9ef9dec5f842a7417be5c5ae36
AD  - Victorian Melanoma Service, Alfred Hospital, Melbourne, VIC, Australia
AD  - School of Public Health and Preventive Medicine, Monash University, Melbourne, VIC, Australia
AD  - Victorian Bar, Melbourne, VIC, Australia
AD  - Law Faculty, Department of Psychiatry, University of Melbourne, Melbourne, VIC, Australia
AB  - Artificial intelligence (AI) technology is becoming increasingly accurate and prevalent for the diagnosis of skin cancers. Commercially available AI diagnostic software is entering markets across the world posing new legal and ethical challenges for both clinicians and software companies. Australia has the highest rates of skin cancer in the world and is poised to be a significant benefactor and pioneer of the technology. This review describes the legal and ethical considerations raised by the emergence of artificial intelligence in skin cancer diagnosis and proposes recommendations for best practice. © 2021 The Australasian College of Dermatologists.
KW  - apps
KW  - artificial intelligence
KW  - diagnosis
KW  - ethical
KW  - legal
KW  - skin cancer
KW  - smartphone
KW  - Artificial Intelligence
KW  - Australia
KW  - Confidentiality
KW  - Diagnosis, Computer-Assisted
KW  - Humans
KW  - Informed Consent
KW  - Liability, Legal
KW  - Malpractice
KW  - Skin Neoplasms
KW  - Software
KW  - artificial intelligence
KW  - cancer diagnosis
KW  - cancer patient
KW  - clinician
KW  - diagnostic accuracy
KW  - diagnostic error
KW  - ethics
KW  - histopathology
KW  - human
KW  - legal aspect
KW  - machine learning
KW  - melanoma
KW  - negligence
KW  - photography
KW  - privacy
KW  - Review
KW  - skin cancer
KW  - software
KW  - artificial intelligence
KW  - Australia
KW  - computer assisted diagnosis
KW  - confidentiality
KW  - informed consent
KW  - legal aspect
KW  - legal liability
KW  - legislation and jurisprudence
KW  - malpractice
KW  - skin tumor
PB  - John Wiley and Sons Inc
SN  - 00048380 (ISSN)
C2  - 34407234
LA  - English
J2  - Australas. J. Dermatol.
M3  - Review
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 15; Correspondence Address: D. Jobson; Victorian Melanoma Service, Alfred Hospital, Melbourne, Australia; email: dalewjobson@gmail.com; CODEN: AJDEB
ER  -

TY  - JOUR
AU  - Papa, A.
TI  - Artificial intelligence and public decision-making between technology, policy and rights protection
ST  - Intelligenza Artificiale e decisioni pubbliche tra tecnica, politica e tutela dei diritti
PY  - 2022
T2  - Federalismi.it
VL  - 2022
IS  - 22
SP  - 101
EP  - 114
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141789240&partnerID=40&md5=3874aa4a844e3a1651a232616eb6a6ec
AD  - Istituzioni di diritto pubblico Università degli Studi di Napoli “Parthenope”, Italy
AB  - The use of artificial intelligence in public decision-making is a growing phenomenon. Accordingly, it is crucial to guarantee the use of this technology, without any preconceived limits, while protecting individual freedoms and the democratic nature of the system as a whole. Whilst awaiting the approval, truly difficult, of the European regulation on the subject, the definition of limits and guarantees on the use of AI systems is a matter in the hands of jurisprudence, in an ex post perspective. However, this circumstance does not support the development of a climate of trust in this technology. © 2022, Societa Editoriale Federalismi s.r.l.. All rights reserved.
KW  - algorithms
KW  - artificial intelligence
KW  - inequalities
KW  - protection of rights
KW  - public decision
PB  - Societa Editoriale Federalismi s.r.l.
SN  - 18263534 (ISSN)
LA  - Italian
J2  - Federalismi.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 2
ER  -

TY  - JOUR
AU  - Chatterjee, S.
AU  - N.S, S.
TI  - Artificial intelligence and human rights: a comprehensive study from Indian legal and policy perspective
PY  - 2022
T2  - International Journal of Law and Management
VL  - 64
IS  - 1
SP  - 110
EP  - 134
DO  - 10.1108/IJLMA-02-2021-0049
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108152642&doi=10.1108%2fIJLMA-02-2021-0049&partnerID=40&md5=2973c10d91bafaea98c08095c4e0528f
AD  - The WB National University of Juridical Sciences, Kolkata, India
AB  - Purpose: The purpose of this study is to investigate the impact of artificial intelligence (AI) on the human rights issue. This study has also examined issues with AI for business and its civil and criminal liability. This study has provided inputs to the policymakers and government authorities to overcome different challenges. Design/methodology/approach: This study has analysed different international and Indian laws on human rights issues and the impacts of these laws to protect the human rights of the individual, which could be under threat due to the advancement of AI technology. This study has used descriptive doctrinal legal research methods to examine and understand the insights of existing laws and regulations in India to protect human rights and how these laws could be further developed to protect human rights under the Indian jurisprudence, which is under threat due to rapid advancement of AI-related technology. Findings: The study provides a comprehensive insight on the influence of AI on human rights issues and the existing laws in India. The study also shows different policy initiatives by the Government of India to regulate AI. Research limitations/implications: The study highlights some of the key policy recommendations helpful to regulate AI. Moreover, this study provides inputs to the regulatory authorities and legal fraternity to draft a much-needed comprehensive policy to regulate AI in the context of the protection of human rights of the citizens. Originality/value: AI is constantly posing entangled challenges to human rights. There is no comprehensive study, which investigated the emergence of AI and its influence on human rights issues, especially from the Indian legal perspective. So there is a research gap. This study provides a unique insight of the emergence of AI applications and its influence on human rights issues and provides inputs to the policymaker to help them to draft an effective regulation on AI to protect the human rights of Indian citizens. Thus, this study is considered a unique study that adds value towards the overall literature. © 2021, Emerald Publishing Limited.
KW  - AI
KW  - Data privacy law
KW  - Governance and ethics
KW  - India
KW  - Jurisprudence
KW  - Law
KW  - Law and regulation
KW  - Policy
KW  - Policy and law
KW  - Regulation
KW  - Technology
KW  - Technology law
PB  - Emerald Group Holdings Ltd.
SN  - 1754243X (ISSN)
LA  - English
J2  - Int. J. Law Manage.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 12; Correspondence Address: S. Chatterjee; The WB National University of Juridical Sciences, Kolkata, India; email: sheshadri.academic@gmail.com
ER  -

TY  - CONF
AU  - Kemper, B.
TI  - AI and Stochastic Terrorism - Should it be done?
PY  - 2022
T2  - Proceedings - 2022 IEEE International Symposium on Software Reliability Engineering Workshops, ISSREW 2022
SP  - 347
EP  - 356
DO  - 10.1109/ISSREW55968.2022.00091
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146331688&doi=10.1109%2fISSREW55968.2022.00091&partnerID=40&md5=0598fdf8be4e47c1b098ec07d80681d6
AD  - Kemper Engineering Services, Baton Rouge, LA, United States
AB  - The use of Artificial Intelligence and Machine Learning technology may seem to be the tools needed to combat media-inspired 'lone wolf attacks' by implementing the concept of 'stochastic terrorism,' targeting harmful media influences. Machine Learning is in current use to sort through social media data to assess hate speech. Artificial Intelligence is in current use to interpret the data and trends processed by Machine Learning for tasks such as finding criminal networks. The question becomes 'can stochastic terrorism be proven' and 'should this be implemented.' Labeling someone as a 'terrorist,' regardless of any modifier for the term, tags the person or group for severe, potentially lethal, response by the government and the community. Criminal accusation cannot ethically be done casually or without sufficient cause. Due to documented problems with bias in all aspects of the issue, using these computational tools to establish legal causation between media statements by pundits, politicians, or others and the violence of 'lone wolf' actors would not meet the requirements of US jurisprudence or the ethical principles for Artificial Intelligence of being explainable, transparent, and responsible. © 2022 IEEE.
KW  - artificial intelligence
KW  - bias
KW  - civil rights
KW  - due process
KW  - ethics
KW  - forensic
KW  - machine learning
KW  - stochastic terrorism
KW  - trust
KW  - Ethical technology
KW  - Stochastic systems
KW  - Terrorism
KW  - 'current
KW  - Artificial intelligence learning
KW  - Bias
KW  - Civil rights
KW  - Due process
KW  - Forensic
KW  - Machine-learning
KW  - Stochastic terrorism
KW  - Stochastics
KW  - Trust
KW  - Machine learning
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 978-166547679-9 (ISBN)
LA  - English
J2  - Proc. - IEEE Int. Symp. Softw. Reliab. Eng. Workshops, ISSREW
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 2; Conference name: 33rd IEEE International Symposium on Software Reliability Engineering Workshops, ISSREW 2022; Conference date: 31 October 2022 through 3 November 2022; Conference code: 185583
ER  -

TY  - JOUR
AU  - Li, W.
AU  - Dissanaike, S.
TI  - Jury verdicts, outcomes, and tort reform features of malpractice cases involving thoracic outlet syndrome
PY  - 2022
T2  - Journal of Vascular Surgery
VL  - 75
IS  - 3
SP  - 962
EP  - 967
DO  - 10.1016/j.jvs.2021.08.098
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124137677&doi=10.1016%2fj.jvs.2021.08.098&partnerID=40&md5=722de361f82c6d3858c0a0fc21904bf5
AD  - Department of Surgery, Texas Tech University Health Sciences Center, Lubbock, Tex, United States
AD  - Loyola University Chicago School of Law, Chicago, Ill, United States
AB  - Objective/Background: Thoracic outlet syndrome (TOS) is most often referred to vascular surgeons. However, there is a lack of understanding of the malpractice cases involving TOS. The goal of this study is to better understand the medicolegal landscape related to the care of TOS. Methods: The Westlaw Edge AI-powered proprietary system was retrospectively reviewed for malpractice cases involving TOS. A Boolean search strategy was used to identify target cases under the case category of “Jury Verdicts & Settlements” for all state and federal jurisdictions from 1970 to September 2020. The settled case was described but not included in the statistical analysis. Descriptive statistics were used to report our findings, and when appropriate. The P ≤ .05 decision rule was established a priori as the null hypothesis rejection criterion to determine associations between jury verdicts outcomes and state's tort reform status. Results: In this study, 39 cases were identified and met the study's inclusion criteria from the entire Westlaw Edge database. Among plaintiffs who disclosed age and/or gender, median age was 35.0 years with a female majority (67.6%). Cases involving TOS were noted to be steadily decreasing since the mid-1990s. The cases were unevenly spread across 18 states, with the highest number of cases (14, 35.9%) from California and the second highest (4, 10.3%) from Pennsylvania. A similar uneven distribution was seen among U.S. census regions, in which the West had the highest cases (39.5%). The study revealed that more cases were brought to trials in tort reform states (26, 68.4%) than in non-tort reform states (12, 31.6%). A total of 24 of 39 (61.5%) plaintiffs had one specific claim, which resulted in their economic and noneconomic damages. Negligent operation and treatment complication represented an overwhelming majority of claims brought by 38 of 39 plaintiffs (97.4%). Misdiagnosis and lack of informed consent were both brought nine times (23.1%) by the group. Intraoperative nerve injury (20 patients, 51.3%) was the most commonly reported complication. Excluding one case with a settlement of $965,000, 30 of 38 (78.9%) cases went to trials and received defense verdicts. Eight cases (20.5%) were found in favor of plaintiffs with a median payout of $725,581. Conclusions: This study highlighted higher than average payouts to plaintiffs and risk factors that may result in malpractice lawsuits for surgeons undertaking TOS treatment. Future studies are needed to further clarify the relationships between tort reform and outcomes of malpractice cases involving TOS. © 2021 Society for Vascular Surgery
KW  - Jury verdicts
KW  - Malpractice
KW  - Thoracic outlet syndrome
KW  - Tort reform
KW  - Adult
KW  - Compensation and Redress
KW  - Databases, Factual
KW  - Decompression, Surgical
KW  - Female
KW  - Humans
KW  - Insurance, Liability
KW  - Liability, Legal
KW  - Male
KW  - Malpractice
KW  - Medical Errors
KW  - Policy Making
KW  - Postoperative Complications
KW  - Retrospective Studies
KW  - Risk Assessment
KW  - Risk Factors
KW  - Thoracic Outlet Syndrome
KW  - Treatment Outcome
KW  - Vascular Surgical Procedures
KW  - adult
KW  - Article
KW  - California
KW  - clinical article
KW  - diagnostic error
KW  - female
KW  - gender
KW  - human
KW  - informed consent
KW  - law suit
KW  - male
KW  - malpractice
KW  - nerve injury
KW  - Pennsylvania
KW  - peroperative complication
KW  - postoperative complication
KW  - risk factor
KW  - thorax outlet syndrome
KW  - United States
KW  - adverse event
KW  - compensation
KW  - decompression surgery
KW  - economics
KW  - factual database
KW  - insurance
KW  - legal liability
KW  - legislation and jurisprudence
KW  - malpractice
KW  - management
KW  - medical error
KW  - postoperative complication
KW  - retrospective study
KW  - risk assessment
KW  - thorax outlet syndrome
KW  - treatment outcome
KW  - vascular surgery
PB  - Elsevier Inc.
SN  - 07415214 (ISSN)
C2  - 34601048
LA  - English
J2  - J. Vasc. Surg.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 3; Correspondence Address: W. Li; Department of Surgery, Texas Tech Health Sciences Center, 3601 4th St, MS #8312, Lubbock, TX 79430; and Loyola University Chicago School of Law, Chicago, 25 E Pearson St, IL, 60611; email: wli10@luc.edu; CODEN: JVSUE
ER  -

