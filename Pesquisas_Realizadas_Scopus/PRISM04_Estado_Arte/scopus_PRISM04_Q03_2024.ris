TY  - JOUR
AU  - Migliorini, S.
AU  - Moreira, J.I.
TI  - The Case for Nurturing AI Literacy in Law Schools
PY  - 2024
T2  - Asian Journal of Legal Education
DO  - 10.1177/23220058241265613
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201266566&doi=10.1177%2f23220058241265613&partnerID=40&md5=e1498a6c1a2654b5c4f7d137c7358d13
AD  - Faculty of Law, University of Macau, Macao
AB  - The debate surrounding the permissibility of generative artificial intelligence (AI) tools in legal education has garnered widespread attention. However, this discourse has largely oscillated between the advantages and disadvantages of generative AI usage whilst failing to fully consider how the uptake of these tools relates to the fundamental objectives of legal education. This article contributes to the current debate by positing that since the primary aim of legal education is the preparation of legal professionals and the development of legal research, generative AI must be holistically integrated into the dominant approaches to legal teaching. This stems from the fact that the legal profession will increasingly rely on generative AI in its daily work. Therefore, AI literacy will emerge as a critical professional skill in the legal realm. Against this background, this article further argues that the integration of AI into the legal curriculum should be addressed by diversifying assessment strategies, emphasizing the importance of academic integrity and making resources on the ethical use of AI available to both students and academic staff in law schools. © 2024 The West Bengal National University of Juridical Sciences.
PB  - SAGE Publications Inc.
SN  - 23220058 (ISSN)
LA  - English
J2  - Asian. J.  Leg. Educ.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 2; Correspondence Address: J.I. Moreira; Faculty of Law, University of Macau, Macao; email: joaomoreira@um.edu.mo
ER  -

TY  - JOUR
AU  - Bukar, U.A.
AU  - Sayeed, M.S.
AU  - Fatimah Abdul Razak, S.
AU  - Yogarayan, S.
AU  - Sneesl, R.
TI  - Decision-Making Framework for the Utilization of Generative Artificial Intelligence in Education: A Case Study of ChatGPT
PY  - 2024
T2  - IEEE Access
VL  - 12
SP  - 95368
EP  - 95389
DO  - 10.1109/ACCESS.2024.3425172
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198250201&doi=10.1109%2fACCESS.2024.3425172&partnerID=40&md5=042dd30c36dd4e425e6c75cf66f88e8d
AD  - Multimedia University, Centre for Intelligent Cloud Computing (CICC), Faculty of Information Science and Technology, Melaka, Bukit Beruang, 75450, Malaysia
AD  - Universiti Putra Malaysia (UPM), Faculty of Computer Science and Information Technology, Department of Software Engineering and Information System, Selangor, Serdang, 43400, Malaysia
AD  - University of Basrah, College of Science, Basrah, 61001, Iraq
AB  - The increasing integration of ChatGPT, a Generative Artificial Intelligence (Gen-AI) model, into educational environments has sparked substantial ethical concerns. This paper addresses the crucial question of whether to impose restrictions or legislate the usage of Gen-AI, with ChatGPT as a pivotal case study. Through systematic literature review and frequency of occurrence analysis, 10 ethical concerns were selected for further analysis using the Analytic Hierarchy Process (AHP). The analysis responses of 10 expert panels show that the top concerns, as revealed by their weights, after meeting the consistency requirement, include copyright, legal, and compliance issues (0.1731), privacy and confidentiality (0.1286), academic integrity (0.1206), incorrect reference and citation practices (0.1111), and safety and security concerns (0.1050). Evaluating the impact of these concerns on the policy alternatives (restriction and legislation), the findings revealed that 'Restriction' received a higher weight (0.513712) compared to 'Legislation' (0.485887). Notably, copyright, legal, and compliance issues, privacy and confidentiality, and academic integrity emerged as crucial factors influencing the decision between restriction and legislation. This study offers valuable insights for educational institutions and policymakers, suggesting the need for inclusive discussions, pilot programs to assess impacts on critical thinking, development of clear guidelines, flexible regulatory frameworks, awareness campaigns, and potential strategies for ethical and responsible use.  © 2013 IEEE.
KW  - AHP
KW  - ChatGPT
KW  - decision making
KW  - ethical concerns
KW  - legislation
KW  - restriction
KW  - Analytic hierarchy process
KW  - Artificial intelligence
KW  - Copyrights
KW  - Hierarchical systems
KW  - Laws and legislation
KW  - Philosophical aspects
KW  - Case-studies
KW  - Chatbots
KW  - ChatGPT
KW  - Decisions makings
KW  - Ethical concerns
KW  - Generative AI
KW  - Medical services
KW  - Privacy
KW  - Restriction
KW  - Decision making
PB  - Institute of Electrical and Electronics Engineers Inc.
SN  - 21693536 (ISSN)
LA  - English
J2  - IEEE Access
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 2; Correspondence Address: M.S. Sayeed; Multimedia University, Centre for Intelligent Cloud Computing (CICC), Faculty of Information Science and Technology, Bukit Beruang, Melaka, 75450, Malaysia; email: shohel.sayeed@mmu.edu.my
ER  -

TY  - JOUR
AU  - Bozkurt, A.
TI  - GenAI et al.: Cocreation, Authorship, Ownership, Academic Ethics and Integrity in a Time of Generative AI
PY  - 2024
T2  - Open Praxis
VL  - 16
IS  - 1
SP  - 1
EP  - 10
DO  - 10.55982/openpraxis.16.1.654
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188900975&doi=10.55982%2fopenpraxis.16.1.654&partnerID=40&md5=a9ea382cb38b1563b25aa0e0dc8cdc8e
AD  - Anadolu University, Turkey
AB  - This paper investigates the complex interplay between generative artificial intelligence (AI) and human intellect in academic writing and publishing. It examines the ‘organic versus synthetic’ paradox, emphasizing the implications of using generative AI tools in educational and academic integrity contexts. The paper critiques the prevalent ‘publish or perish’ culture in academia, highlighting the need for systemic reevaluation due to generative AI’s emerging role in academic writing and reporting. It delves into the legal and ethical challenges of authorship and ownership, especially in relation to copyright laws and AI-generated content. The paper discusses generative AI’s diverse roles and advocates for transparent reporting to uphold academic integrity. Additionally, it calls for a broader examination of generative AI tools and stresses the need for new mechanisms to identify generative AI use and ensure adherence to academic integrity and ethics. The implications of generative AI are also explored, suggesting the need for innovative AI-inclusive strategies in academia. The paper concludes by emphasizing the significance of generative AI in various information-processing domains, highlighting the urgency to adapt and transform academic practices in an era of rapid generative AI-driven change. © 2024 The Author(s).
KW  - academic integrity
KW  - academic writing
KW  - AI
KW  - AIEd
KW  - artificial intelligence
KW  - authorship
KW  - chatbots
KW  - ChatGPT
KW  - cocreating
KW  - collaboration
KW  - conversational agents
KW  - education
KW  - educational technology
KW  - ethics
KW  - GenAI
KW  - Generative AI
KW  - generative pre-trained transformer
KW  - GPT
KW  - higher education
KW  - large language models
KW  - learning
KW  - LLMs
KW  - natural language processing
KW  - ownership
KW  - teaching
KW  - transparency in research
PB  - International Council for Open and Distance Education
SN  - 13699997 (ISSN)
LA  - English
J2  - Open. Prax.
M3  - Editorial
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 17; Correspondence Address: A. Bozkurt; Anadolu University, Turkey; email: arasbozkurt@gmail.com
ER  -

TY  - JOUR
AU  - Thongmeensuk, S.
TI  - Rethinking copyright exceptions in the era of generative AI: Balancing innovation and intellectual property protection
PY  - 2024
T2  - Journal of World Intellectual Property
VL  - 27
IS  - 2
SP  - 278
EP  - 295
DO  - 10.1111/jwip.12301
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191154123&doi=10.1111%2fjwip.12301&partnerID=40&md5=da31022811243d20ce78dc867472cf42
AD  - Thailand Development Research Institute (TDRI), Bangkok, Wang Thonglang, Thailand
AD  - Central Asian Legal Research (CALR) Fellowship, Tashkent State University of Law, Tashkent, Uzbekistan
AD  - AI Governance Clinic by Electronic Transactions Development Agency (ETDA), Lak Si District, Bangkok, Thailand
AB  - Generative artificial intelligence (AI) systems, together with text and data mining (TDM), introduce complex challenges at the junction of data utilization and copyright laws. The inherent reliance of AI on large quantities of data, often encompassing copyrighted materials, results in multifaceted legal quandaries. Issues surface from the unfeasible task of securing permission from each copyright holder for AI training, further muddled by ambiguities in interpreting copyright laws and fair use provisions. Adding to the conundrum, the clandestine practices of data collection in proprietary AI systems obstruct copyright owners from detecting unauthorized use of their materials. The paper explores the exceptions to copyright laws for TDM in the European Union, the United Kingdom, and Japan, recognizing their crucial role in fostering AI development. The EU has a two-pronged approach under the Directive on Copyright in the Digital Single Market, with one exception catering specifically to research organizations, and another, more generalized one, that can be restricted by rightsholders. The UK allows noncommercial TDM research without infringement but rejected a broader copyright exception due to concerns from the creative sector. Japan has the broadest TDM exception globally, permitting the nonenjoyment use of works without permission, though this can potentially overlook the rights of copyright owners. Notably, the applicability of TDM exceptions to AI-produced copies remains unclear, creating potential legal challenges. Furthermore, an exploration of the fair use doctrine in the United States provides insight into its potential application in AI development. It focuses on the transformative aspect of usage and its impact on the original work's potential market. This exploration underscores the necessity for clear, practical guidelines. In response to these identified challenges, this paper proposes a hybrid model for TDM exceptions emerges, along with recommended specific mechanisms. The model divides exceptions into noncommercial and commercial uses, providing a nuanced solution to complex copyright issues in AI training. Recommendations incorporate mandatory exceptions for noncommercial uses, an opt-out clause for commercial uses, enhanced transparency measures, and a searchable portal for copyright owners. In conclusion, striking a delicate equilibrium between technological progress and the incentive for creative expression is of paramount importance. These suggested solutions aim to establish a harmonious foundation that nurtures innovation and creativity while honoring creators' rights, facilitating AI development, promoting transparency, and ensuring fair compensation for creators. © 2024 John Wiley & Sons Ltd.
KW  - copyright infringement
KW  - fair use doctrine
KW  - generative AI
KW  - text and data mining exception
PB  - John Wiley and Sons Inc
SN  - 14222213 (ISSN)
LA  - English
J2  - J. World Intellect. Prop.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 2; Correspondence Address: S. Thongmeensuk; Thailand Development Research Institute (TDRI), Bangkok, 565 Soi Ramkhamhaeng 39, Phlabphla, Wang Thonglang, 10310, Thailand; email: saliltorn.th@gmail.com
ER  -

TY  - JOUR
AU  - Kadoya, N.
AU  - Arai, K.
AU  - Tanaka, S.
AU  - Kimura, Y.
AU  - Tozuka, R.
AU  - Yasui, K.
AU  - Hayashi, N.
AU  - Katsuta, Y.
AU  - Takahashi, H.
AU  - Inoue, K.
AU  - Jingu, K.
TI  - Assessing knowledge about medical physics in language-generative AI with large language model: using the medical physicist exam
PY  - 2024
T2  - Radiological Physics and Technology
VL  - 17
IS  - 4
SP  - 929
EP  - 937
DO  - 10.1007/s12194-024-00838-2
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203448346&doi=10.1007%2fs12194-024-00838-2&partnerID=40&md5=655aad19d02068752db5e5d8bcb1b529
AD  - Department of Radiation Oncology, Tohoku University Graduate School of Medicine, 1-1 Seiryo-Machi, Aoba-Ku, Miyagi, Sendai, 980-8574, Japan
AD  - Radiation Oncology Center, Ofuna Chuo Hospital, Ofuna 6-2-24, Kanagawa, Kamakura, 247-0056, Japan
AD  - School of Medical Sciences, Division of Medical Physics, Fujita Health University, Aichi, Toyoake, 470-1192, Japan
AD  - Elith, Inc, 2-3-13-605 Ebisunishi, Tokyo, Shibuya-Ku, 150-0021, Japan
AB  - This study aimed to evaluate the performance for answering the Japanese medical physicist examination and providing the benchmark of knowledge about medical physics in language-generative AI with large language model. We used questions from Japan’s 2018, 2019, 2020, 2021 and 2022 medical physicist board examinations, which covered various question types, including multiple-choice questions, and mainly focused on general medicine and medical physics. ChatGPT-3.5 and ChatGPT-4.0 (OpenAI) were used. We compared the AI-based answers with the correct ones. The average accuracy rates were 42.2 ± 2.5% (ChatGPT-3.5) and 72.7 ± 2.6% (ChatGPT-4), showing that ChatGPT-4 was more accurate than ChatGPT-3.5 [all categories (except for radiation-related laws and recommendations/medical ethics): p value < 0.05]. Even with the ChatGPT model with higher accuracy, the accuracy rates were less than 60% in two categories; radiation metrology (55.6%), and radiation-related laws and recommendations/medical ethics (40.0%). These data provide the benchmark for knowledge about medical physics in ChatGPT and can be utilized as basic data for the development of various medical physics tools using ChatGPT (e.g., radiation therapy support tools with Japanese input). © The Author(s), under exclusive licence to Japanese Society of Radiological Technology and Japan Society of Medical Physics 2024.
KW  - Artificial intelligence
KW  - ChatGPT
KW  - Examination
KW  - Medical physicist
KW  - Radiotherapy
KW  - Artificial Intelligence
KW  - Educational Measurement
KW  - Health Physics
KW  - Humans
KW  - Japan
KW  - Language
KW  - Article
KW  - attitude to health
KW  - benchmarking
KW  - ChatGPT
KW  - clinical assessment
KW  - clinical evaluation
KW  - comparative study
KW  - controlled study
KW  - general practice
KW  - generative artificial intelligence
KW  - human
KW  - Japan
KW  - Japanese (people)
KW  - large language model
KW  - measurement accuracy
KW  - medical ethics
KW  - medical physicist
KW  - nuclear medicine
KW  - radiation oncology
KW  - radiation physics
KW  - radiobiology
KW  - radiodiagnosis
KW  - artificial intelligence
KW  - education
KW  - health physics
KW  - language
KW  - procedures
PB  - Springer
SN  - 18650333 (ISSN)
C2  - 39254919
LA  - English
J2  - Radiol. Phys. Technol.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 1; Correspondence Address: N. Kadoya; Department of Radiation Oncology, Tohoku University Graduate School of Medicine, Sendai, 1-1 Seiryo-Machi, Aoba-Ku, Miyagi, 980-8574, Japan; email: kadoya.n@rad.med.tohoku.ac.jp
ER  -

TY  - JOUR
AU  - Dermawan, A.
TI  - Text and data mining exceptions in the development of generative AI models: What the EU member states could learn from the Japanese “nonenjoyment” purposes?
PY  - 2024
T2  - Journal of World Intellectual Property
VL  - 27
IS  - 1
SP  - 44
EP  - 68
DO  - 10.1111/jwip.12285
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160839288&doi=10.1111%2fjwip.12285&partnerID=40&md5=a74ca00a9be04b3987e6920d0615bf58
AD  - The Max Planck Institute for Innovation and Competition, Munich, Germany
AD  - The Law, Technology and Design Thinking (LTDT) Research Group, Faculty of Law, University of Lapland, Rovaniemi, Finland
AB  - The European Union (EU) text and data mining (TDM) provisions are a progressive move, but the horizon is still uncertain for both generative artificial intelligence (GenAI) models researchers and developers. This article suggests that to drive innovation and further the commitment to the digital single market, during the national implementation, EU Member States could consider taking the Japanese broad, all-encompassing and “nonenjoyment-based” TDM as an example. The Japanese “nonenjoyment” purposes, however, are not foreign to the European continental view of copyright. A similar concept can be found under the German concept of “Freier Werkgenuss” or enjoyment of the work. A flexible TDM exception built upon the German notion of nonenjoyment purposes could become an opening clause to foster innovation and creativity in the age of GenAI. Moreover, the article argues that an opening clause allowing TDM with “nonenjoyment” purposes could be permissible under the so-called three-step test. This article further suggests, if there is no political will to safeguard “the right to read should be the right to mine” and to provide a welcoming environment for GenAI researchers and developers, when shaping the legal interpretation through national case law, the EU Member States could consider the following: (1) advocate for 72 h of response if technological protection measures (TPMs) are preventing TDM, and (2) Robot Exclusion Standard (robot.txt) as a warning when TDM is not allowed on a website. It is now in the hands of the EU Member States, whether to protect the interests of rightholders or to create a balance between safeguarding “the right to read should be the right to mine,” protecting rightholders exclusivity, and creating a supportive environment for the GenAI models researcher and developers. © 2023 The Authors. The Journal of World Intellectual Property published by John Wiley & Sons Ltd.
KW  - copyright and related rights
KW  - freier werkgenuss
KW  - generative AI models
KW  - innovation
KW  - text and data mining
PB  - John Wiley and Sons Inc
SN  - 14222213 (ISSN)
LA  - English
J2  - J. World Intellect. Prop.
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 4; Correspondence Address: A. Dermawan; The Max Planck Institute for Innovation and Competition, Munich, Germany; email: artha.dermawan@ip.mpg.de
ER  -

TY  - JOUR
AU  - Zaretsky, J.
AU  - Min Kim, J.
AU  - Baskharoun, S.
AU  - Zhao, Y.
AU  - Austrian, J.
AU  - Aphinyanaphongs, Y.
AU  - Gupta, R.
AU  - Blecker, S.B.
AU  - Feldman, J.
TI  - Generative Artificial Intelligence to Transform Inpatient Discharge Summaries to Patient-Friendly Language and Format
PY  - 2024
T2  - JAMA Network Open
SP  - E240357
DO  - 10.1001/jamanetworkopen.2024.0357
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187472990&doi=10.1001%2fjamanetworkopen.2024.0357&partnerID=40&md5=f69bdc78efc778e78319f1f817bc41fb
AD  - Division of Hospital Medicine, Department of Medicine, NYU (New York University) Langone Health, New York, NY, United States
AD  - Department of Medicine, NYU Long Island School of Medicine, Mineola, United States
AD  - Department of Population Health, NYU Langone Health, New York, United States
AD  - Department of Health Informatics, NYU Langone Medical Center Information Technology, New York, United States
AD  - Predictive Analytics Unit, NYU Langone Health, New York, United States
AD  - Department of Internal Medicine, Long Island Community Hospital, NYU Langone Health, New York, United States
AB  - IMPORTANCE By law, patients have immediate access to discharge notes in their medical records. Technical language and abbreviations make notes difficult to read and understand for a typical patient. Large language models (LLMs [eg, GPT-4]) have the potential to transform these notes into patient-friendly language and format. OBJECTIVE To determine whether an LLM can transform discharge summaries into a format that is more readable and understandable. DESIGN, SETTING, AND PARTICIPANTS This cross-sectional study evaluated a sample of the discharge summaries of adult patients discharged from the General Internal Medicine service at NYU (New York University) Langone Health from June 1 to 30, 2023. Patients discharged as deceased were excluded. All discharge summaries were processed by the LLM between July 26 and August 5, 2023. INTERVENTIONS A secure Health Insurance Portability and Accountability Act–compliant platform, Microsoft Azure OpenAI, was used to transform these discharge summaries into a patient-friendly format between July 26 and August 5, 2023. MAIN OUTCOMES AND MEASURES Outcomes included readability as measured by Flesch-Kincaid Grade Level and understandability using Patient Education Materials Assessment Tool (PEMAT) scores. Readability and understandability of the original discharge summaries were compared with the transformed, patient-friendly discharge summaries created through the LLM. As balancing metrics, accuracy and completeness of the patient-friendly version were measured. RESULTS Discharge summaries of 50 patients (31 female [62.0%] and 19 male [38.0%]) were included. The median patient age was 65.5 (IQR, 59.0-77.5) years. Mean (SD) Flesch-Kincaid Grade Level was significantly lower in the patient-friendly discharge summaries (6.2 [0.5] vs 11.0 [1.5]; P < .001). PEMAT understandability scores were significantly higher for patient-friendly discharge summaries (81% vs 13%; P < .001). Two physicians reviewed each patient-friendly discharge summary for accuracy on a 6-point scale, with 54 of 100 reviews (54.0%) giving the best possible rating of 6. Summaries were rated entirely complete in 56 reviews (56.0%). Eighteen reviews noted safety concerns, mostly involving omissions, but also several inaccurate statements (termed hallucinations). CONCLUSIONS AND RELEVANCE The findings of this cross-sectional study of 50 discharge summaries suggest that LLMs can be used to translate discharge summaries into patient-friendly language and formats that are significantly more readable and understandable than discharge summaries as they appear in electronic health records. However, implementation will require improvements in accuracy, completeness, and safety. Given the safety concerns, initial implementation will require physician review. © 2024 American Medical Association. All rights reserved.
KW  - Adult
KW  - Aged
KW  - Artificial Intelligence
KW  - Cross-Sectional Studies
KW  - Electronic Health Records
KW  - Female
KW  - Humans
KW  - Inpatients
KW  - Language
KW  - Male
KW  - Middle Aged
KW  - Patient Discharge
KW  - United States
KW  - adult
KW  - aged
KW  - artificial intelligence
KW  - cross-sectional study
KW  - electronic health record
KW  - female
KW  - hospital discharge
KW  - hospital patient
KW  - human
KW  - language
KW  - male
KW  - middle aged
KW  - United States
PB  - American Medical Association
SN  - 25743805 (ISSN)
C2  - 38466307
LA  - English
J2  - JAMA Netw. Open
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 25; Correspondence Address: J. Zaretsky; NYU Langone Health, New York, 550 First Ave, 10016, United States; email: jonah.zaretsky@nyulangone.org
ER  -

TY  - JOUR
TI  - Research on the Risks of Disinformation from Generative Artificial Intelligence and Its Governance Paths
ST  - 生成式人工智能的虚假信息风险特征及其治理路径
PY  - 2024
T2  - Information studies: Theory and Application
VL  - 47
IS  - 3
SP  - 112
EP  - 120
DO  - 10.16353/j.cnki.1000-7490.2024.03.015
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204366601&doi=10.16353%2fj.cnki.1000-7490.2024.03.015&partnerID=40&md5=e6e4a9a89d6c8b31cdc5dde6e0cdaa9e
AB  - [Purpose/significance] Generative artificial intelligence (AI) transforms the mode of information generation in cyberspace, creating massive and realistic disinformation that poses a severe threat to social security. It is imperative to devise a governance mechanism for the disinformation risk of generative AI from the perspective of balancing development and security. [Method/process] This paper Summarize the practical problems and future risks of disinformation generated by generative AI, and propose the challenges that generative AI poses to the existing disinformation governance system, thereby clarifying the governance paths against the disinformation risks of generative AI. [Result/conclusion] At the level of mechanism construction, a collaborative governance mechanism for false information should be established, through strategic planning to unify the normative concept of “disinformation” and transmit it to legal systems and information law enforcement practices. At the level of pluralistic governance, we encourage multiple actors to participate in fact-checking work, assign AIGC identification obligations to information publishers and disseminators, and enhance citizens’ information literacy through school education and extension of resource supplement. At the level of scientific and technological methods, it is to reduce the risk of false information from the underlying technology of generative AI, and require generative AI service providers to equip with necessary technology and channels for identifying disinformation. © 2024 Information studies: Theory and Application. All rights reserved.
KW  - AIGC
KW  - collaborative governance
KW  - disinformation
KW  - generative artificial intelligence
KW  - mechanism of fact checking
PB  - Information studies: Theory and Application
SN  - 10007490 (ISSN)
LA  - Chinese
J2  - Inf. Stud. Theory and Application
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 2
ER  -

TY  - CONF
AU  - El Ali, A.
AU  - Venkatraj, K.P.
AU  - Morosoli, S.
AU  - Naudts, L.
AU  - Helberger, N.
AU  - Cesar, P.
TI  - Transparent AI Disclosure Obligations: Who, What, When, Where, Why, How
PY  - 2024
T2  - Conference on Human Factors in Computing Systems - Proceedings
C7  - 342
DO  - 10.1145/3613905.3650750
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194181995&doi=10.1145%2f3613905.3650750&partnerID=40&md5=8f73034e613a6694b257dfc3a0e0d153
AD  - Centrum Wiskunde & Informatica, Amsterdam, Netherlands
AD  - University of Amsterdam, Amsterdam, Netherlands
AD  - University of Amsterdam, KU Leuven, Amsterdam, Netherlands
AD  - Centrum Wiskunde & Informatica, Delft University of Technology, Amsterdam, Netherlands
AB  - Advances in Generative Artificial Intelligence (AI) are resulting in AI-generated media output that is (nearly) indistinguishable from human-created content. This can drastically impact users and the media sector, especially given global risks of misinformation. While the currently discussed European AI Act aims at addressing these risks through Article 52's AI transparency obligations, its interpretation and implications remain unclear. In this early work, we adopt a participatory AI approach to derive key questions based on Article 52's disclosure obligations. We ran two workshops with researchers, designers, and engineers across disciplines (N=16), where participants deconstructed Article 52's relevant clauses using the 5W1H framework. We contribute a set of 149 questions clustered into five themes and 18 sub-themes. We believe these can not only help inform future legal developments and interpretations of Article 52, but also provide a starting point for Human-Computer Interaction research to (re-)examine disclosure transparency from a human-centered AI lens. © 2024 Association for Computing Machinery. All rights reserved.
KW  - Article 52
KW  - disclosures
KW  - EU AI Act
KW  - generative artificial intelligence
KW  - law
KW  - obligations
KW  - research questions
KW  - transparency
KW  - Artificial intelligence
KW  - Human computer interaction
KW  - Article 52
KW  - Disclosure
KW  - EU artificial intelligence act
KW  - Generative artificial intelligence
KW  - Global risks
KW  - Human-computer interaction researches
KW  - Law
KW  - Obligation
KW  - Research questions
KW  - Transparency
PB  - Association for Computing Machinery
SN  - 979-840070331-7 (ISBN)
LA  - English
J2  - Conf Hum Fact Comput Syst Proc
M3  - Conference paper
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 3; Conference name: 2024 CHI Conference on Human Factors in Computing Sytems, CHI EA 2024; Conference date: 11 May 2024 through 16 May 2024; Conference code: 199442
ER  -

TY  - JOUR
AU  - Ye, X.
AU  - Yan, Y.
AU  - Li, J.
AU  - Jiang, B.
TI  - Privacy and personal data risk governance for generative artificial intelligence: A Chinese perspective
PY  - 2024
T2  - Telecommunications Policy
VL  - 48
IS  - 10
C7  - 102851
DO  - 10.1016/j.telpol.2024.102851
UR  - https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203293688&doi=10.1016%2fj.telpol.2024.102851&partnerID=40&md5=e011d23fe27cbec79c260387de425d89
AD  - Law School, Central China Normal University, China
AD  - School of Government, University of International Business and Economics, China
AD  - School of Law, University of International Business and Economics, China
AD  - School of International Studies, Hainan University, China
AD  - School of International Law, China University of Political Science and Law, China
AB  - The rapid development of generative artificial intelligence (AI) has attracted global attention and posed challenges to existing data governance frameworks. The increased technical complexity and expanded scale of data usage not only make it more difficult to regulate AI but also present challenges for the current legal system. This article, which takes ChatGPT's training data and working principles as a starting point, examines specific privacy risks, data leakage risks, and personal data risks posed by generative AI. It also analyzes the latest practices in privacy and personal data protection in China. This article finds that while China's governance on privacy and personal data protection takes a macro-micro integration approach and a private-and-public law integration approach, there are shortcomings in the legal system. Given that the current personal data protection system centered on individual control is unsuitable for the modes of data processing by generative AI, and that private law is insufficient in safeguarding data privacy, urgent institutional innovation is needed to achieve the objective of “trustworthy AI.” © 2024 The Authors
KW  - Chinese law
KW  - Generative AI
KW  - Privacy and personal data protection
KW  - Risk governance
KW  - Data assimilation
KW  - Generative adversarial networks
KW  - 'current
KW  - Chinese law
KW  - Data governances
KW  - Generative artificial intelligence
KW  - Integration approach
KW  - Legal system
KW  - Personal data protections
KW  - Privacy and personal data protection
KW  - Risk governance
KW  - Technical complexity
KW  - Differential privacy
PB  - Elsevier Ltd
SN  - 03085961 (ISSN)
LA  - English
J2  - Telecommun Policy
M3  - Article
DB  - Scopus
N1  - Export Date: 18 December 2024; Cited By: 2; Correspondence Address: Y. Yan; Beijing, No.10 Huixin East Street, Chaoyang District, 100029, China; email: 03388@uibe.edu.cn; CODEN: TEPOD
ER  -

